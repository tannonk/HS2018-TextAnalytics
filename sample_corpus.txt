Many observers consider that overcoming these issues will require a new paradigm: open science. The idea is to break the shackles that fetter the individual elements of the scientific production process – from the formation of hypotheses to the publication of results (See infographic, ‘The elements of open science’, p. 13). The watchwords are: sharing and inclusion, collaboration and decentralisation, and transparency. By fully opening research work, it can be made useful to everyone: to scientists, industry, and members of civil society. Even computer programs will be able to draw new conclusions from old results. The first pillar is open access, the aim of which is to ensure all scientific publications are accessible free of charge. “Even if people are a little impatient, we are clearly on the right track”, says Daniël Lakens, a psychology researcher and practitioner of open science at Eindhoven University of Technology. According to a European study published in 2014, more than half of all the articles published since 2007 are open access. Nevertheless, the question of cost remains: even if an open-access journal can be consulted free of charge, the average cost of publishing each article is EUR 3,000. Also to be factored in are prepublication archives, such as Arxiv and SSRN, that offer free access to manuscripts submitted to journals. Tariffs for publishing articles are continually increasing, and this is a bone of contention. Science publishing has to react, as it is now also confronted by piracy: some websites make millions of articles available, and not all of them illegally. The second pillar, open research data, involves a radical change in the attitude of scientists with regard to their raw data. “Most of them consider that it belongs to them”, says Lakens. Their work revolves around the interpretation of their results and the formulation of clear and concise conclusions, not around the disclosure of primary data. This approach renders it impossible to make comparisons or to question their choice of interpretation, such as the type of statistical analysis employed. “For me, publication bias – that is, the general practice of only publishing positive results – is the biggest problem in today’s science. Fixing it will require access to all data, particularly those not included in a publication”, says Lakens. For most scientists, there is no individual or direct interest in sharing raw data, particularly in light of the burdens of time, cost and, in some cases, the development of computer skills. Open research data therefore often continues to rely on individual initiative or top-down provisos of certain research programmes. “What’s needed is new incentives, because open data today has only a minimal impact on a researcher’s reputation”, says Sascha Friesike of the Alexander von Humboldt Institute for Internet and Society (HIIG) in Berlin and a former doctoral student in the management of innovation at the University of St. Gallen. Things are changing, however, “particularly because a number of public and private financing bodies are introducing a requirement to share the data stemming from the research they pay for”, she adds. Data is not enough on its own, however; there also needs to be precise disclosure of the methodology used in acquiring it, such as laboratory methods or adjustments made to instrumentation. Only then will it be possible for other research groups to reproduce the results and subsequently either validate or refute them. The open-science movement aspires to a world where researchers resolve their problems in concert with each other and keep lab notebooks available to everybody on the Internet. “Science is tackling problems that are becoming increasingly complex and that therefore need greater collaboration”, says Friesike. “Instead of meeting the often rigid requirements of research programmes, researchers should be more interested in organising themselves by launching calls to collaboration that are open to everyone. This would also up the pressure to share data, methods and facilities – without that there is hardly any incentive for others to join a project”. B. Fecher and S. Friesike: Open Science: One Term, Five Schools of Thought. SSRN (2013)

What does 'open science' mean to you as a researcher? At the School of Computer and Communication Sciences at EPFL, we traditionally make all our published papers freely available online. We also provide all the associated data and source codes. In this manner, all our results can be reproduced by other research groups. Researchers are already drowning in papers today. How can they hope to keep up if everything is going to be made freely available? With open science, the exact opposite will happen. Publishing an article on this basis means that all data is documented clearly. Every step in our work that led to a result is described so that others can comprehend it. This means that, overall, fewer papers will be published, while their quality will rise at the same time. It will also make research more transparent. How exactly do you go about this? We still publish in the traditional journals. But even while we're submitting the paper, we put all our data on our server. As soon as the article is accepted, we also place it on free online access. Shouldn't a researcher have the right to keep his laboratory recipes to himself? Certainly not in my field, the computer sciences. And maybe the same should apply in other fields too. 350 years ago, we moved from the age of alchemy into chemistry. The alchemists simply claimed that they could produce gold according to a secret method. There was no possibility of checking their claims systematically. You could choose to believe them, or not. But all that changed with the onset of chemistry. We began to publish our methods. That was the moment when modern science was born. If we do things differently today, then we're returning to an age of alchemy. Of all the publications that have resulted from SNSF funding, only 40 percent are freely available. As President of the Research Council, are you OK with that? No. I'm frustrated. We are much too slow. Today, the Swiss taxpayers pay three times. First for the actual research, secondly for their subscription to the specialist journals where it's published, then thirdly for open access. This means the publisher profits twice. That's truly shameful. We can't tolerate it. So what are you doing about it? How do you want to achieve this? If Switzerland as a centre of research is able to present a united front, then we can go to the publishers and say: Either you do a deal with us now, or the Swiss research community will boycott you. That will be difficult, of course. But the Netherlands have managed it. And they've been successful. Is Switzerland ready for such a step? The whole situation is rather complicated. The many different researchers active in Switzerland have different interests. We're still finding it a little difficult to coordinate all these interests. Couldn't the SNSF simply compel researchers to publish their data only in open-access journals? That's not so simple, because in some cases it would be bad for their careers. Researchers have to endeavour to publish in journals that are best suited to their results. It's also our goal to further the careers of our researchers, not to hinder them. Why doesn't EPFL found its own specialist journal? A specialist journal of our own would be a very good idea. But it's not something that we can make happen on a top-down basis. It has to come from the research community itself. If a community decides to leave the traditional path, it will happen. But I'm not the person to decide that. Such a process would require a cultural shift among researchers. Have researchers elsewhere already gone down that path? Yes. Together with other researchers, the famous mathematician Timothy Gowers at the University of Cambridge has founded the journal 'Discrete Analysis'. It's a virtual journal. The editorial board can concentrate solely on peer-reviewing because the papers submitted are managed by an external company. The costs amount to about ten francs per manuscript. So it's a hundred to a thousand times cheaper than publishing in a traditional journal. In 2012, an article in Nature showed that 47 of 53 important cancer studies were not reproducible. How is that possible? To be fair, we have to admit that research is more difficult in some fields than in others. In medicine, for example, you only have a small amount of data because you're dealing with real people. That means that there are often problems with both statistics and reproducibility. Nevertheless, the reproducibility crisis also affects other areas, such as biology, where you can choose your volume of data more freely. I've heard well-known professors claim: "The other group couldn't reproduce that because they're not as good as us". There are indeed people who have a real knack – they can work with organisms so well that their experiments succeed, while others can't reproduce them. Nevertheless, I think that it's a weakness, because the goal of science is absolute reproducibility. Isn't it just that people are cheating? This can happen, but it's certainly not the norm. Here we also have to remember that researchers are in competition with each other. A bit too much competition today. The resulting pressure makes researchers feel compelled to publish their work, even when it's inadequate. So is competition bad for research? No, I wouldn't put it as simply as that. In science, we have always been keen to be the first to discover something. That's how we make progress in research, by being cleverer and better than the others. It's part and parcel of research that we compete against each other. So what's the problem? Today, it's particularly difficult for young people to become real researchers. Fifty years ago, we still had the leisure to think differently about the world and to generate new ideas. Today, research has become a business. The general public, politicians and the private sector think that you can pour money into research at one end, and get useful results out of the other end shortly afterwards. But of course it's not like that. Research needs time and space if people are going to be able to think creatively. But researchers have it good at EPFL, don't they? This is not just a Swiss matter. Research is global. And there are several alarming phenomena. In certain Asian countries, for example, researchers' wages depend on the specialist journals in which they publish. That's a dubious practice, because it almost encourages dishonest behaviour. And does this have an impact on Switzerland as a centre of research? Yes. Young researchers feel under pressure to publish. They'll turn the material for one article into three articles, because it looks better on their publication list. We also see this in requests for peer review. There's been a huge increase in recent years. The whole system is being swamped. And quality considerations naturally get left behind. How can open science improve the current system? If we shift to open science, then we'll produce fewer, but better-quality papers. And they can be reviewed quicker because everything is documented. You're the next EPFL president. What concrete measures are you planning so as to promote open science there? In those research fields that have already taken major steps into open science, I want to promote a research culture in which other fields are encouraged to join them. We're providing an online tool for this. It allows researchers to upload their data easily and let others see it. Third parties can then check it. But this tool is also intended to promote collaboration between different research fields. In the environmental sciences, for example, people aren't necessarily accustomed to dealing with large volumes of data. Here, the mathematicians or computer scientists could help them out. How can you convince young researchers about the value of open science? I tell them: The most important thing for your career is that your work has a big impact. If you place your data online, your work will become more visible and people will also trust you. And that will help your work to have a bigger impact. I can't compel them to embrace it. It's something they have to realise by themselves.

The theory of evolution supports egoistic behaviour, even down to the level of DNA as is reflected in the concept of the ‘selfish gene’. So it is astonishing just how often organisms actually cooperate. But without mutual assistance, nothing works. Male and female birds invest jointly in rearing their young, for example. Insects create veritable ‘States’ with tasks shared among them. The emergence of cooperative behaviour is a perennial topic of debate among biologists, and is a subject of intensive research by evolutionary biologists, geneticists and even game theorists. Taking this dilemma as his starting point, Wubs has been investigating a virtual population to see which of three strategies to promote cooperation would win through. An individual can either punish the traitor, leave him, or pay him back in the sense of ‘an eye for an eye’. Different parameters of the mathematical model can be varied for the different rounds of interaction – such as the size of the population and the actual number of interactions. Although the model represents a simplification of real circumstances, it can depict biological principles realistically. In large groups, it is advantageous simply to avoid disloyal members. “The strategy of changing partner is the more dominant, the bigger the group and the bigger the number of interactions”, says Wubs. This result is intuitively comprehensible: in a large group, an individual that leaves its non-cooperating partner has a good chance of finding a better partner. The ‘punishment’ alternative, however, requires lifelong effort to keep one’s partner in his place. This strategy changes with the population size and the number of interactions. “In small groups, it’s better to punish uncooperative members”, says Wubs. In the case of birds, this can mean that the renegade partner has a feather torn out. The individual carrying out the punishment thereby compels the partner to cooperate. In smaller groups this is advantageous, because the number of possible cooperating individuals is small. Surprisingly, the computer simulations also showed that punishment was the means of choice in mid-size populations with some 50 interacting individuals. This wasn’t a result that Wubs had expected. Simon Powers, a theoretical biologist and modeller who lectures at Napier University in Edinburgh, finds this result particularly worthy of emphasis: “Among biologists there has long been a debate about whether natural selection can favour the punishment of non-cooperating individuals”. In Powers’s opinion, the computer models developed by Wubs and his colleagues have now shown that punishment could even outweigh other forms of partner control. Elegant maths can clearly help us to acquire new insights into evolution that would otherwise not be obvious. For Wubs as a theoretical biologist, the appeal of his specialist field lies precisely in this form of knowledge production. “We can develop hypotheses and test them”, he says. Empiricists can then look for real populations that the model predicts must exist. M. Wubs et al.: Coevolution between positive reciprocity, punishment, and partner switching in repeated interactions. Proceedings of the Royal Society of London B (2016)

What’s it like for a researcher to be in the political limelight? I’m aware that we are researching into topics that are controversial – such as how long people should have to wait before they can apply for Swiss citizenship. Other policy matters, however, are astonishingly free of controversy. Such as the positive consequences of shorter asylum procedures. In a democracy, it’s important to be able to demonstrate the pros and cons of different policies, and to do so with political independence. Our field of research is emotionally charged, but we aim to provide cool-headed analysis and objective instruments so that people can form fact-based opinions. The visibility of migration topics in many countries has meant an increasing interest in our work in recent years. How do you cope when politicians appropriate your research results? I have two tasks as a researcher. First, I have to make accurate analyses, identifying causes and effects. For example, if we shorten an asylum procedure by two months, it means refugees can begin working sooner. This costs the state less and promotes integration. Secondly, I have to ensure that our results can be understood by both experts and laypeople in the way that we have quantified them. After all, our research is funded by people’s taxes. The better we succeed in that, the less room there is for misinterpretation. We can make suggestions for better integration policies, but it’s up to politicians, administrators and the voters to decide if and how our suggestions are to be put into practice. Have you ever considered withholding results for fear they’ll be misunderstood? This is one of the taboo topics among researchers. There is rarely a good time to publish inconvenient findings. Speaking for myself, I have never been in that kind of situation. But I think I have a pretty thick skin. All the same, your work prompts all kinds of reactions. Do you read the commentaries in the social media? Sometimes. But that’s not necessarily a meaningful way to spend your time. What about you: where do you stand on the political spectrum? My interest in migration as a topic is partly due to my own biography. But this has no impact on the scientific process by which I conduct my research, or on the results I get. I want to understand what works and what doesn’t. The analysis itself is a neutral process. Nor do I have any incentive to gloss over anything. Our society has political instruments that can be expensive and well-meaning, but that actually achieve nothing. In such cases, a country has to review what it’s doing. Should you intervene more in public debate? My research takes place in the midst of our society. So I have to communicate my results to everyone who’s affected, which in this case means all those who are involved in the field of migration. We also choose our communication partners systematically. We have presented our results on labour market integration to the European Parliament, and showed the representatives of different countries how they can make data available for further studies. Your projects are international in focus, though you’re Swiss yourself. Does this help you to remain more independent? It helps. But what’s relevant to Switzerland also meets with interest abroad. Lots of European countries were interested in our results on accelerating the asylum process. For example, we were asked about adapting it to the Finnish context. Our public relations work means we get many requests from countries outside Switzerland. This can help us to build up pressure for researchers to get access to data from those countries that had previously kept it under wraps.

The trace element selenium (Se) only occurs in tiny concentrations and yet is essential to living beings. It usually gets less attention than its big brothers iron, iodine or zinc, but neither human beings nor animals can do without it. This was reason enough for the biogeochemist Lenny Winkel from the Department of Environmental Sciences at ETH Zurich and Eawag to devote herself more intensively to this trace element. And Winkel isn’t just looking at it on a molecular level, but as part of a bigger picture. Together with her team, she’s investigating what the distribution of selenium looks like across the globe, and what factors determine where it occurs. “Basically, we don’t know so much about the distribution of trace elements”, says Winkel. The concentration of selenium in the soil is different from one region to the next. Humans absorb selenium primarily through plant-based foodstuffs. But even in plants, the selenium content varies greatly according to where they grow. There are estimates that between half a million and a million people across the world suffer from selenium deficiency. In Europe – and thus in Switzerland too – the problem is not so much the concentration of selenium in the soil, but the amount of it that’s absorbed by plants, says Winkel. But this does not mean that everyone in Switzerland is necessarily suffering from a selenium deficiency, because we rarely subsist on purely local products. “The concentration of selenium in the earth is also decreasing everywhere on account of global warming”, says Winkel. She and her team have recently published the first-ever global map of selenium distribution in the soil. It’s not just Europe that’s affected, but other areas on other continents too. In Mongolia, the authorities began a programme in 2016 to give chickens feed that has been enriched with selenium. The eggs produced by these chickens could help to reduce the deficiency symptoms  among the population. Different climate and soil parameters determine how much selenium is concentrated in the soil. As a rule of thumb: if the  soil is dry, the selenium content is usually too low. But it’s not just the amount of rainfall that determines the concentration of it. The condition of the soil plays an important role, as does the amount of organic carbon in it. This organic material binds with the selenium and keeps it longer in the soil. “Lenny Winkel’s research project is very important – and it’s unique”, says Markus Lenz of FHNW School of Life Sciences, who  is also researching into selenium. There are few comparable projects that deal with the global distribution of trace elements. Nor is selenium easy to investigate, because it has a highly complex chemistry and occurs in the environment in different  bonding forms. It is also still unclear to what extent the phytoplankton in the oceans play a role in the global distribution of this trace element. This is something that Winkel’s team wants to investigate further. Only if we know more about the global distribution channels of selenium can we hope to take measures to combat its deficiency in specific areas – a deficiency that climate change is only making worse. lexandra Bröhm is a science journalist at the Tages-Anzeiger and the SonntagsZeitung. G.D. Jones et al.: Selenium deficiency risk predicted to increase under future climate change. PNAS (2017)

Sign languages are natural languages. They are developed and used in a linguistic community just like spoken languages. In Switzerland, there are three in use: Swiss-German, French and Italian sign languages. Modern linguistic research into sign languages began in the 1960s with studies in the USA and the Netherlands. In Switzerland, Penny Boyes Braem founded the Center for Sign Language Research in Basel in 1982 as a private, non-profit organisation. “Back then, no other institution in Switzerland was prepared to promote research into these languages, which were looked down on by some”, she explains. “For linguists, however, the descriptions in these languages, which are produced and perceived visually, are highly interesting because they often shed new light on traditional language theories”. For example, in sign language, visual iconicity is present on all levels – in other words, there is a visible relationship to linguistic expressions. This casts a ‘long shadow’ over the linguistic principle that the relationship between the linguistic sign (i.e. words) and their meaning is arbitrary in all human languages. For example, the words for the concept ‘tree’ are very different in unrelated languages. But in many sign languages of the world, the signs for ‘tree’ offer a pictorial aspect of the form of a tree. Today, sign language is being investigated at several institutions in Switzerland, such as at the University of Applied Sciences of Special Needs Education (HfH), at the University of Zurich and at the Zurich University of Applied Sciences in Winterthur (ZHAW). These projects need researchers who have themselves mastered sign language. One of them is Katja Tissi of the HfH. She has been deaf since birth and learnt her sign language from her older sister, who is also deaf. “As a child I felt bad when I used sign language”, she recalls. Until 1980, Swiss experts concentrated on sending the hearing-impaired to hearing and speech training sessions, and they communicated mostly via lip-reading. But on a visit to the USA, Tissi discovered that sign language was a subject of scientific research over there. “When I saw that sign language was recognised, it opened up whole new worlds to me, and gave me self-confidence”. Sign language research has profited from developments in computers and multimedia. What is of central importance is image recognition. “Just like people who can hear, more and more hearing-impaired people are using the Internet and social media” explains Penny Boyes Braem. In order to communicate via the Internet, the hearing-impaired often produce video clips in sign language. That way, they can be easily identified – unlike the users of spoken language, who can remain anonymous thanks to their use of written communication. This is why researchers are developing technologies to recognise signs on video, and then to have these translated back into gestures by a completely anonymous avatar. One initial step in this direction is the ‘Smile’ project (Scalable Multimodal sign language technology for sIgn language Learning and assessmEnt). It is being run by the Idiap Research Institute in Martigny in collaboration with the HfH and the University of Surrey (UK). This project is developing automatic sign language recognition technology that will offer learners feedback on their use of Swiss-German sign language. Automatic machine translation also plays a role in the doctoral research of Sarah Ebling at the University of Zurich. Hearing-impaired people cannot understand the platform announcements given at train stations. So Ebling has developed a system that enables the announcements to be shown by an avatar in Swiss-German sign language (DSGS) on a smartphone. Further research areas include the signals of the hands and the face as well as the cognitive processes involved when using sign languages. “Various studies have shown that coordinating a manual gesture with a non-manual component is a great challenge for adult learners who can hear. We still know far too little about the functioning of this modality-specific language acquisition”, explains Tobias Haug, the director of studies and a researcher at HfH. In order to investigate this, the HfH is planning a project for a so-called ‘learner corpus’ in DSGS. “The goal of this learner corpus is to collect data on learners over a certain period of their DSGS acquisition. We want to find out, for example, the typical difficulties they encounter when learning a sign language”.

“I arrived in Xàbia in August 2016. It’s a small coastal resort town in Alicante, and home to myriad retirees from northern and central Europe, especially the United Kingdom. In one neighbourhood in particular the residents speak only English and the shops all have English names. It is, in effect, a form of colony. There’s even a commonly heard joke in Xàbia: during negotiations over Gibraltar, the former Prime Minister Margaret Thatcher is said to have remarked: ‘I’ll give you Gibraltar back, but leave us Xàbia!’ dictates that solidarity among individuals is more the preserve of the family than of the state. There are expectations of retirees, such as providing support to the family, typically by looking after grandchildren. As they reach a grander age, they can then count on their children to care for them. This model is based on the members of the family all living in relatively close proximity, which led me to wonder what effect distance has on family solidarity. I’m following a post-doctoral programme at the University of Manchester (UK) and Virginia Tech (USA). Coincidence conspired in leading me to Xàbia. For many years, I’ve been studying the issues stemming from ageing, and I knew, thanks to the literature, that there were many retirees in Alicante. As I knew no one at all who’d gone there to set up for the long haul, I contacted a number of organisations and centres for retirees, including a regional association of Swiss retirees. Xàbia just happened to be the home of the first people I came into contact with. They put me in touch with other retirees, who had me added to some Facebook groups. This allowed me to extend my network to the neighbouring town of Dénia. I first travelled there for a month-and-a-half stay, before returning once more in January 2017. On this second trip, my husband and two children came with me. During my stay, I spoke to many retirees either living in Xàbia or spending part of the year there. I met with them both in public and in their homes. Through in-depth interviews, I was able to analyse the nature of the family bonds they maintained with those living far away. According to the people I interviewed, finances were a significant factor in the decision to leave home. They considered that they could improve their living conditions during their retirement by migrating abroad. In fact, some were in a financial situation that left them very little choice. Given the differences in purchasing power, some retirees were able to buy large houses, sometimes even with a pool. They can go out and eat in restaurants, which would not necessarily have been the case in the countries they had left behind. They were also aware that their presence was a helping hand to the regional economy, reinforcing their idea that they were legitimately at home there. They were open to talk about their situations and were proud of what they had achieved. They no longer felt like they were ‘mouths to be fed’. The literature on the topic generally considers retirees as individuals who leave to enjoy their freedom, particularly with regard to family duties. I found the opposite. First, they had chosen Spain over Thailand and North Africa, so as not to be too far from their families. They agreed on the need to be available in case of emergency. They also see it as important to be able to receive family members as guests and had the impression that they could offer their children and grandchildren an enjoyable setting for their holidays, bringing them further value. In some cases, the departure had caused tension with the children, who had expected them to share in the daily chores. In other cases, they received the Support of their families.” Interview by Benjamin Keller.



In 2019, the UN will publish its  Global Sustainable Development Report (GSDR). Peter Messerli, a geographer and professor of sustainability from Bern, is one of the 15 members of its independent group of scientists, and has been appointed its co-chair. The schedule is tight, and their goals are ambitious – but in compensation, these scientists have the opportunity to exert major influence in the world’s highest-ranking political body. What is the purpose of the Global Sustainable Development Report? At the United Nations Conference on Sustainable Development in Rio in 2012, the member states of the UN decided to intensify knowledge exchange between politics and science. The coming Report is important for implementing and monitoring the development goals in the UN’s 2030 Agenda. But there is no simple magic formula. We have to weigh up carefully the advantages and disadvantages, basing our decisions on facts and knowledge. Only in this manner can we make fair decisions. What is your strategy for managing this Herculean task? We want to divide up the Report into four large areas. The different chapters will first focus on analysing the interdependencies of the sustainability goals in the 2030 Agenda. Secondly, we will deal with the implementation process: What changes are at all possible, and how are we going to approach them? Thirdly, we have to keep our eyes open for new topics that have not yet been considered in the 2030 Agenda. And fourthly? We want to strengthen the voice of science substantially. And we can achieve this. But we have to develop and implement the appropriate methods so that we can find solutions at the interface between research and politics. I see a great need for action here, both in politics and in science. Is this yet another report that’s destined to disappear into desk drawers? No, on the contrary. The voice of science will be represented at the table when the heads of state of all member countries meet at the UN General Assembly in 2019. How did a Swiss citizen land this position? Switzerland is a hotspot for global change research. In our democratic system, we are already living out this exchange between politics, science and the people. This is also why science was represented in the Swiss delegation right from the very start. Interview: This Rutishauser

They illustrate what researchers experience in their work, and show who they are: these are the images, photos and videos that were submitted for the new SNSF competition for scientific images. Some 239 people from all regions of Switzerland took part. In total, 437 images and 60 videos were submitted in the four categories ‘Object of study’, ‘Men and women of science’, ‘Locations and instruments’ and ‘ Video loop’.



In Switzerland, almost two-thirds of adults are overweight, despite broad-based campaigns to counter it. And the trend is upwards. This also means an increased risk of cardiovascular diseases, type 2 diabetes mellitus, and even several types of cancer. Many people try to burn off excess calories by doing sports. But the majority of our less athletic fellow citizens can also get their weight under control by moving more. In order to help them, a group led by Abdul Dulloo, a professor of nutritional physiology at the University of Fribourg, is studying the energy expended during normal activities. “Up to now, most studies have concentrated on intensive activities that require roughly five to 12 times as much energy as lying down or sitting. But in everyday life, we rarely go above four times that level of intensity”. His team’s experiments (see the box ‘Measuring energy consumption’) show that by just standing, we use on average ten percent more energy than when we sit. But they also found that standing only boosts energy consumption to any considerable extent in one out of four people. “In all the activities we’ve measured, people consume very different amounts of energy”, explains Dulloo. And this can’t be explained away just by their age or weight. Even obese people display very different degrees of energy consumption. The researchers tried to find the answers in the different ways people stand. Do people use up more energy when they repeatedly shift their weight from one leg to the other? The answer is disappointingly no. So this also couldn’t explain the differences between individuals. “In order to burn more calories properly, people have to take whole steps”, says Dulloo. Once he and his team have understood these small differences, he hopes that they will be able to individualise strategies to counter excess weight. It is still difficult to reach the right people with national health campaigns, says Sigrid Beer from the Institute of Social and Preventive Medicine at the University of Bern. “Preventive measures have to reach both those members of the population who are not yet affected, and also those who are as yet unaware of the problem”. Only once someone is under treatment today do they start to consider changes to their individual behaviour. If the wrong people go on diets, this could even trigger an increase in weight later on. If people of normal weight reduce their lean body mass, the body counteracts by saving energy and by increasing its energy intake, says Dulloo. It also reduces the level of the hormone leptin, which regulates fat metabolism and indirectly holds back our appetite. At the same time, more and more people are spending eight hours a day sitting in front of their computer screens. “We are experiencing an erosion of our daily physical activity. So we try to compensate by doing sports. But it’s not enough to jog a little and then sit around the whole day”, says Dulloo. J. L. Miles-Chan et al.: Standing economy: does the heterogeneity in the energy cost of posture maintenance reside in differential patterns of spontaneous weight-shifting? European Journal of Applied Physiology (2017)A. G. Dulloo: Collateral fattening: When a deficit in lean body mass drives overeating. Obesity (2017)

To be sure, this is complaining at a high comfort level. And we can really only wish for every scientist and scholar to have a secure job. Nevertheless, it is important to recognise areas of irritation, especially in large, less flexible organisations. The Swiss research elite should thus react to even the smallest signals in their customarily sovereign manner. A sustainable  educational policy means we have to place a very high value on international collaboration, experience abroad, both interdisciplinary and unconventional projects, a high degree of risk tolerance, innovative capacity, a critical discursive culture and a readiness to leave one’s personal comfort zones. What we especially need is the kind of top performers whose careers are founded precisely on these criteria. In order to compete internationally, researchers would do better to orient themselves according to dynamic development processes instead of taking delight in the status quo. And funding bodies should in future also create the necessary incentives to support inconvenient mavericks and those with a special thirst for knowledge and achievement.  Ulf Büntgen has been a professor of environmental systems analysis at the Department of Geography, University of Cambridge, since January 2017. He is also a Senior Scientist at the Swiss Federal Institute for Forest, Snow and Landscape Research (WSL), where he was a researcher for 14 years.

When a mouse encounters a snake, it has to decide in a flash what action offers the best chance of survival. Should it enter into paralytic shock, thereby becoming invisible to the predator, or should it flee as quickly as possible? This decision is not made consciously, but is determined by a multitude of factors – such as the distance between the mouse and the snake, the availability of a get-away route, previous experiences, and the state of health of the mouse. There is a circuit in the brain that is very important for these life-or-death decisions, and it’s located in an almond-shaped area called the ‘amygdala’. “All the information that can influence a behavioural reaction is channelled from the most varied regions of the brain into the amygdala, and processed there”, explains the neuroscientist Andreas Lüthi. He and his working group at the Friedrich Miescher Institute for Biomedical Research in Basel have been investigating what processes then occur in the mouse’s amygdala. Lüthi and his researchers are especially interested in how a decision is made between two completely different forms of behaviour – passive paralytic shock or active flight. In order to find this out, they trained their test animals to fall into paralytic shock when they hear a pure tone, and to display flight behaviour when they hear a mixture of tones. They also used a genetic procedure to alter the behaviour of the different types of nerve cells in the amygdala so that these can be hindered when the mouse is exposed to yellow light. By doing this, the researchers have made it possible to switch off specific groups of nerves and observe what impact it has on the behaviour of the mice. Their experiment demonstrated that two groups of nerve cells control fear behaviour: one group is responsible for triggering paralytic shock, the other for triggering flight. “It seems that there is a switch in the amygdala that can be turned one way or the other”, says Lüthi. Furthermore, the two nerve groups are closely linked with each other. Activating the paralytic shock hinders the flight response and vice versa. This prevents the amygdala from giving the order for two contradictory forms of behaviour to the muscles. “In this case, two types of nerve cells work contrary to each other to trigger a clear all-or-nothing reaction”, explains Fritjof Helmchen, one of the directors of the Institute for Brain Research at the University of Zurich. “This experiment is a perfect example of how you can use new methods to study live, non-sedated animals to find out what components in a circuit of nerve cells determine specific patterns of behaviour”. Helmchen was not involved in the study himself, but he believes that findings from this type of experiment could find applications in human medicine in the coming decades, because many mental illnesses arise from altered circuitry and misdirected information flows in the brain. Lüthi also believes that his results are essentially transferable to humans: “The structure of the amygdala has been largely retained throughout the process of evolution, so it is constructed in the same way in humans as in mice. Anxiety disorders in people often occur because this old system dominates and is very difficult to control consciously”. He also observes that human patterns of behaviour are far more complex and varied: “People often consciously take bigger risks in order to discover new things and perhaps to draw an advantage from it – whereas that would be a poor strategy for a little mouse”. J. Fadok, S. Krabbe, M. Markovic, J. Courtin, C. Xu, L. Massi, P. Botta, K. Bylund, C. Müller, A. Kovacevic, P. Tovote & A. Lüthi: A competitive inhibitory circuit for selection of active and passive fear responses. Nature (2017)

The recipe for highly ranked universities Six new preprint servers online In percent

“The climate stress had weakened the microbial communities in the soil by lowering their ability to absorb nitrogen from their surroundings”, says Nicolas Legay, the main author of the study. Plants too require nitrogen to grow. “As the micro-organisms were suddenly less competitive, the plants found the soil richer and grew better”. The researchers then subjected the plants afresh to drought conditions. Again they produced greater volumes of fodder. “Once more, the microbial communities suffered. But it is only a short-term effect”, Legay adds. The micro-organisms in the soil are indeed highly susceptible to drought, but in the long term, they are also responsible for recycling soil nutrients. “As time goes by, the soil quality can therefore actually decline, and with it will go the overall quantity of fodder produced”. This study is part of a larger European project investigating the impact of moderate agricultural practices (light fertilisation and harvesting) in comparison to intensive farming. For Legay, if the frequency of climate events should increase, traditional farming practices will become difficult to sustain in the absence of soil amendments.  

These two pharmacologists used green fluorescent blood vessels to carry out their tests on zebrafish embryos. Using zebrafish is ethically less problematical than using rodents, which are more highly developed. What’s more, the zebrafish embryos have a fascinating advantage: they are transparent. This means that the research team can observe in a living organism how the nanotransporters – marked with a red fluorescent colour – spread out in the blood vessels. It transpired that even the tiniest differences in their structure had a major impact on their distribution in the organism. It is still extremely difficult today to predict how nanotransporters will behave in an organism. The researchers hope that their tests on zebrafish embryos will enable them to find out how nanotransporters have to be constructed so that they can deliver the biggest possible amount of their ‘cargo’ to sick cells, thereby leaving healthy tissue untouched. “The zebrafish model is intended to help us identify the most promising candidates from a number of different transporters before we embark on a complex series of tests in rodents”, says Witzigmann.  

Malaspinas is 35 years old and is studying how our ancestors populated the planet. In particular, she’s looking at how they left Africa, how they adapted to new environments and at which points in history those events occurred. To bear this out, she is turning to both contemporary and ancient DNA samples held in museums, and analysing them using mathematical and digital models. For example, her team is analysing the hypothesis of transpacific contact between Polynesia and the Americas. This is the project that has led her to take ancient DNA samples from Easter Island. For another project, she travelled to South America in response to a phone call from a researcher at the National Museum in Rio de Janeiro, Brazil. Her correspondent had been studying human remains there and had noted that the genome of certain individuals from a local population, which had lived some several centuries before, was entirely Polynesian. Malaspinas was born in Geneva and grew up with three siblings and her parents: a physicist father and a Greek artist mother. When she was 17, she spent three months in Crete with her godfather, a chemist at the University of Heraklion. “I would go to his laboratory, asking questions. I was fascinated by the freedom of his work: spending months thinking about one question, discussing ideas, experimenting, beginning again. I realised it was what I wanted to do”. She thought about studying law or literature, but decided to go for medicine. She did not, however, meet the enrolment deadline and had to settle for biology and physics, which she studied simultaneously. During a class on evolution, she had a “life-changing moment”, at which point she realised she wanted to study population genetics. In the name of love, she set her bearings for California, where she began a Ph.D. at the prestigious University of Berkeley. “I wasn’t afraid and I didn’t delay. I just threw my swimming costumes in a suitcase and left – thinking that Berkeley was closer to Los Angeles than to San Francisco!”. She returned to Switzerland in 2015 after having also spent time in Denmark. Malaspinas describes her professional career as if she’d just had a long streak of good luck and owed her current position to her fairy godmother. Her postdoctoral supervisor in Copenhagen, Eske Willerslev, sees things differently: “She’s built her career on the basis of a brilliant intelligence and an enormous work ethic”. At the University of Bern, the specialist in population genetics Laurent Excoffier applauds her capacity to link theoretical studies and empirical data. “She’s one of those rare people who can not only develop and implement models but also collect and analyse the samples she’s taken on the ground so as to verify her theories”. The play is set in a museum, where a group of visitors is guided by a young scientist who introduces her work on DNA. The audience is taken on a journey starting with humans leaving Africa and ending on arrival in Australia, where they encounter aboriginal populations. “We wanted to show that science careers are fun. But at the same time, we want to publicise our work, to explain how the genome contains the history of our ancestors and to underscore that we are all relatives and all migrants. In this way, we hope to draw people’s attention to the fate of indigenous populations”. This is another way to give back to society.

Every year, doctors all over the world implant more than a million cardiac pacemakers. It’s a routine operation, but five to ten years later, the tiny device needs a new battery. And with every new operation comes the risk of complications. For this reason, the biomedical engineer Adrian Zurbuchen is working on an autonomous pacemaker that could work without any battery. In order to push six litres of blood through the body every minute, the heart has a pump capacity of roughly one watt. A pacemaker by contrast requires only five to ten microwatts, thus only a fraction of the energy produced by the muscle. In an in-vivo experiment with pigs, Zurbuchen and his team managed to produce 1.7 microwatts of power at 160 heartbeats per minute. That would not be sufficient, but Zurbuchen has run a simulation and calculated the parameters of the harvester that would have to be altered in order for it to run on the energy available. Alexandra Bröhm

When you think about the animals that suffer for science in the laboratory, you get a queasy feeling in your stomach. No one carries out animal tests for the fun of it. But the knowledge gained from them has time and again resulted in medical progress – also in the veterinary sciences. Legislators have also taken into account the ethical dilemma that arises when weighing up the possible benefits for humankind against the suffering of the animals themselves: according to the law, animal tests are “to be limited to that which is strictly indispensable”.





Today’s world is increasingly dominated by emotions, slogans and imagery. Those who use factual argumentation are struggling to punch at their weight. For Tom Nichols, prosperity is at fault: as steeped in abundance as we are, we tend to forget that the basis for our health and comfort is not opinion, but fact. But giving up is hardly an option. When addressing society’s woes, experts must double-down on common-sense and even-handedness. To be heard above the raucous citizens, they must avoid the many pitfalls that end in antagonism, such as impatience, paternalism and hyper-factuality. Courage must also be sought to undertake the effective strategies of marketing and communication sciences: aim to understand before being understood, show empathy, know when to step aside. For some time now, sociologists have been telling us that ideas are only accepted when communicated by the trustworthy. In the light of the current erosion of scientific authority, individual experts stand virtually no chance. The smart way forward, therefore, is to listen to the advice of communications professionals: analyse the target audience, identify the key stakeholders and focus on them. Scientists tend to keep their noses to the grindstone, but such dedication can be counter-productive when it comes to crossing swords with wary citizens. There’s little place for modesty in academia. It is, however, an essential tool for convincing the most sceptical. Daniel Saraga, Editor in chief

When kids count on their fingers, it’s not just as a stopgap because they can’t do it in their heads alone. “Counting on your fingers is in fact an achievement that not all of them can manage initially”, says Thevenot. “The kids first have to comprehend that fingers can signify numbers”. But whoever uses just their fingers for addition won’t get very far, because it all stops at the number ten. That’s why cleverer kids soon change their strategy. They make a mental note of the bigger number, then count upwards by using as many fingers as are necessary to add the smaller number. This doesn’t help for long either, of course. When the numbers go even higher, then the fingers once again cease to do their job. At UNIL, Thevenot is continuing her observations on the development of child subjects, and anticipates that the cleverer ones will refrain from using their fingers by the age of about eight, while the others will stick with it a little longer.

Cooperative machines work side by side with humans on the factory floor, robots care for patients in retirement homes, and they weed crops for farmers. Artificial intelligence is increasingly coming into direct contact with people. And accidents occur on a regular basis. For example, in 2015, a robot crushed a worker to death in a VW factory in Germany. And several people have already died in crashes with self-driving cars. “That’s just the beginning”, says Nora Markwalder, an assistant professor at the Law School of the University of St. Gallen, who is researching into new technologies and criminal law. Autonomous systems are getting more independent and entering into ever more spheres of our lives. This raises legal questions. Who is to blame if a robot nurse lets an elderly person fall, if a police robot beats up a passer-by so badly he’s hospitalised, or if a chatbot instigates a murder? “But if that becomes the case in future, it would be entirely reasonable to hold a robot criminally responsible”, says Markwalder. Not necessarily with the goal of getting the machine to mend its ways. In her opinion, punishment should rather aim to stabilise currently valid norms. That means demonstrating to society that no one is allowed to kill and go unpunished, not even a robot. Markwalder and Simmler have also given thought to the type of punishment that could be imposed. It would have to be something that hurts the machine. “Of course, these are not the same things as with people”, says Markwalder. Instead of sending the robot to prison, for example, you could restrict its computing capacity. Or send it to the scrap heap as a kind of death sentence. “But that’s all still in the realm of science fiction”, admits Markwalder. Nevertheless, she thinks it’s important that we engage in good time with difficulties that could arise sooner or later.

In February 2016, an announcement echoed right across the globe: the American LIGO project had confirmed its detection of the gravitational waves created by the fusion of two black holes, more than a billion light-years away. Since then, five similar observations have been made, confirming that these phenomena are observable with highly sensitive instruments. A new discipline was born: gravitational astronomy. At EPFL, Daniel Figueroa now wants to see if this approach could provide answers to a literally primordial question: is it possible to ‘see’ what happened during the first few moments after the Big Bang? “Since gravitational waves are not hindered by matter, they could have propagated throughout the Universe since it began”, he says. If so, today they would make up a kind of uniform background that would be perfectly similar for all observers, wherever they are in the Universe. This hypothesis is based on solid foundations, says Rainer Weiss, a researcher at MIT and 2017 Nobel Laureate in Physics for his work in this field. Especially with regard to the so-called inflationary epoch, when the expansion of the Universe was at its fastest. “Of course, many renowned cosmologists have developed models of inflation that defy gravitational wave emissions”, he says. “But that doesn’t make this question any less interesting, on the contrary”. But these are still theoretical models. Confirming or rejecting them will involve actual observations. Specialists are therefore eagerly awaiting the commissioning of the unique LISA space observatory set for 2034. It will be composed of three laser-beam reflecting satellites situated 2.5 million kilometres apart. Together they will be able to detect minute variations in distance (about 10 picometres, the diameter of an atom) and thus gravitational waves of a type different from those observed until now. According to Weiss, however, many theoretical models predict that the gravitational waves from the Big Bang may not be strong enough to be detectable by LISA. “Many of us think that we will have to wait for a more sensitive instrument to measure them directly. But there are some ideas about increased energy densities at the end of the inflationary epoch that would be just powerful enough for LISA. Anyway: whether we detect them or not, it could inform our thinking on the unification of quantum theories and gravitation, which is one of the biggest questions in physics”. Enough to project us even closer to our origin, 13.8 billion years ago.

A homage to the colliery: Andreas Gursky’s installation of mineworkers’ clothing and equipment, which they used to hang up to dry in the ‘Bergwerk Ost’ colliery in Hamm (Germany), now abandoned. | Image: Andreas Gursky/Pro Litteris, Bonn 2018, Courtesy Sprüth Magers.





Research has gone global. Finding solutions to problems in developing nations today also means tackling global issues that have an impact on the West, such as climate change and migration. The success of this research will depend on the ability of northern and southern institutions to work together efficiently. “Research capacity in the South has been strengthened over the past 15 years”, says Gilles Carbonnier of the Graduate Institute of International and Development Studies in Geneva. Countries like Ghana, Indonesia, Peru, South Africa and many others in the Global South have grown richer, while traditional divides are shifting between the developed and the developing, rich and poor. The international research landscape is changing too. But inequality still exists at many levels: “In research partnerships we sense the same tensions that are typically embedded in donor-recipient relations in international development cooperation: donors tend to seek to impose their ideas and conditions”, says Carbonnier. The key questions here are: who decides what research projects are to be realised, and who is to benefit from the results? How will those benefits be disseminated, and how can cooperation in a given social system be increased? And finally: who should decide where the money goes? Deep-seated habits and old, established power relations still play a role in international partnerships, says Carbonnier: “Building fair research partnerships consumes time and resources. There is real pressure to publish research outcomes fast in peer-reviewed – Anglo-Saxon – journals edited in the North. And there is harsh competition for funding”. The existing tensions between the drive to recognise academic excellence and achieving longer-term, capacity-building objectives are at the heart of the North-South research partnership debate. “There is increasing pressure from the partners in the South to engage in fair research partnerships. It is crucial to give greater space to locally produced knowledge and a greater variety of ‘knowledge ecologies’ – and to accept that contextualisation may lead to outcomes that don’t always conform to standard expectations in the north”. Most research in a north-south context contains policy-relevant components, says Laurent Goetschel of the University of Basel, who is president of the Swiss Commission for Research Partnerships with Developing Countries of the Swiss Academy of Sciences. One of the challenges is to get research partnerships functioning despite divergent socio-political and economic contexts. The first question is crucial: who sets the agenda and decides what research should be done? For many years, the decision has been made mostly by the research funders, says Benjamin Apraku Gyampoh, Programme Manager at the Nairobi-based African Academy of Sciences (AAS). For him, research partnerships have biased donor-recipient relations that plague international development cooperation. “There is the infamously wrong perception that the one with the money has all the wisdom and knows how best to use the money”. One may have the funds and good intentions, but might not understand the context within which the recipient is working, and might not be willing to learn about the recipient’s environment. “Research partners – funders and recipients – must learn from each other about how to develop, retool and facilitate systems”, he adds. In agricultural research cooperation, it should be the farmers who determine the area of research for funding bodies, says Professor Ngozi Ifeoma Odiaka of the University of Agriculture in Makurdi, Nigeria. In 2015 the AAS established the Alliance for Accelerating Excellence in Science in Africa, which is funded by institutions such as the UK’s Department for International Development, the Wellcome Trust and the Bill and Melinda Gates Foundation. According to Gyampoh, these funders agree on the need to shift the centre of research decisions and funding from Europe and America to Africa. The person who is responsible to a donor for a project also needs to have decision-making powers, says Goetschel: “Ideally, this would be a joint responsibility of southern and northern researchers towards a joint funding agency, or of each partner towards his/her funding agency”. In practice, however, most of the funding comes from the Global North, so the final decision-making power lies with the Northern partner. Nevertheless, within the governance of a partnership project, rules may and should be developed to assure the Southern partners of the possibility of making joint decisions. Another challenge is quantifying the resources invested by recipient organisations whose input goes beyond financing, adds Gympoh. For instance, office space, utilities, salaries and staff benefits are provided to research institutions by African governments, but these are difficult to quantify as research ‘input’. As a consequence, funders can get the impression that their partner is contributing nothing, and this can affect their relationship. Gyampoh believes it is possible to conduct fair research if it is based on the right kind of relationships and partnerships. Funding bodies and researchers on the spot should not wait until after submitting a proposal before engaging in dialogue, but should begin long before this if fair research is to come about. Who is to take the credit for research outcomes achieved jointly by scientists from the Global North and South? This has been a source of some discontent, with scientists from the South feeling that they are doing all the ‘donkey work’ while the funding and oversight organisations give all the credit to their Northern collaborators. But the benefit to be derived from research results depends on how those involved define it. To the funder it can mean being acknowledged for providing the money, while for the researcher the benefit can come from publishing the results. To the general community, there can be concrete interventions resulting from the research findings, says Gyampoh. Data obtained from shared research should belong to all the researchers involved, and made accessible to others on open access as soon as possible, says Goetschel. But sharing this knowledge depends on the kind of results obtained: “Certain types of results are very complex and should be available mainly to the research community”, he says. The Bill and Melinda Gates Foundation is part of the Global Grand Challenges partnership network, which aims to solve some of the most pressing challenges in health and development. “All their grantees and partners must commit to making their research outputs widely available at an affordable price, in sufficient quantity and in a timeframe that provides real and meaningful benefit to those who need it most”, says Ayo Ajayi, the director of the Africa Team leading the Gates Foundation’s work on policy, advocacy and government relations across Africa. “We continually collect and share data on our progress, reflect on lessons learned, and make course corrections as needed, through ongoing dialogue with our grantees and partners”. Published research resulting from their funding is to be promptly and broadly disseminated. They have adopted an open-access policy that enables unrestricted access and re-use of all peer-reviewed, published research that has been funded in whole or in part by the Foundation, including any underlying data sets. Gyampoh emphasises that research data belongs to everyone. “In fair research, issues of intellectual property must be addressed humanely and with an understanding that what is being done is for the good of all”, he says. “Permission should be granted to anyone who wants to use the data ethically for the benefit of humankind. Of course, there must be an acknowledgement of who and what made it possible for the data to become available”. At the University of Agriculture in Makurdi, Odiaka notes that in terms of publicity, most research is published in peer-reviewed journals or in conference proceedings, which limits the scope of dissemination to those who have access to them, or to the few who attend conferences. Sharing both publications and research data is now also a matter of discussion. In order to apply for IDRC grants, researchers from Canada and developing countries need to come together to develop Joint proposals – whether based on existing collaborations or created from scratch, explains Lefebvre. To set up a collaboration on an equal footing, IDRC requires two programme leads: one in Canada and the other in the developing country. Each lead is responsible for his or her own budget, which ensures equality among the lead researchers. Creating equal partnerships is in the interest of funders and researchers alike. Otherwise, they risk the law courts doing it for them. On 18 July 2014, a landmark ruling by Kenya’s industrial court awarded six Kenyan doctors a total of 30 million Kenyan shillings (USD 341,000) in compensation for careers held back by “institutional racism” in a UK-Kenyan medical research partnership. The doctors, said the court, had faced “systemic discrimination” while working for the Kenya Medical Research Institute – Wellcome Trust Research Programme in Kenya’s Kilifi. According to the ruling, the six were passed over for promotions and grants while they were working for the programme, which was run in partnership with the University of Oxford. Their lives were disrupted “in terms of career development, contribution to scientific outcomes to the country and in terms of ability to get alternative employment and academic scholarships”. The solution for the future might be found in the past. As Gilles Carbonnier and Tiina Kontinen state in their 2014 EADI Policy Paper ‘Academia Meets Development?’: “Past experiences can help new actors to avoid falling into the old bias and traps well-known to those who have been active in this field [North-South cooperation] over the past decades”. Ochieng’ Ogodo is Sub-Saharan African English Edition Regional Coordinator and News Editor at SciDev.net, a non-profit organisation headquartered in London that publishes news and analysis on science and technology for global development. He is based in Nairobi.

What’s the aim of your association? We want to define the technical standards that will allow the air-traffic management of manned and unmanned aircraft. The focus is on professional and commercial journeys measured in tens of kilometres and that may involve air space in two countries. What are you working on exactly? It’s an extremely complex field with many different actors involved. First we are going to publish an overview of the ecosystem and the challenges to be overcome. Then we’ll look at things like drone identification: what format will the identifier take? How is it registered and communicated? The aims are sky security on the one hand, and technical interoperability on the other. How do you set yourselves apart from the giant American association AUVSI?  AUVSI grew from the military use of drones, and is principally a lobby. We are an industrial association: we are about growing the market through the introduction of technical solutions that meet legislative requirements, not about influencing them. It’s a niche and we are the only ones working on it. If not, we’d have never got started! Have you reached the critical mass needed for defining standards?  We’re on the right path: we’ve gone from 15 to 40 members in the space of six months. We have brought together the leading manufacturers of drones and communications systems, the suppliers of the data necessary for navigation, such as weather and map data, and the air controllers and representatives of various governments. We’re very decentralised: the regulators come with their requests, manufacturers discuss possible technical solutions, and we try to find a consensus on what is feasible. Why did you choose Lausanne? Because there are a number of drone startups there, not to mention NCCR Robotics, which is led by EPFL. For our foreign members, Switzerland is tiny. They can visit Lausanne as readily as they can Zurich.

Artificial intelligence can already win at poker games, commentate on sports matches and create works of art. Nothing is holding it back in the fields of science either. It’s enabling linguists to unravel text corpora, physicists to conjure up new materials, and biochemists to orchestrate hundreds of experiments on the double. It’s become so creative there are now prototypes capable of transforming observations into original hypotheses. Faced with this, we must continue to chart a course based on sound epistemology. We’ve seen how computer-generated mathematical proofs supersede our individual abilities to read, verify or even understand them. In principle, the average algorithm proceeds using relatively simple steps; in practice, however, matters are quickly complicated. Results are spewed out in such volumes that it’s humanly impossible to follow their ‘reasoning’, stripping us of all but blind faith. And what use is an opaque result that we don’t understand anyway? Furthermore, is science the sum of its results or the sum of its methods? According to the physicist Richard Feynmann, science is an attitude. “It’s a kind of scientific integrity, [...] – a kind of leaning over backwards. For example, if you’re doing an experiment, you should report everything that you think might make it invalid”. It’d be naïve to leave this key step to a computer program. Given that robot researchers are here to stay, we should seize the opportunity instead to spurn algorithmic reasoning. After all, humans’ strength is discursive, counterfactual thought. Even unconventional thinking has its place. Let’s be frank, there’s no comparison between the very soul of science and a pipette-wielding robotic arm. Daniel Saraga, chief editor

At today’s rate of data creation, existing systems will soon reach capacity. This is leading people to start questioning Moore’s law, which says that the number of transistors that can be squeezed onto a given electronic chip doubles every 18 months. “The current path of miniaturisation” says Christopher Lutz, a physicist at IBM in Amalden, USA, “suggests that there would be, in principle, some 20 intermediate steps before arriving at the atom. This would require a further 30 to 40 years”. Yet it appears we’ve arrived at this final step in a single stride, a landmark in what is a booming research field. In 2016 teams led by Pietro Gambardella at ETH Zurich and by Harald Brune at EPFL showed that holmium atoms – a group of rare earth metals – could, on a certain surface, display a form of ‘magnetic remanence’. On the basis that what can be magnetised can be used to store data, all that remained was to demonstrate the ability to read and write using the individual atoms. This is exactly what has been done by IBM’s Lutz and Fabian Natterer, a member of Brune’s team. It’s possible to write data to an atom, so long as it’s possible to orient the atom’s magnetisation in one direction or another, such as up or down. This is the same method used in hard disks, which record data encoded in binary bits (zeros and ones). “We used a scanning tunnelling microscope”, says Natterer. This instrument has a minute tip which scans a material’s surface, characterising each part of it with atomic precision. The tip is composed of an iridium atom and it emits a polarised electric current. This current is actually strong enough to change the magnetisation of holmium atoms and thereby to record a bit. “The effect is long-lasting”, says Lutz. Reading back the information can be done using one of two methods, Lutz adds. “The first also uses an electric current, which meets greater or lesser resistance depending on the magnetic state of the holmium atom, making it possible to distinguish the data recorded there”. This is more or less what is done currently with hard disks, adds Natterer. “The second method is done remotely, by detecting the magnetic field of the holmium atom”, says Lutz. This is still currently a laboratory technique with very considerable restrictions. “It only works in a vacuum below 4 Kelvin  (–269° C)”, says Lutz. “The system is also very sensitive, because holmium atoms can move around on the surface”, adds Gambardella. However, they are also looking into other ways of recording data on atomic matter. Another approach is to magnetise molecules. “We are using a compound of dysprosium (Dy), which is another rare-earth element”, says Florian Allouche, a chemist at ETH Zurich. “A priori, this molecule does not have a memory effect. Yet at low temperatures it can achieve magnetic remanence after having been grafted onto silica and treated chemically to create dysprosium ions (electrically charged atoms) which can later be applied to a surface”. According to Allouche, there are both advantages and disadvantages to this technique. On the one hand, “the molecules are simple to prepare and to characterise and could be replicated on other surfaces”, but on the other hand, “we have yet to find a way to define precisely the structure for the magnetic sites”. Where the scientists do agree is that current data storage won’t be replaced by atomic data storage just yet. “But the proof of concept is there”, states Lutz. And according to Natterer, “the discovery will allow us to study matter at the atomic level. And through the control of magnetism at that scale, we may even create exotic materials”. Gambardella sees this research being applied to quantum computing. Lutz thinks that “our work is about doing as much good for the future as possible”. F. D. Natterer et al.: Reading and writing single-atom magnets. Nature (2017)F. Allouche et al.: Magnetic Memory from Site Isolated Dy(III) on Silica Materials. ACS Central Science (2017)

We’ve all got used to our computers getting ever quicker. But this development is now coming up against physical limitations. This is because of the current way in which computers are constructed, explains Yusuf Leblebici of EPFL in Lausanne. Processors and memory are separate units in the classical von Neumann computer architecture, and the connection between them is increasingly becoming a bottleneck: “If the processors work at high speed, it becomes more difficult to transfer the data quickly enough between memory and processor”. The solution could lie in new structures for computer chips. New electronic components could play a role here. Researchers like Leblebici are taking biological nerve cells as their models. They want to develop neuromorphic chips whose electronic construction is like a network of nerve cells. The advantage of this is that computational and storage activities are much more closely interlinked. Essentially, neuromorphic chips can be built with conventional electronic components – the Truenorth chip of IBM is based on this principle, for example. It digitally imitates the characteristics of nerve cells. Leblebici is pursuing a different possibility, employing new components called memristors. Put simply, these are electrical resistors that remember the electric currents that have previously flowed through them. This is similar to the learning ability of nerve cells in the brain. In the coming years, Leblebici will be developing several prototypes of neuromorphic chips in a collaborative project with IBM and the Institute of Neuroinformatics at the University of Zurich. He and his colleagues are proceeding on three levels. In one part of the project, they are constructing new memristors; in a second they are making circuits based on these components, such as coupling them with sensors; and a third group is busy integrating them into a total system. In this manner, Lebleb ici hopes that they will be able to carry out video recognition with one of the prototypes in just a few years. The main advantage of chips built from memristors is their high surface density, explains Leblebici. Individual computational functions can be carried out on a hundredth of the surface of conventional chips. The price of this is a reduction in computational accuracy. Memristor chips cannot deliver results precisely to a large number of decimal places. But many other tasks require an extremely high velocity to process huge amounts of data, and one or another small error is of little consequence in such cases. Typical examples are the recognition and analysis of audio data, photos and videos. The eye won’t complain if an individual pixel has the wrong colour. All microelectronics companies are very interested in ideas for neuromorphic chips, says Markus Kubicek from the Technical University of Vienna. Three years ago, he made the headlines with an article on the mechanisms that could one day replace flash memory. He wrote it at ETH Zurich together with Jennifer Rupp. There is a fundamental difference between memristors and classical silicon transistors, explains Kubicek. Unlike transistors, memristors often don’t recognise the states of 0 and 1, but also something between them. This is a characteristic that doesn’t just enable them to learn, but can also be used to realise ‘fuzzy logic’ – a variant of logic that allows for unclear statements. According to Kubicek, it’s still anybody’s guess whether chips using memristors will prevail, or neuromorphic constructions using more conventional components. There are in fact many different types of memristors. Kubicek usually uses oxides for them, such as titanium or strontium oxide. Their operating principle is founded in oxygen defects. Other groups use metal filaments, for example. Memristors could also be made with an even higher density than up to now. To achieve this, researchers would have to realise a three-dimensional architecture – and thereby pile up the memristors one on another, so to speak. Such constructions could accommodate ‘deep learning’, says Leblebici, which is important in the development of artificial intelligence. It is often suggested that chips using memristors could use much less electricity than conventional chips. But Leblebici wants to curb such optimism a little. “You mustn’t forget that memristors need electronic circuitry on their periphery, too”, he says. And this circuitry needs extra electricity. The biggest challenge in developing memristors is very different, says Kubicek. It’s their lack of durability. From a technical standpoint, they need to remain stable over more than a billion cycles. Sometimes even more than a thousand billion. “Most memristors today can’t yet manage that”, he says. But that could change. The production process of memristors is still too diverse for industrial applications, says Christian Mayr of the Technical University of Dresden. He is also researching into neuromorphic structures. “Several production steps are necessary to manufacture memristors”, he explains. “That’s a problem. Manufacturers of semiconductors dislike every extra step in production because it leads to increased costs”. Mayr believes that there are promising applications for memristors in the field of neuroprosthetics and other, similar interfaces between computers and biology. Mayr was experimenting with such systems during a research visit to Zurich from 2013 to 2015. Other interesting applications are opening up in information compression. The human eye is capable of reducing information density by a factor of 100 before the visual signal is sent to the brain, says Mayr. Perhaps neuromorphic chips will be able to do something similar in future. Whether this will involve memristors or not still remains an open question.

Camels are indispensable pack animals in the desert. But these well-loved creatures have become an unpredictable threat to humans on account of the dangerous viruses they carry. Their airways harbour coronaviruses that can provoke fatal pneumonia in people. Since the first cases of Middle East Respiratory Syndrome (MERS) were registered in the summer of 2012, a total of 1,641 people had been infected in Saudi Arabia with the coronavirus up to June 2017. Forty-one percent of them have died. When a disease can be passed from animals to humans, it’s a phenomenon known as zoonosis. “This coronavirus is a typical zoonosis, such as we have repeatedly observed in recent years”, says Volker Thiel, professor for virology at the University of Bern and Head of Virology at the Swiss Federal Institute of Virology and Immunology (IVI). Many pathogens often circulate inconspicuously in animals that they do not affect. Occasionally, a chance leap across the species barrier can occur – such as into humans. The reactions can be violent, and in the worst cases, deadly to the new host. Ebola, SARS, MERS and Zika are the last cases in a long series of zoonoses. Rabies, the plague, AIDS and bird flu testify to earlier occurrences. Volker Thiel was very much in demand in the winter of 2002 when serious cases of the new lung infection called ‘Severe acquired respiratory syndrome’ (SARS) occurred in southern China. He was one of the first to receive and sequence viral isolates from patients. Within a short space of time, epidemiologists were able to identify a coronavirus as the pathogen. By comparing it with the genome of harmless viruses, researchers were able to find the mutations that had been necessary for it to cross the species barrier into humans. “It needs surface molecules that can bind themselves firmly to the docking sites on human lung cells”, says Thiel. They also found out how the virus was able to mitigate signals from the immune system. “In a blood sample, whether from animals or humans, there are thousands of individual viruses that are all slightly different from each other”, says Thiel. This high mutation rate creates many variants, which increases the chance that one of them will be able cross the species barrier to attack a new host. On the other hand, this variability explains a phenomenon that can often be observed: after the initial intense infections, the virus stops adapting, because it cannot proliferate if it kills its host. “We were able to observe this weakening in outbreaks of SARS and also of Ebola”, says Thiel. In the case of SARS, the coronaviruses most likely jumped from mongooses to humans – presumably when these animals were slaughtered; they are regarded as a delicacy. Coronaviruses circulate in many animals, though primarily in bats and rodents, as an international team of researchers under Simon Anthony recently proved at Columbia University in New York. Teams in 20 countries in Latin America, Africa and Asia investigated bats, rodents and apes in a study lasting several years. They analysed tissue samples for viral genetic material, and found coronaviruses in ten percent of the bats they examined; in rodents and apes it was less than one percent. The diversity of the coronaviruses was also by far the greatest in the bats. “Bats are the most important reservoir for coronaviruses”, Anthony concludes. One reason for this lies in the robust immune system of bats, which can keep their viral tenants in check. Another reason can be found in the large-scale social communities in which up to several million animals can live in close contact with each other. This facilitates the exchange of viruses. Furthermore, the bat species is extraordinarily large and varied. When humans enter regions they have never inhabited, such as the rainforests of Africa and South-East Asia, viruses are given a new opportunity to spread. Colds from camels Extensive specimen collections from the jungles of Central Africa have shown that fruit bats are the origin of the highly dangerous Ebola virus. We know that SARS and MERS also come from bats, because almost identical viruses have been found in these animals. “We assume that the MERS virus jumped from bats to camels at some point in the past, and that it has meanwhile established itself in its new host”, says Thiel. From there, it now regularly jumps across to the humans who live near the animals. Thiel and his team have been able to show that the MERS coronavirus also displays surface molecules that can bind themselves easily to lung cells. Such changes of host, from camels to humans, obviously already took place in the distant past, hundreds of years ago. In collaboration with the renowned virologist and co-discoverer of the SARS virus, Christian Drosten in Berlin, Volker Thiel recently found coronaviruses in camels that are closely related to one of the cold viruses found today in humans. It is logical to assume that this virus also caused deadly infections at the time it first took humans as its host, and that it weakened over the course of time. Comparisons between the coronavirus in camels and the cold virus in humans have provided initial information about the steps involved in the process of genetic adaptation. “We can see differences in the genome, but don’t yet understand their meaning”, says Thiel. Bats are by no means the only bearers of highly dangerous pathogens. Extremely hazardous strains regularly occur in an exchange between pigs, birds and humans. This is why new influenza pathogens from pigs (H1N1) and waterfowl (H5N1) are being closely monitored by virologists. Christian Griot, Director of the Swiss Federal Institute of Virology and Immunology, sees these influenza viruses as presenting the biggest risk at present. Such a virus could spread across the world in a very short space of time. This is not yet the case with the coronavirus that causes MERS. But that may change. Every new human infection offers the virus another opportunity to adapt itself better and to infect the upper respiratory tract, which it at present finds difficult. “If it were to spread more easily from one human to another, then we would have reason to fear a worldwide pandemic with very many victims”, says Volker Thiel. And it is getting more and more difficult to prevent outbreaks. Meanwhile, the MERS virus has established itself firmly in the camel population on the Arabian Peninsula. These proud ships of the desert are now a ticking time bomb. E. Kindler et al.: Early endonuclease-mediated evasion of RNA sensing ensures efficient coronavirus replication. EPLoS Pathog (2017)V. M. Corman et al.: Link of a ubiquitous human coronavirus to dromedary camels. PNAS (2016)



The first chipset focuses on pure processing speed, the second on saving energy. According to Andreas Burg, the director of EPFL’s Telecommunication Circuits Laboratory (TCL) and lead researcher, this technology is crucial, as polar codes will be able to regulate the amount of redundancy needed on the fly. In other words, when there’s few gaps in the data signals being received, the number of redundant signals will be reduced and the speed of transmission increased. Consequently, there’s also a reduction in the need for processing on the device and hence also energy. All of which means better battery life. “The protocols in our devices today have been upgraded constantly for more than twenty years, but polar codes already match the performance of their predecessors with a year still to go before going industrial”, says Burg. “But then, they’ll also be upgraded for the twenty years to come before reaching their full potential”.  

This polymer has up to now been used primarily in technological fields, such as in manufacturing biosensors or solar cells. It has a big advantage because it can conduct electricity. For several decades now, we’ve also known that bones heal better when they are stimulated by electricity. In her experiment, she and her team carried out observations over 28 days, monitoring the activity of the genes in mice that create the calcium deposits necessary for making bones. They wanted to see whether precursor cells would develop into mature bone cells. They also analysed both the electrical conductivity of the polymer and its consistency, to ensure that the cells could actually enter into it. “We were able to show that bone cells grow well on PEDOT:PSS”, says Guex. Nevertheless, she warns against excessive expectations, insisting that clinical applications are still a long way off. “Our study provides an initial, hopeful basis”. As a next step, she proposes testing the application on human stem cells and optimising laboratory conditions.  

People have always experimented on themselves. Across civilisations, humans have long tried out different foods and diets, plants with medicinal properties, ways of living, rituals, etc. Exploring and understanding the world initially depended on self-experimentation – and rather heavily, too. As knowledge production became more organised and professional, scientific norms and standards emerged that enclosed most experiments within institutional boundaries. Even in such settings, however, researchers continued to self-experiment. The history of science is studded with anecdotes and recorded cases of researchers testing their ideas, theories and devices on themselves first. Biomedicine in particular offers several fascinating examples including that of Barry Marshall, who ingested helicobacter pylori bacteria to test his hypothesis that they caused ulcers. Eventually Marshall and his colleague Robin Warren were awarded the 2005 Nobel Prize in physiology and medicine for their discovery. To be sure, not every attempt at self-experimentation is guaranteed such a glorious outcome. What’s more, such experiments can be harmful to those who undertake them. We are not at ease with a high risk of self-harm, and in many areas of life we try to avoid and prevent this. So, is the risk of self-harm sufficient to justify prohibiting self-experimentation? A general ban on self-experimentation would be unjustified; it would also be largely unenforceable. As autonomous competent agents, individuals are entitled to take risks, provided that they do not conduct illegal activities. People choose to pursue extreme sports, for example, which requires excessive, potentially harmful training and entails the risk of lethal accidents. While most of us would rather not take such risks, we should not be in a position to dictate to others a degree of risk that they may or may not take, especially when the purpose of their action is highly valued. We rely on safety standards, training, information and other means to help people make better decisions about risk when they wish to pursue valuable goals. Setting limits on individual freedoms requires a strong justification. For example, there might be forms of self-experimentation that can be ethically problematic, such as experiments that may cause harm to others – the use of an infectious agent, for example. Typically, access to such agents is regulated and controlled in similar ways as with other hazardous products. Devices and technologies that require safety standards and qualified users are also regulated through assorted consumer protection measures and other mechanisms. Existing prohibitions of harmful compounds on the grounds of public risk inevitably curb the most worrisome forms of self-experimentation. Today, with increasing access to online information, the popularity of citizen science and bio-hacking, and the emergence of movements such as the quantified self, people are being presented with more opportunities to experiment on themselves. Communities of self-experimenters weigh up the risks and benefits, and have begun setting standards of ethical conduct for their experiments. If national legislators consider regulatory action against self-experimentation, it is important, beyond considerations of possible harm, that they take into account the social value of self-experimentation as an expression of our freedom to pursue valuable goals.

Hubert Filser writes regularly for the Süddeutsche Zeitung and lives in Munich.

The latest heroes of the sports world aren’t wearing football boots or swinging tennis rackets. They’re sat in front of a PC screen, steering game characters through a virtual world with intense concentration and at high speed. Competitions between different e-sports teams today fill huge halls and promise prize money running into the millions. The many hours spent in front of a PC screen can be rewarded with huge cash sums for elite professional gamers. For pilots, too, it’s well known that having played video games has a positive impact on skills. Much of pilot training takes place in simulators that are not fundamentally different from the ones on PCs at home. And there’s even a completely new profession where the skills learnt from gaming can be transferred one-to-one. Drone pilots control their unmanned planes all over the world via computer screens – with the important difference that their drones don’t fly over imagined landscapes, but in the real world. One typical research approach is to compare people who play regularly with those who have no experience of action video games. However, this kind of experiment risks being skewed by unknown factors. For example, it might happen that people with better visual perception actually have a preference for playing video games, and do so more often. This is why researchers also carry out experiments under controlled conditions. To this end, they seek out test subjects without any experience of video games and divide them up into two groups. One group plays an action game such as Call of Duty, perhaps for 50 hours in total, divided up over 12 weeks. The other group spends the same amount of time playing a simulation game such as Sims, which has no action elements. The test subjects then sit standardised cognitive tests both before and after the 12 weeks, and the results of the two groups are compared. With the help of such experiments, Bavelier and her colleagues have discovered that a whole series of abilities are developed by the players of the action games. The effects were noticeable across all levels of cognition – from simple perception to complex mental processes. The players of the action games were better able to differentiate between different shades of grey, and were able to keep more moving objects in view on the edge of their visual field. They were able to process information quicker and had shorter reaction times, and they scored better results even when it was a matter of making decisions and solving problems. They were also able to switch quicker between two tasks or carry out several tasks at the same time. Bavelier believes that the common reason for these positive effects is selective attention – in other words, the ability to concentrate on one task despite a multitude of information and impressions; this entails shutting out anything that is not essential. Another important finding is that the abilities learnt in action games can be transferred to real situations. For this reason, Bavelier is convinced that this provides people with an advantage in the new world of work: “Ultimately, just about everything we do in the 21st century is based on our interaction with computers”. The US Army scored a jackpot with its first-person-shooter video game ‘America’s Army’, in which the player proceeds through the training programme of a US soldier and has to fulfil missions that are close to reality. The idea was to convey a realistic picture of the army, and thereby find suitable new recruits, both male and female. The great success of the game means that it today also serves for schooling and practice purposes. Not every company can pay out a two-digit million-dollar sum for a tailor-made video game, but even simple puzzle games or simulations can increase our productivity, say Edery and Mollick, and at the same time provide fun at the workplace. Dominik Petko, a media lecturer at the Schwyz University of Teacher Education, is also looking into serious games. He sees great potential in them, for both schools and further education: “Some games have been very well designed, and you can use them, for example, to teach second-grade kids linear equations”. But there are also very bad games, he says, that offer absolutely nothing. “So our question is this: What are the design principles and design elements that distinguish effective games from those that are less effective?” In order to find this out, Petko compares the learning impact of the same game in different variations with different school classes. In one variation, for example, the cute character will be missing, while in another, you can’t collect reward points. His goal is to find an attractive game that engages its participants, but at the same time doesn’t occupy too much cognitive capacity, instead leaving enough space for the learning process. Petko also believes it’s important that the tasks set by the game are neither too simple nor too difficult, and that the game automatically adapts to the ability of the player. The University of Zurich is currently testing another application of serious games. They don’t just want them to impart educational content, but to shape our ethical consciousness. “Ethics education in its current form is usually rather distant and boring, if I may be allowed to exaggerate a little”, says the ethics researcher Markus Christen. “People sit together and discuss things”. Together with Carmen Tanner and colleagues, he’s now developed a ‘serious moral game’ that is intended to impart ethical values in the financial sector. In this game, the participants can be advisors to a big company, for example, and they keep getting into ethically tricky situations – such as dealing with the confidentiality of documents. “By being immersed in the game, the players should find out more about themselves as moral beings than if they were merely to engage in abstract reflection”, says Christen. But he doesn’t believe that playing a game alone is sufficient – “it’s probably also important for players to reflect afterwards on their behaviour during the game”. They are currently carrying out experiments to see if his hypothesis is correct. They are also working on a serious moral game for training medical students in ethics, focussing on the conflicts of interest that occur in everyday medical work. Many companies are already making use of these findings, and get their employees to play collaborative video games together – in hopes that a good team in the virtual world will also work well together in the office. In this regard, so-called Massively Multiplayer Online Role-Playing Games (MMORPGs) are of particular interest. These include games such as World of Warcraft. In these games, which are often played by more than a thousand people at once, the characters can make friends with each other and come together in teams in order to fight common enemies. Psychologists believe that new forms of friendship, leadership and collaboration are being developed in these virtual worlds. Just how much these principles can truly be applied to the real world remains an open question. Already today, lots of people are sitting on their own in a ‘home office’ and only communicate virtually with the rest of their team. But there’s also help underway to counter this increasing isolation in the workplace. The use of virtual reality software is intended to give employees the impression that they’re sitting in the same room as their colleagues, even if they’re actually spread all over the world. Soon, virtual reality will be helping us to design new products, test prototypes and visualise data. “One day, we believe this kind of immersive, augmented reality will become a part of daily life for billions of people”, wrote Mark Zuckerberg, boss of Facebook, on his blog. So it seems unavoidable that the workers of the future will have to cope with virtual reality too. The young people of today, sitting at home and playing the latest video games with their virtual-reality glasses, are unwittingly preparing themselves for the working world of the future.

Mistakes are part of life. They are also – in fact, above all – part of scientific research. This image of a fractured concrete block reflects just one of those failed experiments. “We were still in the preparatory phase of our work, trying to ensure that the sample was firmly bonded to the metal sheets above and below”, explains Max Tirassa, a doctoral student at EPFL’s Institute of Civil Engineering. “To do this we set out to apply a constant force for ten minutes. But the machine had not been correctly set, and the excess pressure crushed the concrete”. Fascinated by the patterns that had appeared, Tirassa took out his mobile phone and immortalised the result of this experiment gone wrong. “At that time, I had just begun my research and often documented what I was doing in the lab. I’m more selective today ...”. Ironically, the study was actually designed to abuse the concrete block, just not in this way. “Buildings always end up developing cracks”, he says. “We want to understand how they transfer different forces inside the concrete, which is a very important issue for the stability of buildings”. Researchers start by horizontally sawing two parts of the sample to simulate cracks, leaving a column intact in the middle (a ‘dog bone’ in engineering jargon). Once the block is bonded, vertical and lateral forces are applied until they eventually break the concrete remaining between the two horizontal slots. “I like this image because it shows an often-forgotten part of the scientific process: the meticulous preparation that precedes any experiment. It illustrates well how science also involves making mistakes. At first, I blamed myself for this incident, because I had just started my doctorate. But the lab technicians reassured me. In science, most publications only talk about successes. It’s a pity, as we need to talk about mistakes too. They always teach us something”.

Oil is what makes the modern world go around. In refineries, it’s broken down to make fuel and the basic chemicals for innumerable everyday products such as textiles, medicines and plastics. But this resource has no future. Wood is an interesting possible replacement that’s renewable and climate-neutral. It could be transformed into all the substances we need using biorefineries. Hopes now rest on second-generation fuels that can be produced exclusively from wood waste or other plant waste. But this is immeasurably more difficult because wood is a complicated chemical mixture of cellulose, other sugar chains and lignin. It will be the job of biorefineries to transform these organic compounds into the desired fuel by chemical means. There are several challenges involved here. Constructing such a refinery will mean developing completely new chemical procedures that will differ from those of traditional refineries. But these procedures are still at an early stage of development. They’re being used in labs or small test facilities, and have barely been tested up to now on an industrial scale. And because experience is lacking, it’s also economically risky. Some companies have already given up trying to produce biofuel from wood or plant waste. The process was too complicated, the raw materials were too expensive, and oil was still too cheap to make it worthwhile – not least because of the fracking boom in the USA. François Maréchal’s approach is different. He doesn’t just want to produce biofuel alone, but to use biorefineries to produce basic materials for the chemical industry too. “We are trying to copy a normal refinery”, says Maréchal, “but one in which wood happens to be the raw material”. This means creating new processes. Wood will be transformed in two main steps – a biochemical process and a thermochemical one (see “Heating wood”). But what kinds of fuel and chemical are best made from wood so as to produce viable goods for the market? Maréchal feeds in all the cost factors for equipment, raw materials, energy, water and reagents. Then he calculates the possible profit for the most varied combinations of chemicals and fuels. The economic winners for a mid-size, 200-megawatt refinery are succinic acid, and dimethyl ether for diesel engines. “Succinic acid is the basis for different products in the chemical and pharmaceutical industries and bioplastics”, says Maréchal. The US Department of Energy regards it as one of the ten biorefinery products with the biggest potential. “It’s the most lucrative to produce by biochemical means. With this, we’d straightaway have market viability”. Unlike an oil refinery, a biorefinery mustn’t just make economic sense. It also has to be environmentally friendly and conserve as much carbon dioxide as possible. Even though trees bind the carbon dioxide that is later set free by vehicles, the transformation of wood into fuel needs extra energy. Furthermore, different fuels burn with different degrees of efficiency. So Maréchal is also carrying out ecological simulations. As a result, he has ascertained that it would be best if the biorefinery only produced a natural gas substitute (synthetic natural gas) and diesel. “Ultimately, we’ve achieved a compromise between economy and ecology”, says Maréchal. So the winners are: succinic acid and synthetic natural gas. Maréchal’s work is already being put into practice. As part of NRP 66, Michael Studer from the Bern University of Applied Sciences has developed a pilot plant in the canton of Jura that aims to produce ethanol from wood waste. Studer is keeping Maréchal’s twin-track strategy in mind, but initially he just wants to have fuel as his only end product, adding other production chains at a later date. Studer is putting his hopes in the highly integrated process design of his plant: “Four processes that normally run serially are taking place here in a single reactor”, he says. Given that a third of the price obtained for ethanol is needed to offset the high investment costs, Studer hopes to make drastic savings. Studer had to start from scratch when designing the plant. “You can’t transfer standard procedures to a Swiss context. We simply don’t have the same volume of biomass that you find in the USA or Sweden”. So high investment costs can’t just be absorbed by higher production levels. The wood waste will come from a factory to be built by a timber company that is also involved in Studer’s pilot plant. “Only 60 percent of the beech wood is used for production; the rest goes into the energy industry”, says Studer. But they can’t produce that many wooden pellets for heating purposes. That’s why they had the idea of combining the production plant with the biorefinery. “In order for a biorefinery to be run economically, it needs higher-quality products than just fuels, and it needs to utilise all components of the biomass if possible”, says Hasler. Succinic acid is a good product: “It creates revenues three to four times higher than biofuels”. But the market for succinic acid isn’t yet so well developed, he says, and demand is still too low. All the same, Hasler thinks a biorefinery could result in other highly promising products – maybe nutritional supplements such as thickening agents, modified sugars, or cellulose fibres for textiles or composite materials.

Nature conservation is hard work. Researchers have to go out into the field – rummaging among the reeds and rushes of muddy ponds, for example, just to try and find a great crested newt. “Such shy species are difficult to find just by going out in the field”, says Benedikt Schmidt, a resident expert at the Coordination Office for the Protection of Amphibians and Reptiles in Switzerland (KARCH). He and his colleagues only manage scarce sightings on their field trips, but they still have to use the information gathered to draw conclusions about the dissemination and migration of the animals. Now, thanks to molecular genetics, his work should become easier and his research results more reliable. These methods make visible the invisible, and enable him to count the uncountable. Assorted genetic procedures are already being employed in the study of amphibians. In order to determine the variety of amphibians in a body of water, they now need nothing more than a water sample. The skins of frogs and newts constantly shed cells and secretions, which contain fragments of their genetic material. This environmental DNA (‘e-DNA’ for short) can today be found reliably in water. The volume of the genetic material is unimaginably small. “Ultimately, you only take a shot glass of water to the lab, so there naturally isn’t much DNA in it. That means you have to work especially cleanly in the lab”, says Schmidt, who also researches at the University of Zurich. But the work is worth it: using these genetic methods, the biodiversity of Swiss ponds can be registered more reliably. The possible applications of this method go far beyond making inventories of animals. Conservation genetics also brings clarity when monitoring the advance of invasive species – such as the water frog. Many water frog populations in Switzerland are no longer pure, but comprise hybrids of indigenous species and others that have come from outside. Sometimes, a pond can even turn out to have nothing but non-native species. But they can be so similar to the indigenous frogs that you can’t tell them apart with the naked eye. “This is a case of gradual immigration. We’ve long known about it, but we weren’t aware of the extent of it. Investigating the e-DNA has shown that only a third of all Swiss ponds have purely indigenous populations”, says Schmidt. Now the authorities can concentrate their conservation measures in those places where they can truly help the indigenous species, instead of unintentionally promoting the spread of invasive species. Thanks to conservation genetics, it’s also possible to make more reliable statements about how far animals move about within their habitat. “With species conservation, it’s important to know just what links exist between individual populations”, says Janine Bolliger, a landscape ecologist at the Swiss Federal Institute for Forest, Snow and Landscape Research (WSL). The more individuals encounter each other, the more intermixed their genes become. “It’s especially the small, fragmented populations that will at some point succumb to incest and genetic impoverishment, and this can lead to their extinction”, says Bolliger. But assessing such cross-linkage requires more than just a water sample, says Rolf Holderegger, the head of the Research Unit for Biodiversity and Conservation Biology at the WSL. He’s been working in conservation genetics there for more than 20 years. “You take a swab of the mucous membrane in a frog’s mouth. Then you investigate between 10 and 15 sections of its DNA”, says Holderegger. Such investigations can reveal for the first-ever time the degree of interaction between different populations. “We can find out which individuals have moved where”, says Bolliger. If a newt or a frog sets off on its travels, it’ll produce offspring on the way. In this manner, it leaves behind a kind of genetic slime trail that goes right across the countryside. Astonishingly, the genetic analysis in this case provided an all-clear signal. “The animals that lived in the town were genetically quite different from those outside the town, but there was a fluid transition between the two of them”, says Bolliger. In other words, Alpine newts are successfully moving from one side of the motorway to the other, presumably through small culverts or underpasses. This year, between 50 and 100 sets will be sold. The cost of an analysis is about CHF 250. That means less than CHF 800 per pond. “If you wanted to determine the diversity of species by field work alone, you’d soon pay a similar amount for the number of hours involved”, says Meier. Traditional field trips aren’t going to be replaced by conservation genetics any time soon. Holderegger from the WSL sees them more as a complement to field work, because a biologist out in the field will also inspect the general state of a body of water, or will observe shifts in the environment that could have an impact on species diversity. Species that live in shrubs and trees, such as the common tree frog, for example, would slip through the metaphorical net of the e-DNA hunters. “In those cases, a water probe wouldn’t help much”, says Holderegger.

“My time at ETH was the darkest period in my career”, said a former doctoral student about the years she spent at the Institute for Astronomy of ETH Zurich. In an interview with ‘NZZ am Sonntag’ in Autumn 2017, she claimed that her professor had tormented her for a full ten years. Others who were affected spoke of insults, of being forced to be available at all times of day and night, and of meetings held until midnight that had more to do with interpersonal matters than with research. The Institute was closed down, an investigation set up, and the professor in question was temporarily suspended. Soon, further cases of harassment became public. And a survey conducted by the Academic Association of Scientific Staff at ETH Zurich (AVETH) recently revealed that every fourth doctoral student feels that they’ve been subjected to an abuse of power. It’s unlikely that ETH Zurich is the only university in the world with problems like these. Behind closed doors, members of other universities have hinted at similar cases. Do Swiss universities have a leadership problem among their professors? What’s clear is that abuses of power at universities isn’t a new phenomenon. The dependent relationship that exists between doctoral supervisors and the supervised is part and parcel of the Humboldtian tradition, and can also have positive consequences. “A professor isn’t just a line manager, but in a best-case scenario also a patron”, says the educational economist Stefan Wolter, Director of the Swiss Coordination Centre for Research in Education. Even today, academic careers can depend on which professor supervised which doctoral thesis. “A doctoral student is defined by his or her professor”, says Wolter. Their professor’s connections and reputation can open doors, once students have finished their doctorate. This is also why students put up with difficult personality traits in their supervisor. “Often, you know in advance what you’re letting yourself in for when you take a specific professor as your supervisor”. This type of dependent relationship isn’t limited to universities. Wolter worked for many years in a large bank, where he observed comparable structures. “You find yourself in an insider network where the boss demands obedience”. And the employees comply with it, because their own career depends on it. “If a line manager is promoted, then his employees move up with him”. Other factors come into play that might prevent rectors and vice-chancellors from taking action against a guilty professor in order to put a stop to the abuse of power. There’s the matter of international competition, and the power of the professors. It’s well known that someone might be a brilliant researcher, but not necessarily an excellent leader. But if someone is a leader in their field, then no one wants to lose them – even if they’re difficult to work with. What’s more, every intervention against a professor serves to destabilise the position of university management, which in Switzerland is already in a weak position because of the way the whole system is conceived. There was a model case of this at the University of Zurich, five years ago. After the so-called ‘Mörgeli affair’, the Rector at the time sacked a woman professor who was well regarded by her colleagues. There was a huge protest, and the Rector resigned. So do we simply have to accept abuses of power and weak leadership? No, that’s no longer the case, says Antonio Loprieno, former Rector of the University of Basel, not least because doctoral students today have a very different degree of self-awareness. “They’re the product of a globalised world, and are no longer willing to accept the family-oriented dominance of a doctoral supervisor”. So what can we do about it? Astonishingly, professorial appointments are still made today without any real regard for a candidate’s competence as a supervisor. And it’s surprising because for some time now, universities have been subjecting all their lecturers to precise evaluations of their teaching quality. No one has yet considered trying to measure the quality of doctoral supervision. Instead, universities have created numerous ombudsmen and contact officers in the last few years. But if and when these people actually take action, it’s only after an abuse of power has already occurred. Perhaps it would be good if the whole system were changed. Dependent relationships could be ended with the institution of doctoral schools, such as already exist in Switzerland. Candidates would apply to a school, not to an individual professor, and the doctoral thesis would be supervised by a mentor. “Doctoral schools should be a means of combatting abuses of power”, says Caspar Hirschi, a professor of history at the University of St. Gallen. “But in real life, they’re not”. When they were introduced, he says, the same thing happened that usually happens when things are reformed in Switzerland: new structures were set up without getting rid of the old. Because unlike in the USA or Germany, when doctoral students are accepted into a programme, they don’t automatically get the funding for their doctorate. As a result, they have to apply to a professor for a position as an assistant – and that professor thereafter often functions as their supervisor, examiner, and even the co-author of their publications. In this manner, the old dependencies are being recreated. These problems can only be solved, believes Hirschi, if you can guarantee funding to a doctoral student, and if you separate mentoring from examining. In his opinion, it would be more effective to set up doctoral committees such as are widespread abroad, where doctoral students are supervised by a team of professors. The system originated in American universities, where there is strong leadership at the top. There are hardly any problems with the ‘dictatorship of the professors’ in that system, says Loprieno. “The harassment case at ETH wouldn’t have happened with doctoral committees”.

Most of these projects are planned for the Swiss Midlands – one of the country’s most densely populated areas. In order to advance the planning for these projects, the Swiss Federal Office of Topography (Swisstopo) has developed a complex 3D model depicting the geological composition of the subsoil and bedrock, from Geneva through the Midlands to eastern Switzerland. This so-called molasses basin ranges from a few hundred metres in depth in the north to some six kilometres in the south, and comprises sedimentary layers such as limestone, sandstone and clay. These sediments date from 250 million to 30 million years ago, when Switzerland was still covered by the oceans. This is why Geomol 17 has already played an important role in planning the route network for “Cargo sous terrain”. This project aims to connect the large cities of the Midlands with a tunnel six metres wide, in which goods can be transported from place to place by unmanned, fully automated vehicles. According to the company, in future up to 40 percent of all goods transport could proceed like this, under the ground. The first portion of the network should be ready for business by 2030. It will be some 70 kilometres long and will link Zurich with Niederbipp in the canton of Solothurn. Besides the thickness and the course of the sedimentary layers, GeoMol 17 also visualises places where fractures occur. Knowing the position of these fault planes is an important criterion when choosing sites for underground construction projects, such as deep drilling. “Using the 3D model, for example, you can deliberate on how water flows through these faults, which is very important for geothermal plans”, says Gunter Siddiqi, an expert on the matter at the Swiss Federal Office of Energy. Whereas earlier depictions only showed a handful of such fault zones, GeoMol 17 is now mapping the position of some 600 of them. “In this regard, the project is incredibly important for Switzerland”, says Siddiqi. For GeoMol 17’s modelling, the geologists didn’t use any new data, but consolidated many thousands of existing datasets from different sources, in particular from Seag, a company that has been carrying out exploration for oil and natural gas in Switzerland since the 1950s, and from Nagra, which has been conducting geological surveys for many years in order to find underground storage space for radioactive waste. Measurements from other private companies, research projects and topographical maps were also utilised. “The most complex problem was to turn this into a uniform set of data, because some of it was very old”, says Allenbach. “We scanned and processed masses of papers”. In order to cope with this abundance of material, Swisstopo was joined by the Geological Museum of the canton of Vaud and the universities of Geneva, Fribourg, Bern and Basel, each of which took on a segment of it. They also acquired fundamental information on the structure of the bedrock from new analyses of data from earlier drilling. This involved using drill cores and crushed materials that had been analysed on the surface to help them understand the composition of the rock layers in the Earth. “This means we have acquired a very good understanding of the bedrock in Switzerland, though regrettably only in a few places”, says Siddiqi. Exploring the subsurface is expensive and complex – and is accordingly undertaken rarely. Up to now, only 165 drilling operations have been conducted in Switzerland to a depth of more than 500 metres, which corresponds to roughly four drilling operations for every 1,000 square kilometres. Seismic measurements are not so rare, though they only offer indirect evidence. To this end, geophysicists create artificial tremors in the ground using vibrators or explosions. By measuring the speed with which the waves of these tremors spread underground, geologists can determine the structure of the rock layers. “Using 3D seismology, we can today depict fault planes in high resolution, tens if not hundreds of metres”, says Marco Herwegh, a professor of structural geology at the University of Bern. Seismic waves triggered by natural earthquakes can also be used to map the bedrock. The Alparray project, which is coordinated by ETH Zurich and the University of Lausanne, has in recent years created a network of 600 seismographs in the Alpine region and the Mediterranean that can register even the slightest of tremors during weak earthquakes. All the same, the first steps have already been made on the way to a 3D model of the Alpine bedrock. Herwegh, for example, is currently working with his research group on a model of the Aar Massif. In addition to the available seismic data, he is also analysing the layers and faults in the visible rock formations. These cut through the surface of the Earth along specific intersecting lines. The researchers can then extrapolate these from the surface down into the depths. This means they can predict how the rock continues under the Earth. Herwegh is convinced that the work his geologists are investing in these 3D models will pay off in future. “These models generate information about where you can have a good chance of success with geothermal drilling – though there isn’t any 100 percent guarantee, and this is what makes it all so exciting”.





'Deoxyribonucleic acid' is twenty letters describing a discovery as simple as it is complex. Living things write their code in their genetic material with only four nucleobases: adenine (A), thymine (T), guanine (G) and cytosine (C). We all know the abbreviation stemming from this discovery: DNA. Just as we all know how it’s depicted geometrically: as a double helix. The origins of the discovery lie in the 1860s, when the Swiss doctor Friedrich Miescher discovered a substance that he found in an extract of pus. He called it ‘nuclein’. It was only after innumerable experiments by many researchers that James Watson, Francis Crick and Maurice Wilkins were awarded the Nobel Prize for Medicine in 1962 for decoding the molecular structure of the nucleic acids and for determining their significance in transmitting information in living things. ATGC – no more and no less. The model of the double helix might have inspired biochemists to begin describing processes in living creatures, but it also did a lot more besides. Two natural scientists showed not so long ago that the double helix can be used to store data – from books and photos to films and music. Architects use the spiral of the gene as a reference point when designing skyscrapers. And hair stylists braid long hair into pigtails with double plaits. The secret to innovation and successful entrepreneurship is also founded on four basic elements: decentralisation, openness, continuity and autonomy – DOCA. Switzerland is an ideal place to build on these four basic pillars. Healthy competition between scientists is vital in a small country where the creativity of decentralised locations is part and parcel of the greater, overall network, and if we wish innovation to emerge from the bottom up. In our discussions about participating in European research programmes such as Horizon 2020, we have seen the great value of an open exchange of ideas, both within Switzerland and beyond its borders. And continuity in the overall environment serves to promote the successful progress of research projects. What will we do if the creativity of our researchers is curtailed by the emergence of constricting dependencies? If individual responsibility – autonomy – is lost? DOCA explains in simple fashion how, through open competition, the philosophy ‘think global, act local’ can function in a country of different cultures such as Switzerland. Common values, common goals and the simplest possible steering mechanisms for decentralised implementation: this is how we can efficiently apply the resources at our disposal – as long as openness, continuity and autonomy are all guaranteed.

Creating hypotheses and making discoveries are at the very heart of the scientific process. But since the early 2000s artificial intelligence has stolen onto the stage. It is developing new ways of producing results and playing a role that we once thought to be the preserve of humans. Although unable to understand their own successes, increasingly powerful machines are leading the way to a very disturbing vision: industrial, robotised, automated scientific research. Let’s start with some examples. At Tufts University in Massachusetts (USA), a network of artificial neurons has been tackling one of biology’s enigmas. It is formulating hypotheses on the regeneration of a freshwater worm that is able to regrow both its head and its tail. At Adelaide University in Australia, a machine has discovered the optimal means for producing a Bose-Einstein condensate, a group of bosons that, at close to 0 Kelvin, expose macroscopic quantum phenomena. And at Johns Hopkins University in Baltimore, machines at the start-up Insilco Medicine have developed models that may be of use in treating cancer. What is it then, if it’s not intelligence? “The examples you mention are what are known as pattern-matching programs”, says Schank. “This is the process used by Facebook to identify your face in photos”. In other words, the machines generate patterns (e.g., the schematic of a molecule or a map of a flatworm’s regeneration) that can be compared with identifiable regularities in patterns stored in databases. This is a very meticulous process. “But the way scientific discoveries are made is completely different: at the outset, confusion reigns. It’s precisely not being able to understand something that leads you to create hypotheses, and then to test them. This is what we mean when we say science”. Schank is fond of telling a story to illustrate the difference between human discovery and automated learning. He calls it the steak-and-haircut story. “Whilst talking with a colleague at Yale, I was complaining that I was never able to get my steak the way I like it: bloody. My meat is always over-done. What the hell, I asked myself. He responded by saying: ‘I used to live in England and I could never find a hairdresser who would cut my hair the way I liked it’. Then, eureka! I saw how the two stories complemented each other and I suddenly had a new perspective. I saw them as being identical. In both cases, we’d requested a service from another person entirely capable of complying yet who didn’t, because that person perceived our requests as being extreme”. There is a moral to this story. “Our minds can achieve this level of abstraction effortlessly. They can see one thing as if it were another. They’re motivated by our innate goals – satiating appetite or satisfying curiosity – and then they calm themselves after getting worked up by a perplexing fact”. C’est ainsi que fonctionne notre cerveau. Mais la nouvelle vague de recherches et d’applications dans le domaine de l’IA, née à la fin des années 1990, ne vise plus à reproduire le modèle de cognition de l’esprit humain. Ce tournant mène vers un type de connaissance inédit, où le savoir est produit par apprentissage automatique à partir des mégadonnées. Cette bifurcation a tiré l’IA de sa léthargie et a permis les suggestions d’Amazon, à Siri, à la victoire d’AlphaGo sur l’un des meilleurs joueurs de go au monde, ou encore à prédire l’expression des gènes d’une bactérie, selon une étude de l’Université de Pennsylvanie de 2016. In the face of this human model of cognition, the new wave of applications of AI research – which began in the late 1990s – no longer aims to reproduce it. What is actually happening is a reorientation towards an unknown form of knowledge, where everything is produced through automatic learning involving big data. This change of direction has thawed AI research and opened the way for services that provide suggestions, such as Amazon and Siri, for the victory of AlphaGo over one of the world’s best go players and even for predicting the expression of a bacteria’s genes, as was done by a study at the University of Pennsylvania in 2016. The question that remains is whether this kind of technology can actually conduct science. It hangs on whether a machine can experience an existential need to understand, a desire to know, a ‘libido sciendi’, as St Augustine would have called it. There must be a limit to what a machine wants to know. At Lugano’s AI research centre, the Istituto Dalle Molle (IDSIA), we turn now to its co-director Jürgen Schmidhuber. In November 2016 the New York Times wrote that “when A.I. matures, it may call Schmidhuber ‘Dad’”. In 1997 his Research pointed to a ‘long, short-term memory’, which is today employed by spoken-language recognition programs. He believes the driving force of scientists, artists and babies is founded on just such a reward system and that it may be the same in networks of artificial neurons. Both forms of intelligence can experience a reward when, out of the disorder of the universe, they identify a repeating pattern or regular event that formerly went unnoticed. “Imagine a program instructed to make a model from a set of images that show apples falling to the ground”, he says. “Without knowing about gravity, a very large quantity of data would be necessary to encode the sequence. But once the discovery has been made, the machine will be able to use it to make predictions, and the data necessary for that would use up less space. The difference between before and after, essentially a data compression, is a measure of the depth of the newly acquired knowledge. This is what triggers the reward signal: a moment of inner joy for the network, if you like”. Schmidhuber feeds this reward mechanism into a formula for his theory of fun and creativity. He compares it with the experience of a musician discovering a harmony, and with humour: “Revealing a punchline unlocks the unexpected ending to a narrative. A certain data compression follows. At which point we laugh”. Understanding this is essential to building machines with artificial curiosity and capable of making discoveries. To wit, the network must work in tandem, he says. “On the one hand, you have a generator that conducts the action and leads the experiments by creating data. Its motivation is maximising its own rewards. On the other hand, there is an inspector that sends the reward every time a discovery is made with regard to a new regularity and which enables it to compress data. This is the kind of system we need if we want to build artificial scientists”. The neural network at Insilico Medicine uses such a dual system, explains Polina Mamoshina, a geneticist and Computer scientist on the project. “The generator is programmed to randomly and virtually create molecular structures. The inspector uses databases to learn to recognise the molecules capable of preventing growth in tumours. At first the aim of the generator is to catch out the inspector by leading it to make incorrect identifications, thereby allowing it to learn progressively”. Among the 60 molecules created by the generator and validated by the inspector, a number of them had already been discovered and patented as therapies against cancer. “This is an encouraging sign of the system’s precision”, says Mamoshina. “We are now going to move to a validation process of new models in vitro and then in vivo”. She sees this as being a revolutionary approach to this area. Instead of blindly scrabbling together new molecules, we are aiming to create medication on demand. Whilst we wait for the curious machines described by Schmidhuber and systems that can cook steak and cut hair to the taste of Schank, automatic learning and big data are currently redefining the scientific landscape. At the University of Bristol, UK, the professor of artificial intelligence Nello Cristianini is warmly embracing these new tools, but at the same time calling to Limit their field of application. “I’ve been working with machine learning for 20 years. I’m happy to say it works. The machine learns, insomuch as it improves its performance with experience”. These approaches are the same as those used to create huge profits at Amazon by ensuring the right book is recommended to the right person. “We should underline that these algorithms do not use psychological modelling for individual users, nor do they conduct a literary analysis of each book”, says Cristianini. “They work on a purely statistical basis: people with certain behaviours or characteristics buy books that in turn have their own particularities. This is what’s important: we can make a prediction without having a theory”. But does this model really work with science? “There is no philosophical reason why it shouldn’t”, he says. “A computer can generate models of molecules and predict their toxicity. What is to be gained from this? Well, we can perfect medication in silico, without having to produce all of the possible molecules and then test them on animals. What is there to lose? That we don’t know why the medicine works”. Machine learning is a black box, because we cannot understand the machine’s reasoning. This is a particularly thorny issue when departing from the world of academia, he says, “where algorithms determine access to rights: admission to a school, eligibility for an insurance policy, early parole...”. Is this type of learning still science? “We should not be drawn in by this question”, says Cristianini. “Machine learning is used to earn money by creating correct predictions, so there will also be a progressive redefinition of what we understand by science. Research funding will follow practical applications, and other approaches will find it difficult to obtain financing”. Should  we then be fearing Chris Anderson’s ‘end of theory’? In 2008, the editor of the magazine Wired said that “the deluge of data is making the scientific method obsolete”. “We should be asking the purpose of theories”, says Cristianini. “For me the answer is extremely clear. There is an infinite cultural value in creating a beautiful theory of mechanics or of thermodynamics, or understanding a part of our universe. We have a desire to know how the world around us works”. A good theory has specific value: “The prediction of a black box is not enough when the stakes are very high: for example, when we send a probe to Mars or plan a surgical intervention. In These cases, we want to know exactly what would happen if we were to change one or another parameter. This means using counterfactual argument, which can only be done using theories”. So, on the one hand we have probabilistic machines, and on the other hand beings who are driven by the need to understand, which is deeply rooted in biological functions, and who generate theories. Will the first replace the second? “What we can entrust to machines is specific tasks”, says Cristianini. He illustrates this: “given a sequence of amino acids, design me a protein. Using the entire human genome – three billion letters – find me the 20,000 genes that make it up! But understanding the significance and importance of a discovery will remain a human task”. The same division of labour can also be applied to social sciences. “I work with historians to investigate historical transitions in English and Italian cultures using a computerised newspaper reading system. As no one can read 500 million articles, the machine does it for us. It is, however, the historian who later explains why one or another result is of importance”. Furthermore, Schmidhuber is convinced of a complementarity. “In science labs, as elsewhere, machines will carry out laborious tasks which humans just don’t want to do, when it comes to it. Of course, that will lead to the loss of jobs. We should therefore ensure that society redistributes the benefits. This will happen through unconditional income, robot taxes or something else”. The social issues raised by the robotisation of the sciences remain as open as the epistemological issues. Can automated prediction be considered scientific knowledge? Cristianini is ready to meet this challenge: “I have just hired two science philosophers to start looking at this question”.

In the world of chess, it’s been 20 years now since humans were last able to beat a computer. More recently, these machines are being geared to work alongside us in the most demanding field of human endeavour: scientific research. Software programs are being designed to help us set up and assess studies, and the computer is becoming a kind of ‘smart butler’ in the laboratory, filtering the flood of literature and assisting with peer review. The advertising pitch of some of these companies sounds very optimistic. The Norwegian start-up Iris, for example, has announced that it can improve searches for relevant research literature. Iris can be tested on their website using a free tool. You feed in a link to a research paper, and then Iris delivers hundreds of results that are sorted according to ‘key concepts’. The studies it identifies are supposedly connected to the content of your paper – but some of the hits are useless because the tool occasionally regards two concepts as having a meaningful connection, when in fact they have nothing to do with each other. The literature search with Semantic Scholar, on the other hand, has been undergoing tests for two years already. The software is designed by the Allen Institute for Artificial Intelligence in California, and uses machine learning to recognise scientific concepts in texts. Up to now, Semantic Scholar has been scanning literature in the computer sciences and neurosciences. Other subject areas are to follow soon. When asked for his opinion, Paul Ginsparg of Cornell University, one of the founders of Arxiv, points to a “potentially rather useful” characteristic of the search machine: it doesn’t just take the number of citations into consideration, but also their significance – in other words, who has quoted a particular study and in what context. Intelligent search machines like Semantic Scholar or Sparrho usually orient themselves to the literature databases of Google Scholar and Pubmed. They are currently enjoying a boom. Just in the last few months, two similar products have appeared: Microsoft Academic and Recommended by Springer Nature. Some companies have even higher ambitions. The start-up Meta in Toronto claims to have developed a new scanning procedure for specialist literature. On this basis, its employees are developing apps, for example, that work with multi-layered neuronal networks. According to the marketing department of Meta, their app Horizon Scanning is able to trace back the origin of a scientific concept: it follows it backwards in time, thereby revealing a whole spectrum of research. According to the company that makes it, Horizon Scanning is intended for the pharmaceutical industry, publishing houses, research corporations and public authorities. Some of its algorithms come from a company that was involved in the development of Apple’s spoken-language interface software Siri. Its founders include several researchers, and the company was recently bought up by the Chan Zuckerberg Initiative. Given the lack of concrete information, experts – such as Jana Koehler of the University of Lucerne or Peter Flach from the University of Bristol – are not in a position to give a firm opinion on it. To them, the software is just like a black box. Besides literature searches, elementary forms of artificial intelligence are already being used in connection with assessing specialist articles. For example, together with his colleagues, Flach has developed a program to help find suitable referees for a study. The open-source software Subsift uses advanced matching algorithms for lists of words that describe studies and peer reviewers. It is a very big challenge to develop assistant software for scientists, says Flach. The problem lies in being able to integrate expert human knowledge in a sensible manner. In future, however, we can increasingly assume that this will succeed.

You call your bank or insurance company, only to be greeted by an automated message. For several protracted minutes, you are presented with a drawn-out and often redundant list of options. Your blood boils and eventually you can hold your tongue no longer: ‘Stupid system!’ But then, and as if by magic, an operator picks up the line.  This is no longer a coincidence, because programs using artificial intelligence are now able to understand emotions, which enables companies to adapt their services. At the University of Zurich, Sascha Frühholz, a professor of psychology who specialises in the neurosciences, is working on the automatic detection of human emotion. “Algorithms are becoming more effective, particularly in recognising the six principal emotions: anger, fear, joy, disgust, sadness and surprise. They still struggle when it comes to the more complex emotions such as shame and pride. But that’s not unlike humans, of course”. Mixing methods The main challenge for the machines is learning to be sufficiently generalised. “The training data are extremely specific”, says Frühholz. “Performance drops with a change in acoustic environment or language. Even if an algorithm can learn to understand anger in the voice of someone from Zurich, it won’t be so successful with someone from Geneva. Accuracy will drop even further with people from Asia, as the acoustic profiles of their languages are even further removed”. To overcome this pitfall, Frühholz has experimented with the combination of supervised and unsupervised learning techniques. “What we did was first to train the algorithm with voice data labelled as angry or happy. We then introduced non-labelled data, allowing the system to build its independence”. The rate of recognition has reached 63 percent, markedly better than using supervised or unsupervised learning alone (54–58 percent). Humans on the other hand are 85–90 percent accurate in determining the emotion in the voice of a person, adds Frühholz, who is also studying human auditory perception. “For both humans and algorithms, recognition accuracy depends to a large extent on the number of emotions that must be simultaneously discerned”. Keeping our roads safe Automatic emotional recognition will have a number of potential applications: customer services, marketing, surveillance, caring for the elderly and even medicine. “For one thing, it will pick out the first signs of an episode of anxiety or depression”, says David Sander, director of NCCR Affective Sciences and of the University of Geneva’s inter-faculty research centre. Over at EPFL, Jean-Philippe Thiran is conducting similar research but this time on the recognition of facial expressions. He has partnered up with the automobile industry, which shares his interest in emotion recognition. Thiran says their aim is “to collate information about the driver. In semi-autonomous cars, for example, it’s extremely important to know the emotional state of the person behind the wheel when handing over control of the vehicle: are they stressed, and can they take decisions?”. Irritated drivers might then find that the car speakers start playing relaxing music, while tired drivers might be stimulated by having the dashboard glow slightly brighter. “Today, research in this field has advanced to a stage where we’re tackling the recognition of facial expressions in unfavourable conditions such as in poor lighting, while moving, and from acute angles. Not to mention those quirky and subtle facial expressions”, adds Thiran. Algorithms are indeed moving forward quickly, but they are not yet capable of interpreting the full range of the emotions that make up everyday situations, whether revealed by the voice or by the face.

On the last day of the 2017 spring session of parliament, the Socialist Party’s National Councillor Rebecca Ruiz from the canton of Vaud proposed a motion to create a biobank law. “Biobanks in which data and specimens from patient treatments are collected and evaluated are rapidly increasing in importance”, says Ruiz. “But current laws are deficient in their coverage of them”. Her proposal received the support of 23 members of parliament. The occasion came at the end of March with the conclusion of the consultation process for the ‘general consent’ that has been devised jointly by the Swiss Academy of Medical Sciences and Swissethics. If hospital patients sign this form, their data and specimens can be utilised in future, as yet undefined research projects. University hospitals have already been working with such general consent forms for a while now, though they still differ from one canton to another. The proposed general consent would be the first time that there has been a single, standardised, national form. But a source of delight for scientists is a cause for concern for patient protection organisations. Franziska Sprecher is a professor of law in Bern who represents the patient protection organisation SPO, and she is critical of the current state of affairs. “It’s not acceptable that there is only a patchy legal basis for something as important as biomedical research and handling patient specimens and digitised data”. Hospitals are too lax in providing data security, she says, and if there is a data breach, then the patients will be left pretty much to cope on their own. So why is general consent so important for biomedical research? Vincent Mooser is a laboratory pathologist who has been running a pioneering biobank with blood specimens at the Lausanne University Hospital (CHUV) since 2013. He explains it as follows: “In order to be successful in the field of personalised medicine, we need data from very, very many people”. As an example, Mooser mentions the CoLaus Study, which began in Lausanne in 2003 with the goal of identifying cardiovascular-disease risk factors. The Lausanne group has over 6,000 patients and is a success, but in order to get further results, CHUV will have to cooperate with other hospitals. With a general consent form, it will become possible to exchange data, both within Switzerland and with foreign laboratories. “We will be doing research on a very different scale altogether”, says Mooser. This is essential in order to remain internationally competitive. Other countries, like the USA, the United Kingdom, China and India have long begun using big data in their medical research. Besides, he says, general consent does not offer up a blank cheque: “Researchers need the permission of their ethics commission for every project they undertake”. In fact, Swiss citizens aren’t reticent about sharing their health data for research purposes. At CHUV, for example, three out of four patients agree to donate their data, even if it goes so far as analysing their whole genome. At the University Hospital in Basel, the percentage is even higher. Up to today, over 27,000 general consent forms have been signed in Lausanne. For Mooser, it is natural that their corresponding data and specimens are protected to the highest possible security standards. CHUV is also home to the offices of the Swiss Biobanking Platform, and the big Swiss biobanks have joined it. On their website, they state that they welcome Ruiz’s motion to create a biobank law. For the time being, the network has accepted the rules of the Declaration of Taipei, issued by the World Medical Association in 2016, which lays down fundamental guidelines for running biobanks. Sprecher sees this as sending out a “strong signal”, but she still wants more to happen. She believes that the Declaration has to become part of the professional ethics guidelines for doctors.

Reading and writing are relatively new achievements in the history of mankind. That means they’re not pre-programmed in our brains. As a result, we spend a lot of time in our early school years learning how to translate spoken language into written letters (and vice versa). But some children just can’t do this properly. They mix up letters, make innumerable spelling errors and can only read hesitantly. Between 5 and 15 percent of the population suffer from such a reading and writing disability, which is generally known as dyslexia. New findings from brain research might offer them help. Researchers have long been investigating just what goes wrong in a case of dyslexia. What is certain is that it’s got nothing to do with intelligence or a lack of it. Instead, neuroscientists have discovered a deficit in the brain’s interface where it processes spoken and written language. “The problem is not primarily to do with hearing or seeing, but lies on a higher level where auditory and visual linguistic processing come together and are concentrated”, explains Daniel Brandeis, a professor of neurophysiology at the University of Zurich. “At this interface, spoken language is dismantled into its individual elements and linked to visual patterns of written characters that can be recognised by specialised regions of the brain”. This corresponds to the experience of those who teach children with special needs. Children with dyslexia find it difficult to break down language into its smallest units – phonemes. For example, they find it difficult to clap to syllables and to differentiate between similar sounds such as ‘t’ and ‘d’. This is why therapies for dyslexia often concentrate on these deficits. “Purely visual training without language has no positive effect on reading and writing”, says Anke Sodogé, a professor at the University of Applied Sciences of Special Needs Education in Zurich. “On the other hand, exercises for differentiating and processing sounds have been proven to be effective”. But she also warns about expectations being too high with this therapy because the progress attained is often only minor, regardless of the effort involved. A new neurological approach to treating dyslexia could improve the success of these therapies. It is based on the finding that specific brain waves are out of step in people with dyslexia. With the aid of electrical brain stimulation, the Swiss psychologist Katharina Rufener at the Otto-von-Guericke University of Magdeburg aims to bring these oscillations back into synch. “The idea is to normalise the initial physiological activity of the brain so that the therapy has a better impact”. In the brain, neurons fire synchronously to create different types of oscillations that fulfil different functions, according to their frequency. The gamma oscillations that are disturbed in cases of dyslexia have a frequency of between 25 and 40 hertz and are involved in processing auditory language: “The brain has about 25 milliseconds to recognise individual phonemes. This sampling rate corresponds roughly to the period of a gamma oscillation”, says Rufener. “In dyslexia, these oscillations are too slow or too quick, which means that the sampling rate of the acoustic language signal is disturbed. This is why the brain cannot distinguish between different phonemes”. In order to make these altered oscillations synchronous again, Rufener stimulates the brain of her test subjects by means of two electrodes attached to their heads. The desired frequency is transmitted to the brain by a weak alternating electric current. It is known that nerve cells in the regions stimulated will take up oscillations transmitted from outside. Rufener stimulated her test subjects with these oscillations and at the same time had them carry out tasks to differentiate phonemes. Children and young people with dyslexia were able to carry out these tasks better with this stimulation than without; the frequencies used were in the gamma range. In a second series of tests, Rufener now wants to find out the effect of other oscillations that are also impaired in the majority of dyslexia patients, and which are linked to cognitive ability. It is still unclear whether or not this method can lead to a long-term improvement, because after a single phase of stimulation, the brain falls back into its incorrect rhythm almost immediately. But there are signs that the effect lasts longer when the brain receives this stimulation several times over a longer period. Anne-Lise Giraud, a professor in neuroscience at the University of Geneva, believes that it is too soon for a therapeutic use of this approach. “Actually, we don’t really know yet what happens when the brain is stimulated”. She is carrying out similar tests in collaboration with the Wyss Center for Bio and Neuroengineering – though initially only on adults without dyslexia. “When we stimulate them, we see an improvement in their ability to recognise phonemes. But we also get many contradictory results”. This is why Giraud first wants to carry out more basic research. For example, it still has not been definitively explained whether or not gamma oscillations are constantly present. “We believe that the brain itself only gives out a weak oscillation, which is then strengthened through the act of hearing”. Her investigations also show that the gamma oscillations are coupled with other waves in the brain that quite possibly control adjustments to different speaking rates. In order to test her hypotheses, Giraud has developed a computer simulation: “The model depicts a network of neurons that produces gamma oscillations, and with this we can run through all these processes”. Even if these connections have not yet been explored in detail, Daniel Brandeis finds the application of electrical brain stimulation a highly promising approach: “I can well imagine that this procedure can decisively increase the efficacy of existing therapies, and thereby achieve quicker, longer-lasting changes”. All the same, we should not expect to achieve a complete cure. “For those who are badly affected, reading usually remains difficult despite successful treatment. Only in rare cases will they be able to read with the same ease as people without dyslexia”. K. S. Rufener et al.: Transcranial Alternating Current Stimulation (tACS) differentially modulates speech perception in young and older adults. Brain Stimulation (2016)

“In Vietnam, coal briquettes are part of everyday life. But even such a widespread object isn’t simply ‘there’. Briquettes are manufactured, transported and traded – the livelihoods of many different people depend on them. I followed the journey of these briquettes, from the coal mines to households and street kitchens. I have spoken with more than 100 people – with workers at opencast mines and in workshops by the banks of the Red River – and I have accompanied the traders who transport the briquettes on their bikes and rickshaws through the chaotic traffic of Hanoi. And I’ve sat next to the cooking pots that hang above the burning briquettes. “My research goes beyond the actual object itself. The coal briquette is a means of analysing Vietnamese society. I have learnt a lot about the relationship between the state and the private sector, about the connections between housekeeping, gender and architecture and about the upswing in religious belief. And in the process of this, it became clear that abstract processes such as urbanisation, economic development and modernisation – and the inequality that results from them – can be observed all the way into the kitchen. Coal briquettes only began replacing wood as fuel in the 1980s, because the government wanted to stop deforestation. Briquettes quickly became popular because they fit in special ovens that you can easily take with you and set up anywhere. Meanwhile, their image has changed once more. Today, they’re regarded as harmful to the environment. “A single object can enable you to take a holistic view of a society. And there are surprises along the way. Briquettes are never bought on the first day of the lunar calendar, because that is supposed to bring bad luck (according to the yin-yang principle). “Vietnam is a socialist country. The coal mines belong to the state, which exports most of its coal. You also find coal being washed into the open by the rain near where it’s mined, and some of it lands on the roads while it’s being transported. These pieces of coal are then gathered, mostly by women. This coal is of lesser quality and small workshops and family businesses compress it into special forms. The end product is a typical cylindrical coal briquette with several holes through it – the locals call it a ‘beehive’. The traders fetch these briquettes on their converted bicycles or – more recently – on mopeds. I’ve accompanied them on their trips to their clients. Men and women trade with these briquettes – and women are traditionally very much part of the business. “I had the idea for my current star anise project together with a colleague from McGill University in Montreal. She was researching mostly in the highlands of Vietnam, whereas my coal project was in the lowlands. It struck us that spices are something that unites these two regions. Star anise and other spices are cultivated in the highlands, harvested, and then transported to the lowlands where they are traded and processed or exported to China and India. Vietnamese cuisine also calls for star anise – it’s part of the traditional recipe for the noodle soup pho. “Using star anise, you can get a very good insight into the economic and societal development of Vietnam. The Country changed after its reforms of 1986. The price of the spice rose a lot as a result of this, and this naturally had a big impact both on the region where it is cultivated and on its trade in general. Furthermore, star anise is interesting to the pharmaceutical industry. It contains shikimic acid, which is the active agent of the flu remedy Tamiflu. After the bird flu outbreak of 2005, demand rose sharply for Tamiflu, and so did the price of star anise. Afterwards, the price sank considerably again because other flu drugs came onto the market, and because the pharma industry was soon able to produce the agent artificially. These global changes have had a concrete impact on local people. Some farmers with whom I spoke have stopped harvesting their star anise trees. It is now too costly.” Recorded by Anne-Careen Stoltze.

When we asked 58-year-old Solange Ghernaouti if she was a woman in a man’s world, her reply was, “I am a scientist who wants to understand and to share: that’s asexual”. She went on to add, “but I am not a man. Let’s be clear about that. I believe humans complement each other”. In her office of 30 years, Ghernaouti walks about barefoot with her hair tied youthfully, and is followed everywhere she goes by her dog Swak, even to her lectures. Ghernaouti is a professor in computer security at the University of Lausanne and she wears this badge proudly. “The moment we expose ourselves, we run the risk of not being appreciated. But I don’t care, what’s important is being respected”. Before specialising in the security of telecommunications networks, Ghernaouti started out designing them. She went on to become an authority figure in cyber security. Her books have since been translated into Chinese, she gives conferences around the world and she advises governmental and United Nations bodies. She is known to her entourage as a fighter, and she is currently fighting for a ‘Geneva Declaration of Cyberspace’ to govern the digital environment, to set forth the specific rights of Internet users and to define the limits to acceptable practices. “Just as with the climate and the environment, we must reflect upon what kind of cyberspace we would like to hand down to our children”. Ghernaouti claims to take an interdisciplinary approach to cyber security. Her projects look at not only technology and risk management but also philosophical, social, economic and political dimensions. In this regard, her concerns extend from the impact of computer conglomerates on our private life to the rise in Internet criminality. This approach does not win her very many friends. In 2015 the website of her research team, the Swiss Cyber Security Advisory and Research Group, was hacked, apparently by the Islamic State. “I marked that one down to experience. It was a lesson in cyber security from the victim’s perspective”. But it would take a lot more to upset Ghernaouti. When she was very young she had to fight to take her own path. She was born to French parents in Algeria during its war of independence. Her father was a geologist in the Sahara and she has a brother who is one year older than her. Before long, her family returned to Paris. “We were not rich. My mother was always very proud to be able to put food on the table every day”. Ghernaouti was a dreamer, fascinated by dictionaries, and dyslexic at a time when the disorder was still relatively unknown. “There are so many letters in my surname that I used to mix them all up!”, she says, smiling. She was placed with the dunces at the bottom of the class, and it was only thanks to her ability in mathematics that she lifted herself from that position and successfully left school at 16 years old. “It was because I had to fight continually that I became as strong as I am”. As she progressed through adolescence, she became inspired by Leonardo da Vinci. “I was fascinated by his ability to invent and to think into the future, but above all by his mirror writing”. She demonstrates by taking a pen in each hand and writing the same sentence simultaneously both left to right and right to left. That’s not bad for a dyslexic girl who used to have difficulty holding a pen. The same can be said of the 30 books she has published, including the first entitled “What do I know? [Que sais-je?]” about the Internet, co-authored by Arnaud Dufour. In the mid-1970s, she left home and her strict upbringing to go into computer studies. “It was the innovative and abstract sides to this discipline that attracted me. Just as a child does with a new toy, I wanted to know exactly how it works and what one can do with it”. To finance her studies, she worked as a carer, maths teacher and neuropsychiatrist, before creating her own company to provide software development services. “It was fun, but really I was just trying to get by. I wanted to be independent and not to have any favours to repay”. Having obtained her PhD, she applied to the University of Lausanne and, at 28 years old, became the first female professor in an applied business school, where she still works today. “Ghernaouti is an exceptional person, she is an extraordinary researcher who identifies new topics to look into and she knows how to get her staff to work”, says Igli Tashi, a former doctoral student and now head of computer security at the Vaud Cantonal Bank. “But what I admire most, beyond any form of prejudice, is her open-mindedness”. Years later she gave birth to a young girl. She sees it as a “wonderful adventure” but also an “extreme marathon”, because she was both a single mother and a career woman. “That’s the real achievement and no one cares!”, she says, adding, “I was on the verge of quitting almost every day”. Her colleague, the biologist Liliane Michalik, describes her as “a very brave and generous woman, devoted to her child and to her work” in a macho academic environment. Despite this, Ghernaouti still finds the time to go one step further: for more than 10 years she has chaired the university’s social committee and its equal opportunities committee. “It’s normal, almost a duty in terms of solidarity and setting a female role model”. Today she spends her spare time with her daughter, her books and her friends. She likes the forest, stargazing, and dreams of keeping chickens. She takes long daily walks with her dog: “this is the time I use to revitalise my mind, think outside the box and organise myself. In fact, it’s my dog who walks me!”, she says, laughing. But her driving interest is understanding, thinking and sharing. “I want to be always open to new ideas. That’s a way of living. People who only see restrictions cannot appreciate that, but personally I find it elating”.

Academia is reforming, from science citizens to open science. Is it happening in a scientific way? It’s the question that’s painful … science demands that politicians take an evidence- based approach to their work, but it  can’t necessarily take that road itself. One issue is that science studies often relies on the jargon of social sciences, which is  poorly understood by biologists and physicists. They really don’t have access to new knowledge. That’s a shame. Is it a culture issue? Yes, but not solely. Up to the 1960s, the meta-discourse on science was principally the domain of researchers working in the natural sciences. It was only later that sociologists and historians started looking from the outside in. That’s when science studies became professional and started raising more painful questions about the way research works. The result was increased tensions between the natural and social sciences. Those tensions have died away since then and the discourse of science studies has achieved better understanding and acceptance. But that is much less the case in Europe than in the US, where universities foster the liberal arts and students follow both hard and social science courses, which facilitates exchange between the domains. What about Switzerland? There’s still few initiatives in science studies. The exceptions are ETH Zurich’s Collegium Helveticum, the University of Lausanne’s Sciences and Technologies Studies Laboratory and EPFL’s College of Humanities. In 2014 Basel closed its chair, resulting in top-notch researchers emigrating. The majority of students and researchers in the natural sciences don’t have a human and social sciences culture. There is a high level of institutional specialisation, meaning there’s no natural home or base camp for science studies. In your opinion, what’s the most pressing matter in the field? The critical approach to expertise. Shouldn’t the public be in a position to trust academic experts when it comes to political votes and decisions? That sounds like a populist anti-elite slogan. Is there a risk of science studies being hijacked? Absolutely. The science sociologist Bruno Latour was reproached in 2004 for having laid down arguments in his critical writing that were later picked up by politicians to refute the science of climate change. We’ve even seen creationists quote science studies in court. But that doesn’t mean we can self-censor on the basis that our research will be misappropriated. That said, populists are developing the idea of extreme relativism, attempting to argue that common sense prevails over expert opinions. Science studies has nothing to do with this position, which is in fact scarier than the all-powerful technocrat. The approach is based on the critical interpretation of scientific facts, and particularly the undermining of their degree of reliability. Researchers are well aware of this argument, but it is often hidden behind the narrative of intermittent progress, historical discoveries and Eureka moments. How can confidence be restored between scientists and the general public? At the end of the 20th century, nation states feared that critical approaches to science would undermine taxpayers’ approval of research. Their response was to introduce participative programmes, such as the evaluation of technology policies. The results appear to be mixed, as studies have shown that consultations were held too late in the process, i.e., after a technological project had already been chosen, and that the public felt somewhat cheated. At the other end of the spectrum is the DIY Science movement, e.g., Hackuarium near Lausanne, where citizens can concoct their own research projects. This is of course mainly young people with a scientific education, but these forms of participative experiments do open up a new platform for other forms of research.

The greatest part of the genetic material of higher organisms comprises junk DNA. This genetic ‘clutter’ contains no blueprints for proteins. Researchers have been discussing for decades why this is so, and what biological significance these non-coding genetic building blocks might have. A group led by Mariusz Nowacki at the Institute of Cell Biology at the University of Bern has been investigating how paramecia deal with these DNA sequences, which are often regarded as being parasitic. Their findings seem paradoxical at first: these water-dwelling, single-cell organisms use these genetic elements in order to dispense with the same sequences themselves. In other words, the ‘junk’ is used to clear itself out. Paramecia are particularly suited for experiments into the role of junk DNA, because they have two types of cell nucleus: a micronucleus and a macronucleus. The micronucleus teems with non-coding DNA sequences. It contains the germ line genome. This is not used for the production of proteins, but is used exclusively for purposes of asexual reproduction. The macronucleus, on the other hand, contains more than 800 working copies of the genome. These are optimised for the immediate needs of the paramecia. In order to create the macronucleus, the genetic material of these organisms is, at one and the same time, copied and de-cluttered. The copies contain a compact, clean copy of all the paramecia genes, from which the junk sequences have been eliminated. But in the long term, these optimised copies are unstable. “That is why the paramecia now and again reproduce sexually – and subsequently create a new macronucleus”, says Nowacki. The junk then has to be eliminated all over again. Up to now, scientists had supposed that the non-coding DNA fragments – cut out of the germ line genome by the single-cell organisms to create a new macronucleus – were broken down and destroyed. But this is not the case, as Nowacki and his team have proven. “The paramecia glue the eliminated fragments together and make rings and loops with them”, says Nowacki. Upon reading these junk-DNA collages, they then create search templates that enable them to locate and remove further parasitic elements in their self-copying genetic material. The more cut-out sequences they find, the quicker they can find other parasitic elements, too – a kind of positive feedback process. This method of arresting undesired genetic elements in order to use them to search for further sequences in the genetic material can also be found in the cells of animals and plants. In this manner, they can ‘switch off’ or shut down parts of their genetic material. This could be a mechanism that in general plays an important role in defending genetic material against deposits of parasitic elements. This is also the opinion of Rebecca Zufall, an evolutionary biologist who is researching into the architecture of the genetic material of an organism related to the paramecia. She is admiring of the work being done in Switzerland: “They’re presenting a clean model of positive feedback and signal amplification that makes sense in the context of the double genome of these single-cell organisms”. Ori Schipper works for the Swiss Cancer League and as a freelance journalist. S. E. Allen, et al.: Circular Concatemers of Ultra-Short DNA Segments Produce Regulatory RNAs. Cell (2017)

Our call is answered by an anthropologist on the Aegean coast of Turkey. She travelled there just a few days ago to find out more about the political situation: “I would like to know what kind of research is at all possible here at the moment”. She would rather not offer any information whatsoever right now – and the same goes for other researchers. In order not to endanger either her, her partners in Turkey or their current research, some of the sources for the following text remain anonymous. This anthropologist has been researching in Turkey for many years now. What kind of research will remain possible in the future is something that she cannot guess yet: “Either way it will become more difficult to do research here”. She is one of several researchers from all over Europe who have been deeply engaged with Turkey. Many of them also see the situation the same way – it’s unpredictable and there’s a sense of latent threat. Many of them find themselves confronted with far-reaching complications in their work: either they aren’t given research permits any more, or get them only after a laborious process. It’s become more difficult for them to access archives, and their partners on the spot have become warier. These scientists often find it difficult to assess the extent of state surveillance right now. Our anthropologist is concerned least of all about herself; the worst that could happen to her is to be expelled from the country and be forbidden from returning. But it could be worse for her research partners in Turkey itself, or for the PhD students with Turkish passports who are working with her. The Western media often discuss how scholarship is under pressure in Turkey. But the figures also speak for themselves. Since the putsch attempt in the summer of 2016, the Turkish state has fired more than 4,800 scholars and begun criminal proceedings against over a hundred of them. The University of Lund published these figures in the spring of 2017. In early June, the American organisation ‘Scholars at risk’ published another report on the situation in Turkey. It describes the persecution of scholars having reached an “unprecedented scale”. Universities are being closed, while staff are being fired, forbidden from travelling, and even arrested. According to the report, thousands of scholars are affected by this state repression. And the persecution is continuing. The increasing pressure on scholarship and science is having a negative impact on foreign researchers working in Turkey. But the repercussions of the current political climate extend much further. They affect the jobs of people in the universities where scholars evaluate and publish their findings. “We consider very carefully what we can publish”, says another social scientist. This professor has been engaged in a study of Turkey for over 30 years. He and his colleagues completed their fieldwork there before the attempted coup last summer. He was lucky, he says. “We were doing research that we couldn’t carry out any more today”. His colleagues returned from Turkey more than a year ago now, including one researcher with Turkish nationality. They are evaluating their data and preparing their initial publications on it. They are writing about thorny issues regarding the relationship between the state and society. “We have to be very careful, and can’t write everything that perhaps we would like to”. Their primary goal in their publications is to protect their Turkish colleagues and their Turkish sources, who are opposition politicians or employees of NGOs. On the one hand, there is the desire to publish all possible relevant findings; on the other hand, there is a vague fear of repression, which has been intensified by events such as the arrest and dismissal of employees of universities and other organisations in Turkey. It’s a dilemma, as Nataša Miškovic can also confirm. She is an SNSF professor at the University of Basel and is active in a project of many years’ standing, researching into the emergence of the Turkish Republic and everyday life in Istanbul and Ankara in the 1920s and ’30s. Her group’s focus is on press photographs from the major daily newspapers Cumhuriye and Akşam. Their research is complete, and they are currently preparing for an exhibition that is also supposed to be shown in Turkey. This demands a great deal of caution. “We have intense discussions on what topics we can show, and where”. In order to not lose cooperation partners, they have also made certain compromises. They become careful whenever state authority becomes a topic. “Just like many other researchers, we are currently working with the hand brake on”, says Miškovic. Our conversations with these scientists are repeatedly suffused with a vague feeling of threat. Despite the unpredictable situation, they want to continue with their work. “We can’t leave every country that doesn’t want us to research there”, says our anthropologist on the telephone. But at that point she finished the conversation because half an hour later she was to meet with employees of a local organisation. A feeling of uncertainty will stay with her.





Concrete is made by gluing together aggregates using cement powder and water. Cement hardens when water is added to it, because the calcium silicate molecules form needle-like structures when they react with the water molecules. As the reaction proceeds, the needles link together to create a solid structure with pores containing a mixture of water and air. The pressure across the water-air interface compresses the concrete, creating the stress that can lead to cracks. Zhangli Hu at EPFL in Lausanne and her colleagues at EMPA in Dübendorf have developed a new method for predicting how relative humidity inside cement drops over time, and hence how readily cracks might form. This technique measures the relative abundance of large and small pores by placing samples of cement inside a benchtop NMR machine. Unlike direct measurements of relative humidity, this approach does not rely on the practice of breaking up samples. NMR-based predictions got to within four percent of direct measurements when dealing with more watery cement, and even to within two percent for cement made with very small amounts of water. That makes this technique promising for the analysis of high-performance concrete, says Hu, since it contains little water and is also more prone to cracking from changes in internal humidity. Edwin Cartlidge

The most recent civil wars in Africa and the Middle East are fundamentally different from the conflicts that took place during the Cold War. Instead of having two camps, each supported by a different major power, current conflicts often involve dozens of different groups that come together in shifting tactical alliances. The political options for achieving peace are correspondingly multifarious. But what measures can achieve the desired success? “Greater success is achieved through negotiations that lead to specific warring parties exiting the conflict”, explains König. “When all foreign groups withdraw, according to our model, the number of combat operations reduces by 41 percent”. His results thus also demonstrate the war-mongering impact of neighbouring states. Nicolas Gattlen

Aristoteles wrote in his ‘Historia animalium’ of how elephants sleep standing up, because if they lie down, they won’t be able to get up again. It was entirely spurious, of course, but the illustration in the Bern copy of the Physiologus links up with this idea by actually describing something we can observe in nature: elephants help others of their kind when they’ve fallen down. The Physiologus combines this observation with an allegory from the Old Testament. It describes the Fall of Adam and Eve – here an elephant couple – who lived in Paradise until they ate of the forbidden fruit. The text then tells of the futile efforts of the other elephants – Moses and the Prophets – to help fallen humanity get up again. Only the last elephant (Christ) is able to help the fallen elephant (Adam) to his feet. The behaviour of the elephants is here a reflection of the history of mankind as interpreted through Christian doctrine. We find the image of the pelican tearing open its breast to feed its young with drops of its own blood in cathedrals, universities and town halls, on the flag of the US State of Louisiana, and in the coat of arms of the town of Luckenwalde in the German state of Brandenburg. In the Physiologus, the pelican illustrates the history of man’s guilt and propitiation. Troubled by the cries of its children, so the Physiologus tells us, the pelican kills them – just as God obliterated the world in the Flood – but then it takes pity on them and awakens them to new life by letting its own blood drip onto them. The theological interpretation of this metaphor was forgotten by the end of the Middle Ages. Here, the open breast of the pelican symbolises Christ’s open side on the Cross, and the blood stands for the sacrament of the Eucharist that promises eternal life.

They investigated the chafer’s chitin exoskeleton using electron and atomic force microscopy, and found a helicoidal structure in the outermost layer. This so-called exocuticle has roughly 70 layers of the finest fibres (micro-fibrils) on top of each other, staggered at regular intervals. “It’s precisely this arrangement that is needed to reflect a single, unique colour – in this case it’s green”. When light is reflected off it, it adopts a specific direction of oscillation, known as being ‘circularly polarised’. A grate-like structure on the surface of the exocuticle also helps to mitigate the reflection of non-polarised light. The researchers have also shown that when viewed through a polarisation filter, the chafer appears even more luminescent. Many insects can perceive this polarisation of light, but birds and mammals can’t. “By creating polarised light, the chafer probably catches the eye of others of its species, while at the same time remaining camouflaged from predators”, says Wilts. Wilts now wants to recreate the chafer’s helicoidal structures in the lab. This could make it possible to produce paints that are more resistant and healthier than those that are pigment-based. But it is also conceivable that they could help to create security features invisible to the naked eye for use in passports and on banknotes. Simon Koechlin

Perhaps a setback was overdue. In recent years, we have been celebrating the astonishing successes of deep neural networks (DNNs), such as in speech and image recognition. DNNs are adaptive networks comprising several layers of virtual neurons. But now an unease has set in: Do we really know what’s happening inside neural networks? Can these new technologies be outsmarted? Are they a security risk? These topics are being investigated in brand-new research fields that call themselves ‘explainable artificial intelligence’ or ‘AI neuroscience’. “Systems using DNNs are at present pretty vulnerable to alterations of basic data”, says Frossard. “Often, we can offer no guarantees for their performance”. This fact can lead to real problems in the fields of medicine and safety. Self-driving cars, for example, have to be able to recognise traffic signs reliably. They can’t let themselves be misled by manipulated data. Researchers are gradually beginning to understand why these mistakes occur. One reason is that the programs are trained with a limited volume of exemplary data. If they are then confronted with very different cases, things can sometimes go wrong. One further reason for their failure is the fact that DNNs don’t learn the structurally correct rendering of objects. “A real image of a four-legged zebra will be classified as a zebra”, explains Nguyen. “But if you add further legs to the zebra in the picture, the DNN tends to be even more certain that it’s a zebra – even if the animal has eight legs”. The problem is that the DNNs ignore the overall structure of the images. Instead, their process of recognition is based on details of colour and form. At least this was the finding from the initial studies conducted into how DNNs function. As for their operating principles, many questions remain largely unanswered, says Yannic Kilcher from the Data Analytics Lab of ETH Zurich. This applies both to DNNs’ mistakes and to their miraculous successes. Often, even if a program is applied to unknown data, it will still provide reasonable results. “Why the neural networks should be capable of such generalisations is something we don’t yet fully understand”, says Kilcher. Frossard and his team are pursuing a different idea. They are introducing empirical prior knowledge to a DNN-supported model. The idea is that if you combine machine learning with concrete knowledge from the real world, then you might be able to construct a program that unites the best of both – the learning abilities of DNNs with the interpretability of conventional programs. Frossard says: “Ultimately, everything depends on the applications. But the best system is probably somewhere in the middle”.

Cottons printed with brightly coloured patterns were unusual, even fascinating to people in early modern Europe. Once the sea route to India was discovered, there was an increase in the trade of exotic goods. From the 16th century onwards, the Dutch, Portuguese and English imported Indian cotton textiles to Europe. They were a low-maintenance alternative to the linen and woollen garments that were the norm back then, and were much more pleasant to wear. With their artful, flowery designs, these cotton textiles – known as ‘indiennes’ or ‘chintz’ – were also as attractive as the silks worn by the upper classes, but considerably cheaper. It was hardly surprising that interest in cotton also grew in the Swiss cantons of the time, among both consumers and businessmen. But potential manufacturers had a problem – they first had to learn the age-old skills of printing and dying that were practised by Indian artisans. In this they were successful, as research has already proven. The Swiss indiennes industry experienced its heyday in the 18th century. The boom began in the 1690s in Geneva, when Huguenot refugees from France set up the first indienne manufacturing companies. Local entrepreneurs followed their example. This ‘calico printing’ spread via Neuchâtel, Biel and Basel to Aargau, Zurich and Glarus. But the story of indienne production in Switzerland has up to now been treated largely as a national phenomenon, says Kim Siebenhüner, a historian at the Friedrich Schiller University in Jena. She’s now expanding the picture to offer a global, historical perspective. Siebenhüner and her colleagues investigated many different sources, including the extant company correspondence of the indienne manufacturer Laué & Cie. in Wildegg in today’s canton of Aargau. They also found relevant information in old inventories of the city of Bern and from examining indienne objects in museums. The Swiss indienne manufacturers were aided by the political environment. France, England and Prussia tried variously to protect their own weavers from the influx of Asian cottons by placing bans on their import and manufacture. But Switzerland was very different, because the local authorities supported this new economic sector by offering cheap loans or privileges to help buy a water mill, for example. “Indienne production was regarded as a welcome source of new jobs that brought people into paid employment”, says Siebenhüner. In social terms, too, Switzerland had a lot less to fear from potential internal conflict. Whereas people warned of a possible overthrow of the existing hierarchies in England if middle-class, bourgeois households were able to afford bed covers, clothes and jackets made of indiennes, this moralising discourse was quite unknown in Switzerland. Was this perhaps because the consumer boom triggered by the indiennes was more moderate here than in the rest of Europe? The historian John Jordan seems to think so, based on his own research findings. He has studied so-called ‘Geltstagssrödeln’ in Bern – inventories that were drawn up in cases of private bankruptcy – and concluded that “in 18th century Bern, cotton was simply one more type of textile alongside wool and linen”. Indienne manufacture is regarded as a precursor of industrialisation in Switzerland because it brought together different trades under the same roof for the first-ever time: pattern designers, engravers of wooden forms, colourists and assistants, as well as managers. But production was not yet mechanised, and was extremely cumbersome. “The Swiss acquired the necessary practical knowledge by procuring skilled workers from abroad”, says Kim Siebenhüner. The expertise of Armenian specialist workers was in particular demand. They came from Asia under their own steam and set up pioneering indienne workshops in Marseille, Geneva, Livorno and Amsterdam. Soon it was the artisans trained in Swiss workshops who were taking their knowledge of indiennes elsewhere, and who became sought-after at home and abroad. According to Siebenhüner, the Swiss further refined the technology and the styles of indiennes: “They varied the raw materials and designed patterns with more familiar subjects”. It was “a century of learning”. Siebenhüner speaks of a “mimetic, imitative economy in the 18th century”, in which the mobility of experts and the circulation of knowledge served to stimulate the Swiss economy. The Swiss put a greater emphasis on utilising their knowledge, and were less afraid of the possible damage that might arise from industrial espionage. Unlike their colleagues abroad, Swiss textile producers didn’t spend much time lobbying to attain legal protection for their designs and techniques. It was only in the 19th century that the Swiss set up their own patent law. Much of Switzerland’s indienne production was intended for export. Manufacturers like Laué sent their commercial agents with sample books to the European trading centres in order to procure contracts and to ensure that they kept in touch with the taste of their clientele. Thanks to their presence across Europe, from Naples to Copenhagen, Bordeaux and Leipzig, the Swiss managed to procure outlet markets in Asia, America and Africa for their locally produced indiennes, as the Bernese historian Gabi Schopf has established: “They played an active role in creating a worldwide trade in textiles, and ensured that Switzerland participated in early-modern globalisation”. This commercial success naturally also had its darker side: Swiss indiennes also served as exchange goods in the international slave trade. The indiennes are an astonishingly diverse topic – they were a textile that changed the economy and society. In the light of today’s controversies about the free movement of people and the pros and cons of economic isolation versus liberalisation, historical research can serve to remind us of the open, global reach of Swiss business long before industrialisation and digitisation. Exhibition of indiennes in the Swiss National Museum, until 14 October 2018

Switzerland rightly boasts of being an underground champion, thanks to the world’s longest intercity railway tunnel (Gotthard), the world’s largest ever underground scientific experiment (part of the LHC at CERN lies in Switzerland) and the multitudinous underground pipelines and bunkers that earn the Alps their comparison with Swiss cheese. But’s it’s a champion only as far as engineering is concerned, because in terms of governance, the Swiss subsoil looks more like a “modern-day Wild West”, according to Olivier Lateltin, the head of the National Geological Survey at Swisstopo. “It is little known and under legislated. The rule that sometimes prevails is first come, first served …”. The authorities are therefore a little unsure as to how to manage what’s under their feet. “Unlike other nations, Switzerland has hardly explored its depths because there are no known oil deposits of interest”, explains Nathalie Andenmatten, who is in charge of geothermal policy for the canton of Geneva. “During the Second World War, France and Germany studied their subsoils for strategic reasons, with the aim of energy self-sufficiency”. This lack of knowledge concerns not only the very depths but even parts less than thirty metres from the surface: only a few large cities have a really precise knowledge of their pipeline network. Everywhere else, the information is either non-existent, incomplete, or difficult to obtain. “The underground land registry is like a no man’s land”, says Lateltin. To find information, you often have to turn to a series of different entities, such as telecommunications operators and local utilities companies”. In addition to spotty knowledge, the legislation is also extremely vague. Switzerland has no federal law specific to the subsoil. Article 667 of the Civil Code does attempt to settle the question by extending the ownership of land “to the full height and depth useful for its exercise”, such as the subsoil level from which thermal energy is extracted for central heating. (Roman law, by contrast, attributed unlimited ownership to the centre of the Earth.) In summary, “at present the question of the private and public domain is not resolved as far as the subsoil is concerned”, says Thierry Largey, a specialist in land planning law at the University of Lausanne. The situation is not without its practical problems either, especially as buildings grow taller and taller, requiring increasingly deep foundations. “This is particularly the case when, in certain land profiles, the foundations need to extend beyond the vertical column of subsoil located directly under the plot itself”, Largey says. “Is there an obligation for the owners to seek permission from their neighbours, or rather from the local authorities?” At the same time, the development of geothermal energy means an increasing number of shafts are being drilled – as deep as 300 metres – for heating individual dwellings. This concomitantly increases the ‘useful’ depth to which ownership can be exercised. Outside of privately owned plots, the Swiss subsoil is public property, much in the same way as lakes, snow-covered peaks and areas unsuitable for agriculture. The cantons exercise their sovereignty over the use of these areas through administrative law. “However, subsoil management remains very sectoral”, says Largey. There is no overview or harmonisation among the cantons. “Some cantonal laws date from the 19th century, while others have recently been revised”. Some cantons even lack explicit legislation in specific applications, such as geothermal energy. On the federal level, subterranean exploitation is not expressly mentioned in land planning legislation. Despite this, some coordination of the exploitation of underground resources remains possible, thanks in particular to planning or allocation tools available at different levels (both federal and cantonal). It is only in recent years that specialists have sounded the alarm, because until lately the lack of legislation and knowledge caused few real problems. In the wake of urbanisation and the development of new technologies, specialists have become concerned about increased competition among underground exploitation projects. This could lead to conflicts and an unsustainable use of resources. Underground spaces have a specificity: once built, they can hardly undergo any change of use. One example is groundwater becoming exposed to pollution. But, above all, it’s the fact that an already overcrowded subsoil means not everyone will be able to drill their own geothermal shaft. In Lausanne, for example, owners of property located above the route of the future M3 underground railway line will not be able to use geothermal heat at all. Which raises the question: will they be compensated? “There is currently no legislation that allows for a decision”, says Nahrath. The rise of geothermal energy – encouraged by the Energy Strategy 2050 – is already in conflict with transport tunnel projects. “Many of these projects concern the future”, continues Lateltin. “But it is now necessary to put in place the tools to manage the underground space”. Nahrath agrees with this: “We must coordinate land planning with long-term subsurface management. We need to establish plans, define zoning and design usage scenarios, in the same way we capably do for the surface. If we do not clarify the legislation for the subsoil, it will emerge out of the case law of the Federal Court in the coming years, because litigation will probably multiply. What we do know in this field is that it’s always better to think ahead and as quickly as possible”. If Switzerland does not flesh out its legislation, courtroom judges are going to decide how we manage our subsoil – cutting out the experts. In Geneva, Andenmatten sees another problem. “If we do not plan the use of the subsoil better, we risk hampering the development of certain technologies in the future”. In the case of geothermal energy, Switzerland has seen an increase in the number of shallow geothermal shafts in recent years, up to around 300 metres deep. They may be well suited to individual houses, but much less to the needs of inner-city buildings, where the subsoil is already congested. These buildings really need collective systems that extract geothermal energy from groundwater or medium-depth shafts. “If the authorities continue to allow individuals to drill their shafts and shaft fields independently without planning, it will no longer be possible to envisage collective systems in these neighbourhoods”, she says. She also thinks that disparities in cantonal legislation – and in some cases the absence of any appropriate legislation – could make it very difficult to implement major geothermal projects. “The data to be provided is different in each canton: something will be prohibited in one place but allowed in another. In short, it’s a disincentive to set up projects. For medium-depth geothermal energy to develop in Switzerland (between 300 and 3,000 metres), it would be necessary to develop and harmonise inter-cantonal practices”.

Botond Roska’s scientific colleagues use superlatives when they describe him: breath-taking, unique, brilliant. The research into the human retina conducted by this Hungarian-born, 48-year-old neurobiologist has attracted attention from all over the world. In recent months, he and his team have succeeded in growing an artificial, completely functional retina in a test tube. It’s a landmark event in science. A friendly fellow with glasses and a blue polo shirt introduces himself at the well-guarded entrance to the Novartis Campus in Basel: “Hi, I’m Botond”. He then leads us past buildings by international star architects, into the back section of the site. Just a few weeks ago, this became the provisional laboratory of the Institute of Molecular and Clinical Ophthalmology in Basel, which Roska founded in December 2017 in collaboration with the senior consultant of the Eye Clinic of the Basel University Hospital. For Roska, the Institute has turned a dream of many years into a reality. “We want to bring basic research and medicine together, and use this to put innovative treatment methods into practice”. The University of Basel, the University Hospital and the pharmaceutical company Novartis are together investing some CHF 20 million each year in the Institute. Over the coming years, over a hundred posts and ten new professorships will be created here. There are sound reasons for this great interest in Roska’s research. As our life expectancy rises, the number of people with eye diseases is going to increase exponentially in many countries. In ophthalmology, however, the past few decades have seen hardly any medical innovations. Botond Roska wants to change that. “I would like my work to help blind people to get their sight back”. In the struggle against eye diseases, this leading scientist combines nanotechnology with mathematics and the neurosciences. It was Roska who recognised what diseases arise in which cell types. “We are in a position today to combat diseases in a cell-type-specific manner”. To do this, he and his team manipulate viruses so that they transport genetically altered material into the diseased cells. With this approach, they should in future be able to treat a multitude of eye conditions such as Stargardt disease and Retinitis pigmentosa – both degenerative diseases of the retina. Botond Roska sits at his laptop and opens images of the retina he has cultivated. The photos have been coloured to show the different cell types of which they are comprised – there are about 100 of them. “The cells are like different little computers that come together to form a supercomputer”. Roska speaks with infectious enthusiasm about his research. The retina, he says, is an image processor that can be completely accounted for in mathematical terms. “My understanding of things is deeply mathematical. I love the clarity of this language”. What science knows today about the functioning of the retina is largely thanks to him. Roska is the son of a musician and a computer scientist. He grew up in Budapest, and his first passion was music. He studied the cello until an injury to his hand brought his career to a premature end. Roska had to re-orientate himself, and so began studying medicine and maths. After completing his degree, however, he didn’t yet feel in a position to work as a doctor. “I still knew too little about the human organism”. It was over dinner that an acquaintance of his father’s triggered his interest in the retina. In order to understand it, he embarked on studies and research in the neurosciences in the USA, then took on a job as team leader at the privately run Friedrich Miescher Institute. Five years ago, he set himself a new goal: “I said to myself that I wanted at least one of my discoveries to bring fundamental progress to medicine”. Roska describes himself as a driven man. “When I’m awake, I’m thinking”. He spends a lot of his time travelling. In the last four weeks alone he’s been in Barcelona, Paris, Honolulu, Boston and Stanford. He speaks at a conference almost every other week. “Exchanging ideas with other scientists is a prerequisite for my own research”, he says. Once at the Institute, he meets the members of his team and external researchers. His most frequent meetings are with Hendrik Scholl. They talk every day, even at weekends. “We’re constantly exchanging ideas. That’s the only way we can unite the different cultural approaches of the research laboratory and hospital medicine”. Botond Roska hardly has any leisure time. He finds it easy to engage in contemplation, he says, laughing. “What’s more difficult for me is being social”. He feels a little uneasy when in larger groups of people. He sometimes takes a break from his work, but only on Sundays. Then he plays cello, listens to Bach, or spends time with his wife. Basel is the best research site in the world for a biomedical specialist like him, says Roska. He has sufficient financial means for his research, and he loves the calm of the city and the unpretentiousness of the people. “I think this is the way to have a fulfilled life: work, love what you’re doing, and stay modest with it”. But now he’s got to go off to his next meeting with a research colleague. It’s just before 6 p.m. Today, too, it will be a long time before Botond Roska’s working day ends.

Whether they hold gold nuggets or a coelacanth from Graubünden, or flowers from the Zurich Oberland: natural history collections are an indispensable source of knowledge about the history of the Earth. They tell us about the dissemination of species, the emergence of biodiversity, and the impact of humans on the environment. The Swiss natural history collections hold well over 60 million specimens of animals, plants, fungi, stones, bones, fossils and soil samples. Some of these objects are over a hundred million years old. But the objects that are accessible to the public form only the tip of a huge iceberg. The biggest part of these collections is stored away out of sight – in the back rooms of museums, botanical gardens and universities. And yet these Swiss collections are of global significance – not just because Switzerland is home to many reference specimens, but also because these collections date back a long time and never suffered from the effects of wars. “As environmental problems increase, the collections become ever more important”, says Pia Stieger, a biologist at the Swiss Academy of Sciences (SCNAT). She heads a group of researchers who are currently writing a baseline report on Switzerland’s natural history collections. “Often, it’s only such collections that enable us to document environmental changes over several decades, and thereby deduce scenarios for the future”. It was only thanks to eggshells in natural history collections that we were able to determine the impact of pesticides on the environment. Indeed, with every technological innovation new analyses are made possible. Researchers can analyse the DNA and the chemical composition of objects, while new scanning technologies allow us to peer inside rocks and plants. Already today, these collections play an important role in investigating climate, biodiversity, pest control and the subsoil and bedrock. But much of the potential of these collections remains unrealised. The problem is that only some 17 percent of the objects have been captured digitally. Most museums lack the trained personnel necessary to take proper care of the objects and attend to their classification and digitisation. “In some institutions you can find boxes full of unsorted objects. They just don’t have the resources or the expert personnel who could classify and label them properly”, says Pia Stieger. “We need a boost in investment in order to turn these collections into a truly efficient research infrastructure”. The European Union is already one step further: it has placed natural history collections on the priority list for research infrastructure. The type cases of natural history For the first-ever time, we now have solid statistics for the Swiss natural history collections. They are bigger than hitherto believed, and contain a particularly large number of reference specimens – artefacts that have resulted in the initial descriptions of new species or rocks. We here take a look at research projects that would have been impossible without these collections. No shrimp too small Freshwater shrimps are important in aquatic ecosystems. They dispose of fallen leaves and are excellent food for fish. But for a long time, little was known about how widespread they were. Four years ago, the Swiss Federal Office for the Environment and the Federal Institute of Aquatic Science and Technology (Eawag) began a study of the distribution of freshwater shrimps in Switzerland. They have analysed samples from over 2,500 different bodies of water and investigated samples that were conserved in several museums. Once the project is completed, the results will be stored in the Cantonal Zoological Museum in Lausanne. This means that future researchers will be able to track how populations of these organisms have changed in different bodies of water. Sour fruit Dried wild plants, crops, seeds, fruit and mushrooms: botanical collections document shifts in nature and cultivated land. The biography of the potato There’s been much debate about the origins of the potatoes cultivated in Europe today. Do they come from the Andean highlands, or the Chilean lowlands? In order to solve this question, researchers have analysed over 50 leaf samples from 11 European herbaria that were preserved between 1720 and 1910, including samples from Basel, Geneva and Zurich. The results show that the first potato varieties introduced to Europe came from the Andes. By the time blight caused the Irish Potato Famine in the late 1840s, however, agriculture both there and on the European continent was already dominated by potato varieties from the Chilean lowlands. Species decline in Zurich How has the flora of the canton of Zurich changed over the past hundred years? To answer this question, the Zurich Botanical Society set up a citizen science project. Since then, 150 volunteers have observed over 100,000 plants in new locations and digitised 35,000 samples from the collections of Zurich University and ETH Zurich. The analysis of this data has not yet been completed. But it is already clear that the flora has changed drastically. Since 1900, some five percent of ferns and flowering plants have disappeared, and five percent are new species. The distribution of roughly every second species has declined sharply during the period in question. Mammoths and dinosaurs are the big hits in museums. But palaeontological collections also hold many other zoological and botanical objects from times long past. Exotic find in the Alps Changing mammals Lake sediments in southern Switzerland contain coniferous timbers from several thousands of years ago. Researchers from the University of Lausanne have now analysed their genetic material. The data shows how the spread of the very first agrarian societies influenced silver firs. Now researchers from the Natural History Museum of Geneva want to use the same methods to analyse bones of mammals such as reindeer and steppe bison. These genetic analyses should show how changes in the environment impacted on large mammals. Crystals, stones, meteorites, soil samples: geological collections can let us experience the history of the Earth and other planets. Traces of life in stones from Mars? In the summer of 2020, the Mars probe ExoMars will transport a close-up imager (CLUPI) to our neighbouring planet. Twenty years ago, researchers discovered traces of microbes in their rock collections that had lived deep in the rock under extreme conditions on Earth. A team from the Space Exploration Institute in Neuchâtel has now developed a camera that will be able to take high-resolution images of outcrops, rocks, soils and drill core samples on Mars. This should make it possible to determine whether or not there used to be life there. Will the tunnel roof hold? More than 30 people died in the fire in the Mont-Blanc Tunnel in 1999. The temperature during the blaze rose to over 1,000 degrees Celsius. For this reason, there was much uncertainty just after the disaster about whether or not the tunnel roof would hold. Before the salvage and clean-up operation could begin, the precise condition of the rock had to be determined in the sections where the fire had taken place. To this end, experts consulted some 500 rock samples in the Museum for Geology in Lausanne that had been taken during the construction of the Tunnel. The Museum has a unique collection of almost 15,000 rock samples from the Mont Blanc massif.

Marcel Tanner’s pencil-holder is a component from the gearbox of a Land Rover – it’s a memento of the biggest-ever repair job he had to undertake during his field trips. It was in Tanzania in April 1982, he recalls. He retired at the beginning of this year – in theory, at least. He has moved from the Director’s office in the Swiss Tropical and Public Health Institute in Basel into a smaller office. Art objects testify to his working visits to Africa, Asia and Latin America. But Tanner isn’t content with just babysitting grandchildren. He’s got too much still to do. And he doesn’t wait for our prepared questions to start talking about his research collaborations. MARCEL TANNER: The founder of our Institute, Rudolf Geigy, began working in Tanzania in 1944. He was busy with ethnological topics, not medicine. But when you see how people live, you soon enough come up against the topic of health. Our approach has always been that we wouldn’t fly in with a research question ready to be answered. Instead, we develop our research questions together with the people on the spot. You need good local knowledge for that. ‘No roots, no fruit’. Didn’t you have your research questions finalised when you first went to Africa in 1979? That was a formative experience. We were in Cameroon, looking for a new diagnostic tool for river blindness, which is a parasitic worm disease. We went into the villages where affected people lived, and treated them. Then we realised that these people had very different problems and concerns besides these worms, and that it wasn’t meaningful to deal with just one disease in isolation. After this experience I switched from immunology, which acquires its material in Africa, to epidemiology and public health, which is concerned with system contexts and investigates fundamental principles and solutions through partnerships. It’s about engaging in mutual learning to promote change. Are many researchers open to changing their research questions? Whenever possible, I send my postgraduate and doctoral students into the field. It doesn’t have to be Africa. If there are parasites in the tap water in the Lützeltal here in the canton of Basel, you still have to work together with all those who are affected. If you send people out and have them work in the field, they will be able to adjust their research questions accordingly. But that’s not always easy when it comes to those giving the money. The people who provide funds usually never get their hands dirty, so they don’t really understand the context. Intercultural collaboration occurs whenever you work together. You don’t need any seminars on interculturalism or any touchy-feely workshops. They just kill off all pleasure in your work. And the pleasure of it is what really counts. If you want to do research, you have to be curious. You have to enjoy sharing your findings with others, and you have to want to achieve something. If you’re in a region with a million inhabitants and you manage to lower child mortality by a third, then you know you’ve achieved something. If you take no joy in things, if you only see the problems and can’t laugh, then you’ll not discover anything. And the joy of it is also what helps you when things don’t go well and you spend a whole day running round to find diesel for the generator in your lab, for example. You learn a lot in such situations. But learning to find diesel out in the bush isn’t going to help you here in Switzerland. Oh but it does, because you’ve learnt to help yourself and to deal with operational crises. Today, a lot of Swiss people want to clarify all possible eventualities before they travel to Africa. They even want to know who will provide nappies for their kids – instead of just going there and organising things themselves on the spot. That all sounds well and good. But there are also cultural difficulties. How right you are – small ones and big ones! African culture functions by word of mouth, and they don’t always answer straightaway. It’s annoying if I don’t get an answer to my e-mails and I can’t communicate properly. Sometimes you flounder because of the political realities. In Chad, we had a comprehensive programme with the nomads. We were well on the way to setting up an institutional structure. We expected the government to participate, also in financial terms. But then nothing came. Despite eight years of planning with everyone involved, the programme failed to produce results – at least to the extent that had been intended. Are there enough well-educated people in poor countries? Education is the biggest problem. We often have students from poor countries who are good in their own subject, but they don’t possess any broad knowledge. You can put this right, but their doctorate will take longer, and the donors have to be prepared to pay the extra. But it’s worth it. Training people well is the biggest impact that you can make – far more important than any journal citation reports or any H index, which are purely for self-glorification purposes. Science, its methods and cultural codes, emerged in our cultural area. So isn’t any scientific collaboration asymmetrical from the outset? Sure. But it depends how you deal with this. Our holy scientific standards are not beyond all doubt either. Just think of the problems we have with peer reviews and our useless publication impact factors... But if you listen to each other, then common codes can emerge. In certain circumstances that can take several generations, which is why a long-term commitment is so important. And it needs respect. If there is no respect, there is no trust. The worst people are the Western consultants who have no local knowledge but always assume they already know everything. Why does Switzerland need a Tropical Institute? Can’t the people affected help themselves? You have to forget the word ‘help’ straight off. When the official Federal Message on Education, Research and Innovation for 2008-2011 first included research collaboration with developing countries, the critics said: You shouldn’t finance development aid through the research budget. But that’s not what it’s about. If you see that a country has a health budget of CHF 15 per person per year, then you can learn something valuable about our own health system that spends CHF 7,000 per head. It’s not about providing ‘help’, it’s about learning together by comparing and sharing. Is your message getting through? Yes. For example, I recently accompanied a group of members of parliament to Tanzania, from political parties ranging from the Greens to the Conservative Democratic Party (BDP). We visited the projects themselves, we weren’t just in high-level meetings. Even the sceptics were convinced by the purpose of our work and by the value of our partnership approach.

The economist and poverty researcher Esther Duflo was one of those who worked on the Washington Report. She had already co-founded the Poverty Action Lab J-PAL back in 2003, a research institute based at the Massachusetts Institute of Technology. J-PAL focuses specifically on randomised field experiments in order to achieve clean measurements of the impact of developmental measures. For example, in a spectacular study, Duflo proved that while the much-praised microloans in India did help to reduce poverty, they did not serve to improve the lives of those affected to the degree anticipated. This criticism of a lack of standards, along with a call for a greater evidence base, did not go unheeded in the professional community. One answer came in 2008 with the foundation of the independent International Initiative for Impact Evaluation (3ie). This NGO links together scientists with politicians and practitioners, organises conferences on topics such as ‘what works’, and promotes evidence-based evaluations. Since it was founded, it has supported more than 200 impact studies in 50 countries worth a total of USD 85 million. In parallel with the efforts made by science, the donor and partner countries have in the last decade also been refining and professionalising their evaluation instruments. The Declaration of Paris in 2005, for example, created a basis for common quality standards to determine the effectiveness of development collaborations. The OECD Development Assistance Committee defined five evaluation criteria: relevance, effectiveness, efficiency, impact and sustainability. These are not binding, but they are recognised internationally as a guide for action. These criteria are also monitored by the OECD itself in its own country reports. The lack of policy coherence among the donor countries is repeatedly criticised – such as when a country’s foreign policy runs counter to the goals of poverty alleviation. The donor countries themselves evaluate the effectiveness of their development methods. Sceptics cast doubt on the independence of these evaluation units, however, because in most countries they are situated within the same organisations that are actually giving the money. Germany struck out on a different path, however, when it created a mandate for an autonomous institute. In 2012, the German Institute for Development Evaluation was founded (DEval). “We place a great emphasis on a scholarly approach and on independence”, insists DEval’s director, the political scientist Jörg Faust. “We are also strongly focussed on a hands-on approach and want to initiate learning processes”. The topics they evaluate are usually multi-layered and complex, and thus require a high degree of expertise regarding both content and methodology. The methodological challenge, says Faust, lies in the basic question as to “how a situation might have developed if the developmental intervention had not taken place”. In order to investigate this, his Institute combines quantitative and qualitative methods. “When we carry out an evaluation, it’s not just about identifying the impact, but about finding out why there is an impact”. For this, they need both rigorous impact research and elaborate qualitative methods. “An informed debate won’t play the one against the other”, emphasises Faust. A few years ago, there was trench warfare between the ‘randomistas’ – the adherents of randomised field experiments as the scientific gold standard – and their critics. But today, the debate about methodology is kept more moderate, explains Faust. “Meanwhile there is greater acceptance of a position that asks more openly how quantitative and qualitative elements can be combined to form a mix of methods that achieves a maximum of knowledge production”. sabel Günther, a development economist and the Head of the Center for Development and Cooperation at ETH Zurich, also wants to find out what makes development collaborations effective, and isn’t confining herself to randomised field experiments. Experimental methods are best suited to the micro-level, she says. In order to analyse factors on the macro-level, such as the impact of tax policies, you often need other quantitative procedures. What is essential is that you always identify “what form of development cooperation has an impact in what context, and where it doesn’t”. This fact-based identification of effective interventions by means of scientifically recognised methods is in everyone’s interest. But this does not mean that “every single project or programme has to be evaluated”. Studies on the effectiveness of development aid should not just serve the accountability of one organisation, but should rather lead to a continuous improvement of the programmes, insists Günther. This learning process must take place above and beyond the boundaries of individual institutions. “The future lies instead in investing more in global knowledge on poverty alleviation, and in using this knowledge”. There are no comparative figures to tell us just how much is spent across the world on evaluating development cooperation. According to Jörg Faust of DEval, not more than one to two percent of the OECD’s development aid money is spent on evaluation. “Given the learning and knowledge needs in fields such as global sustainability and how to deal with fragile states, this surely isn’t too much money”. There are no comparative figures to tell us just how much is spent across the world on evaluating development cooperation. According to Jörg Faust of DEval, not more than one to two percent of the OECD’s development aid money is spent on evaluation. “Given the learning and knowledge needs in fields such as global sustainability and how to deal with fragile states, this surely isn’t too much money”. Both Günther and Faust point to the new UN goals in its 2030 Agenda for Sustainable Development, which has replaced ist Millennium Development Goals. The Agenda was adopted by the UN in 2015, and it has seventeen ‘Sustainable Development Goals’ and 169 ‘targets’. In future, development cooperation should no longer merely contribute to poverty alleviation, but should also cushion the consequences of climate change. This brings new challenges with it – and not just for the assessors. Isabel Günther feels we have to ask the fundamental question as to whether all these challenges can be met using the instruments of development cooperation, when financial resources are in fact being reduced. “Development aid is not the solution to all global problems”.

Drugs are taboo during pregnancy. That’s the guiding principle. But the reality is different. According to an international study that was published in 2014 in the British Medical Journal, 80 percent of all women take drugs during pregnancy. So it’s all the more important for medical personnel to know which substances could be dangerous to the unborn child, and which are safe. But pregnant women are often excluded from medical studies because no one is prepared to take a deliberate risk with the health of the foetus. Although no one denies the fact that women and men are fundamentally different, medical researchers still generally test their new drugs and therapies on men. It’s simply assumed that they will have the same impact on women. But that’s by no means always the case. The metabolisms of men and women sometimes process drugs differently. The female liver contains certain other enzymes that can ensure that drugs work (or not). Furthermore, drugs are distributed differently in a woman’s body. Women are mostly smaller than men, and have a higher proportion of fatty tissue. Certain drugs collect there, which again has an impact on their effectiveness. Then there’s the female kidney, which only performs to 80 percent of the capacity of the male kidney. This fact naturally has an impact on how metabolites are excreted from the body. And this is all without taking women’s menstrual cycle into consideration. The situation with children is at least as difficult. Like women, they are barely taken into account in medical research. Researchers only develop very few drugs specifically for them. But when it comes to drugs and therapies, children are not merely small adults for whom one can simply reduce the dose according to their weight. And paediatric medicine covers a vast range of ages: you can’t compare new-born babies with school-age children, any more than you can compare young people in puberty with toddlers. Various initiatives have been set up in Switzerland that hope to change this untenable state of affairs. Alice Panchaud is a pharmacologist at the University Hospital in Lausanne (CHUV) and is investigating methods to help find non-hazardous drugs for pregnant women. There was little awareness of this topic until the 1960s, when the Thalidomide scandal happened. Children were born with deformed arms and legs after their mothers took the sedative Thalidomide to help mitigate morning sickness during pregnancy. Since that scandal, everything has been done to try and keep pregnant women from taking any drugs at all. “Regrettably, that isn’t realistic”, says Panchaud, who is currently on a two-year research visit to the Harvard School of Public Health. There are diseases that you simply have to treat during pregnancy because they would be more dangerous for the unborn child than any drugs used to treat them. Even if pregnant women don’t take part in clinical trials, there are still two ways of getting usable data about them. Time and again there are cases of women taking drugs without being aware that they are pregnant. Then there are women who for medical reasons are compelled to take certain substances. “We urgently have to collect and analyse the data of these two groups”, says Panchaud. In this manner, a database could be constructed, listing drugs that are harmless to pregnant women. The rule of thumb is: wherever possible, no new drugs should be given to a pregnant woman, because we just don’t know enough about them. In the USA and northern Europe, good progress is being made on just such databases. In Switzerland, however, too Little effort is being invested, and the situation is made more difficult by the far more modest amounts of data available. It’s not just about determining whether a drug is harmless to pregnant women. The permissible dose can also often vary during pregnancy. Women gain weight and retain more water in their bodies, which mostly means that doctors have to increase their dosage. And for this, too, doctors ought to have the relevant data to help them make the right decision in individual cases. So at the CHUV in Lausanne, the relevant authorities are now setting up a biobank with blood samples of pregnant women who are being given drugs. Efforts are also being made to improve the situation with children. The research network Swiss Pednet, which links the Swiss children’s hospitals, is campaigning for the development of more drugs and therapies specifically for children. The dilemma is similar to that with pregnant women. No one wants to test drugs on healthy children, but at the same time there are many situations in which children need drugs. “We don’t want to subject sick children to experiments”, says David Nadal, Head of the Division of Infectious Diseases at the Zurich Children’s Hospital and co-founder of Swiss Pednet. That is why a professional research structure is needed in paediatrics, along with the corresponding finances to enable researchers to collect and analyse data. “Society has to increase its awareness of just how important medical studies are in general, and especially for children”, says Nadal. Today, already more than 80 percent of children hospitalised with cancer are being treated within the framework of such studies. Especially in the case of cancer, there is a great need for new drugs that can specifically help children, because they usually fall sick from cancers that are different from those that affect adults. Thanks to the initiative of various researchers, it has been proven in recent years that there is a clear gender difference in cases of heart disease. “Women die of heart attacks twice as often as men”, says Catherine Gebhard, a cardiologist at the Zurich University Hospital. And if they withstand an actual heart attack, they also have less chances of surviving afterwards. Nevertheless, only 24 percent of the test subjects in heart studies are female, and older women are barely represented at all, even though it has meanwhile become clear that male and female hearts develop differently in old age. “We still know far too little about why women die more often than men after a heart attack”, says Gebhard. The problems begin already at the lowest level. Tests on lab animals are carried out in advance of clinical studies on humans, but almost all the lab animals used are male. The assumption is that the results will also be valid for female animals. Gebhard is now running a research project in which she hopes to find out why women’s hearts age differently. In the near future, women with heart disease should be able to get targeted medical help just the same as pregnant women and children.

This eerie arrangement of tiny, spring-like structures has one goal: noise reduction. It’s 50 cm square in size, and might one day be used in buildings, cars and planes, says its creator, Andrea Bergamini from Empa in Dübendorf.  It’s a remarkable example of phononic crystals: structures arranged with a precise periodicity so as to absorb or deflect sound waves. “It’s a pretty recent field of research”, says Bergamini. “Its name refers to phonons, which are vibrations propagating in solids, and was inspired by its older brothers, the photonic crystals that are able to block or redirect light”. The structure is manufactured with a 3D-printing technique called selective laser sintering (SLS), where polymer powder is deposited layer by layer and melted by a laser to consolidate it. “We’ve created spring-like shapes in order to change the way the overall structure reacts to incoming sound waves: the 4 cm-wide rings cannot only move left, right, forwards and backwards like tiny balls of matter, but can also twist around their axis of symmetry”. This additional movement enabled the researcher to explore more configurations before manufacturing it. “Our goal was to create a material that is reasonably small, and stiff so that it can bear loads, but also light enough for automotive or aerospace applications. It’s a difficult combination, but we’ve succeeded. Our device attenuates 99 percent of 800 Hz waves, which is the typical frequency range of vowels in human speech”. The Empa team will insert their structure into a sandwich of polymers to test it as room panels. As the arrangement is largely empty, it lets most light through. While too thick (10 cm) to serve as a window, it could be used in sound-proofing panes separating rooms without blocking out daylight.

The space flight scene is in a state of upheaval. Something along the lines of a democratisation of space is happening – at least as far as the lower orbits are concerned. For several years, numerous universities have been experimenting with so-called nanosatellites. In the coming years, they will probably experience a commercial breakthrough – and Switzerland is playing an important role in it. For example, there are young entrepreneurs such as the Astrocast team from Lausanne who want to use nanosatellites to create a global data network for the Internet of Things. With a planned minimum bandwidth of one kilobyte per day, the technology is correspondingly cheap. Initial commercial deals have been agreed, and they are presently looking for a Partner who can offer low-cost transport. In fact, constructing small satellites is now such a routine matter that it’s more expensive to put a satellite into orbit than to make it. ‘Low cost’ – that’s the magic word in this ‘new space movement’. “Until now, space missions were the preserve of the big state agencies”, says Markus Rothacher, a professor of mathematics and physical geodesy at ETH Zurich. “But today, every university is in a position to produce its own satellites, as are the smaller companies”. The EPFL spin-off company Astrocast is basing what it does on the expertise gained from the Swisscube, which was the first and so far the only small satellite to have been launched by a Swiss university, back in 2009. A successor satellite should have long been sent up, but the CubETH project of ETH Zurich and EPFL isn’t quite getting off the ground. They planned building a four-inch cube with which to be able to test a simple global navigation satellite system independent of the American GPS. It’s not a receiver designed especially for space, but is made using off-the-rack technology. The researchers at ETH Zurich are currently examining whether the GNSS chips mass-produced by the Thalwil company U-Blox are suitable for the inhospitable conditions of space. They have already survived the vacuum chamber of Ruag Space without incurring any damage, and they are currently undergoing radiation tests at the Paul Scherrer Institute. Michael Swartwout from the University St. Louis is documenting the development of nanosatellites in an online database. He doesn’t see any sign of an imminent drop in the rapid growth that began in 2014. “No slowdown in sight, not at all”, he says. People estimate that by the year 2020 there will be thousands of small satellites in orbit, most of them for telecommunications. By that same year, the company Oneweb wants to have a constellation of 648 satellites in orbit so as to provide Internet access all over the Earth. Elon Musk, the founder of Tesla, is pursuing a similar goal. In November, Oneweb announced who is going to make their satellites: Ruag in Switzerland. It’s a prestigious deal, though hardly one to bring in billions – after all, it’s ‘low cost’. In Switzerland, the 600-plus satellites will be built for just CHF 20 million. That’s CHF 33,000 each: the price of a medium-sized car.

A cosy twosome, in heartfelt intimacy, preferably for a lifetime. That’s what most people still long for, despite rising divorce rates and our increasing focus on individualism. And yet in historical terms, our notion of a partnership founded in love is a relatively young phenomenon. This romantic concept only became established in the 19th century. And it took even longer for researchers to get to grips with it. Only since the 1970s have there been investigations into what keeps couples together (or drives them apart). Before then, separation was usually just not an option. People stayed together – both for economic reasons, and also because societal and religious conventions required it. Things are different today. So it would be really practical to discover a scientifically corroborated formula for long-lasting happiness in love. But research is only of limited help. “The phase of being in love lasts roughly half a year as a rule”, says Alexander Grob, professor of personality and developmental psychology at the University of Basel. After that, people cast off their rose-coloured spectacles and look at the object of their affection in a more realistic light. “And from that moment onwards, things get incredibly complicated”. According to their circumstances and living situation, the most varied interactions can occur. One’s personality is an important factor. Grob has studied how the character traits of partners are linked to positive feelings in their relationship. “Emotionally stable, extrovert, conscientious and socially compatible people with a high degree of self-esteem are more satisfied in their partnerships”. Among the characteristics that are particularly powerful are those that psychologists gather together under the concept of ‘neuroticism’. People who are more emotionally unstable, tense and anxious are less happy in love, while the more stable, self-assured and calm we are, the happier we are. So have nervous, shy and introverted people been dealt the worse cards? Not according to Grob: “We are not just abandoned to the vagaries of our personality as it is. We can also change how we think and act”. Emotionally unstable people who immediately assume the worst in ambiguous situations with their partner – “he/she doesn’t love me any more!” – can become aware of their behaviour and can try to change it or improve it. “If negative interpretations become less common, emotional stability increases”. The result is that one experiences one’s relationship as being happier. Partners can grow together. Over time, people with a lower sense of self-worth become increasingly positive about themselves when they are together with a partner who is content. Furthermore, couples who support each other in order to bring out the best in themselves live especially long and happy lives together. This is the finding of the psychologist Eli Finkel and his team of researchers in the US, who call it the Michelangelo phenomenon. The famous Renaissance sculptor was of the opinion that a work of art already existed, slumbering away in every block of marble. He just had to prise it out – carefully but determinedly chiselling and polishing it to let it emerge. In the context of a partnership, this means that couples should mould and support each other so that their opposite number becomes empowered to realise their ideals and their life’s goals. The tools for this are empathy and sensitivity. Whoever brings these with them is the better ‘sculptor’ in the relationship. It is also possible that we experience new things about ourselves. The eye of a loving partner can recognise dormant potential. But what doesn’t work, on the other hand, is trying to change one’s beloved. “If I don’t like something about my partner, I can influence only how I myself deal with it”, says Grob. In such a case, we should ask whether the issue that annoys us can be integrated, and if so, how. The manner in which couples talk with each other also has a lasting impact on the fate of a relationship, says Nathalie Meuwly, a psychologist at the University of Fribourg: “Partnerships where communication is formed on understanding and good intentions are happier and more stable”. Keeping lines of communication open, listening attentively, giving praise, compliments and little gestures of appreciation and affection – all this can consolidate a partnership to a large degree, and should not be underestimated. It’s worth cultivating this consciously, despite the daily grind, says Meuwly. And for those who have thus far noticed the absence of sex in this article: caresses and eroticism are also forms of communication. Sex creates bonds without needing many words. Positive communication does not mean saying only nice things to one’s partner. People should also broach difficult topics and express criticism. Occasional conflict doesn’t actually do any harm, so as long as it doesn’t topple over into destruction and contempt, says Meuwly. “A conflict can help to clarify positions. And it offers the opportunity for reconciliation”. In this manner, intimacy and understanding can be re-established between the partners. But we should watch out, because it all depends on getting the mixture right. Research has shown that five positive gestures offset only one negative gesture. So whoever criticises their partner once should afterwards display five signs of affection. That way, the relationship can stay balanced. So we’ve found a clear formula after all! It was drawn up by the US pioneer in relationship research John Gottman. According to Meuwly, there are two further factors that play an exceptional role in how partners interact. First, couples who can offer mutual support in stressful situations – such as career stress – can stabilise their partnership in the process. Secondly, solving conflicts and problems together also forges bonds. It’s clearly simpler to offer support in cases of stress at work than it is to deal with arguments involving the relationship itself. “Stress that comes from the “If both are stressed, it can get dangerous for a relationship”. There is still a lot to study. For example, we know little about elderly or same-sex couples. But such research can help us all. For many years now, the University of Zurich has been offering a successful partnership programme entitled ‘Paarlife’, which was developed by Guy Bodenmann, a professor in clinical psychology. Love is like a little plant, he writes. It has to be tended, otherwise it wilts away. R. Weidmann, Th. Ledermann, A. Grob: The Interdependence of Personality and Satisfaction in Couples. European Psychologist (2016) G. Bodenmann, N. Meuwly et al.: Effects of Stress on the Social Support Provided by Men and Women in Intimate Relationships. Psychological Science Online First (2015)

Whoever plays an instrument naturally wants a specific form of feedback from it: the sound of it. But every sound is a vibration that you don’t just hear: when you’re playing, you feel it too. The experts call this haptic feedback. In his doctoral thesis, Matthias Flückiger of ETH Zurich is measuring this haptic feedback directly on musical instruments. “Playing an instrument is a complex interaction of different senses – only part of it occurs via the sense of hearing”, he explains. Flückiger would like to understand this interaction better – and the vibrotactile feedback in particular. He places many highly sensitive sensors on instruments to measure the musician’s playing, position and movement, and the pressure involved. Using so-called actuators – small elements that create vibrations themselves – he can control the reaction of the instrument. This allows Flückiger to study what happens when the vibration behaviour of the instrument changes. This is also a matter of interest to Stefano Papetti at the Zurich University of the Arts (ZHdK). He equipped a digital piano with actuators that give it a virtual resonating body by reproducing vibrations that he had recorded meticulously from an acoustic piano. Then he invited professional musicians to play on the digital piano without telling them what was special about it. Unlike Flückiger, Papetti asked his test subjects for their subjective opinions. The musicians noticed a positive effect that they initially could not name. But when he showed them how the piano had been prepared, several of them realised what was happening: “I wasn’t aware that my instrument vibrates and that I perceive this through my touch”, they said. Papetti now wants to pursue his work together with the Integrated Actuators Laboratory (LAI) at EPFL. But haptic feedback isn’t just relevant to playing an instrument. It is also important to the interaction between humans and machines. “But we live in a world dominated by the visual”, says Papetti. This is why most interfaces are conceived for our eyes. And yet touch is a far more subtle means of giving feedback to the user. As an example, Papetti mentions the latest Apple trackpad, which provides the user with the illusion that its surface ‘gives’ a little when pressed – just by employing vibrations at the right moment. In his earlier work, Papetti and his team at ZHdK tried to find out what role haptic feedback plays in learning and playing an instrument. To this end they built a device that measures what vibrations a person is actually able to perceive. Papetti is a software engineer and himself a “reasonable” keyboard player, and he was able to take up where earlier research had left off. He was part of the large-scale EU research project Natural Interactive Walking, which endeavoured to convey information not just through the usual senses, but through the feet. Papetti co-developed shoes that were equipped with small vibrators that were able to simulate different types of ground when the wearer walked in them. When applied to music, his research provides results that have called extant opinions into question. With his haptic feedback apparatus – an unprepossessing little box with a contact area for the fingers – Papetti has determined threshold values for vibrotactile feedback at a much lower order of magnitude than is described in the literature. It is clear that humans can perceive far more subtle vibrations than was hitherto assumed. This could be of great significance to future applications, says Papetti: if humans can cope with much finer impulses, then touch-interfaces can also be built that are all the more subtle. “Touch is simply the most intimate form of interaction”, says Papetti. And it would be a shame if we couldn’t get our machines to reflect this a little too. S. Papetti et al.: Vibrotactile Sensitivity in Active Touch: Effect of Pressing Force. IEEE Transactions on Haptics (2017)

The bloated corpse of a young man is being recovered from the Bouwersgracht. The dead man is a Russian cancer researcher who has made millions of scientific articles freely accessible online via an Internet platform, and thereby made himself liable to prosecution. In his pocket he has a receipt from a taxi ride to Sonarweg 31, the headquarters of the Greed Elsegier Concern, the most powerful scientific publishing company in the world. A few days later, its CEO is found dead in his office chair. With its exciting plot, this imaginary episode of a successful TV thriller series would lay bare the scandalous monopolistic misuse of power by scientific publishers. Their business model is ingenious: they take knowledge financed by tax monies and privatise it. They publish the results of this research in journals to which the universities have to subscribe at inflated prices – again paid for with tax money. The market is dominated by just a few publishers who exercise their power ruthlessly. With their ever-rising prices they have long reached profit margins of over 30 percent. The salary of the CEO of Reed Elsevier was GBP 16 million in 2015. If only such a thriller could really be made, then awareness might be raised, among both the public and our politicians, of the importance of the Open Access movement, whose aim is simply to prevent the general public from having to buy back knowledge from academic Publishers that their tax dollars have already paid for. But we don’t have to wait for TV to tell the world about it. We ourselves have the power to change the rules of the game. We simply have to stop funding this all-too-profitable business with public money. Matthias Egger has been the President of the National Research Council since January 2017.

They were murders that horrified the public: Lucie, Adeline and Marie were all killed by repeat offenders, and their cases became synonymous with criticism of the Swiss justice system. And even before this, there were accusations that the criminal justice system was too understanding towards criminals. This resentment was given expression on a political level by the approval of several popular initiatives to tighten up penal laws – such as those on preventive detention and on the removal of the statute of limitations on paedophile criminals. This seems to give the impression that the Swiss electorate is dissatisfied with the criminal jurisdiction in their country. And when asked for their general opinion, voters do agree that the courts pass sentences that are too lenient. But when this question is posed on a concrete level, their answers are much less clear. This is the conclusion of André Kuhn, a professor of criminology and criminal law at the University of Neuchâtel. Since 2000 Kuhn has carried out three random tests among both the population and judges to ask how they would punish a reckless driver, a burglar, a criminal banker and a rapist (see ‘The joy of punishment’). He found the results surprising: in the first three cases, a majority of the population would give a more lenient sentence than the judges. Only in the case of the rapist did they want a harsher sentence. To be sure, in all three surveys there were people among the public who preferred highly repressive judgements, and this pulled the survey’s average sentence upwards. But a majority of them offered judgements that were milder than expected. These findings suggest that the criminal justice system in Switzerland largely matches the public’s expectations. “These results might seem astonishing, given the ‘easy justice’ discourse of politicians and the media”, says Martin Seelmann of the University of Zurich, who is writing his doctoral thesis on sentencing. “And yet other studies have also shown that the public often prefers milder sentences than those proposed by politicians and the media”. Some politicians defer to the public’s supposedly restrictive opinions on sentencing because it can bolster their stance as defenders of ‘law and order’. “The fact that popular initiatives to tighten up criminal law have been accepted is also because the media and politicians have been stoking up fears among the population”, says Seelmann. The results of this study have been confirmed by similar surveys in other countries. For example, when asked for their general opinion, people in Great Britain have also described their justice system as being too feeble. But when it came to imposing a sentence in a concrete case of burglary, it emerged that the public’s judgement was at one with that of the judges. This point is also criticised by Martino Mona, a professor of criminal law and legal philosophy at the University of Bern: “Such surveys of the public and of judges, which present significantly shortened, fictitious cases, cannot allow for any relevant assertions about actual practice”. Asking the general population for their spontaneous response to brief case descriptions comes nowhere close to judicial practice, he says. Kuhn doesn’t see this as a problem. “It’s about getting the public to slip into the skin of the judges. It’s a means of assessing the public’s attitude towards the justice system”. He insists that his method of comparing judgements in brief, fictitious cases is a good way of achieving this. Mona’s critical stance isn’t based just on methodological objections. He finds it fundamentally problematical when public opinion is used as a guideline for assessing just sentencing in concrete, individual cases. “It’s counterproductive to keep evaluating the justice system on the basis of whether the judicial verdicts correspond to the will of the populace”. Comparing the general opinion with the judge’s decisions suggests that public attitudes are a relevant criterion for handing down sentences in individual cases. According to Mona, that is an unnecessary doubling of the power of the people. “There are good reasons why we don’t have people’s courts. Furthermore, with our democratic elections and referenda we have enough mechanisms on a political level for the population to be able to determine the general conditions of the justice system”. Kuhn counters that his surveys are not about getting judges to adapt to the will of the people. “Our goal is rather to show that people are wrong when they claim that the public is widely critical of the leniency of our justice system”. In light of these findings, no politician should be allowed to claim the backing of public opinion when demanding harsher sentences. Kuhn regrets that the political discourse barely takes note of scholarly findings when it comes to criminal justice. A. Kuhn: La juste peine selon la population et selon les juges, Résultats d’une triple étude empirique. Tagungsband der Schweizerischen Arbeitsgruppe für Kriminologie (Herbst 2017) M. Hough and J. Roberts: Sentencing Trends in Britain, Public knowledge and public opinion. Punishment and Society (1999)

 Here ten young Scots pine trees display what might normally escape the eye: the delicate intertwining of their roots. As part of a study into the effect of drought on different species, Christoph Bachofen of the Institute for Forest, Snow and Landscape Research (WSL) has been growing these trees in two-metre long boxes in Leuk, Valais. The plants on the right have been growing under normal conditions, whereas those on the left have been subjected to intense artificial droughts. In order to ensure that the natural competitive Environment was reproduced, several trees were grown in each box. The researchers waited three years before opening the boxes and then carefully took them out with their roots intact. On a white background, they photographed each one before recomposing the plants together in digital format. “We’re looking particularly at the length of the roots, their diameter and their mass, but also their architecture”, says Bachofen. “They are denser at the surface, where they have access to nutrients in the humus, and at the bottom, where they have access to water accumulating in the sand and gravel. This is highly representative of soil profiles in Valais”. The study failed to confirm the hypothesis that the Spanish, Greek and Bulgarian pines (2nd, 3rd and 5th from the left) would fare better with the lack of water. “We didn’t even expect the local pines to survive. The artificial drought was drastic: no water at all between June and September for two consecutive years”. With this unexpected resistance, native species might not be so unprepared for global warming.

In the files, he’s called a ‘collector’. However, he only carried his portable cooking utensils around with him, and that’s hardly the professional equipment of a man whose task is to skeletonise human corpses. Nevertheless, it’s thanks to his efforts that the Basel Society for the Natural Sciences was given “by far the most valuable addition” to its ethnological collection in the year 1914, as it wrote in its report for that year: “Two complete skeletons, one male and a young female, both Alacalufe from Tierra del Fuego: specifically, the west coast of the island of Santa Inéz”. This island lies at the southern point of South America and today belongs to Chile. Our otherwise anonymous travelling ‘collector’ is said to have observed a funeral there, after which he promptly exhumed the bodies and then “boiled them down piece by piece in his travelling pan”, thus the annual report in Basel. What remained were bones and skulls. These lie today in the anthropological collection of the Basel Natural History Museum. The period Blanchard is examining is 1905 to 1918, and the objects of his study are the scientific and historical context of anthropology, the institutions and people involved in forming these collections, and the origins of the objects in them. What is extraordinary about the Santa Inéz skeletons, he says, was not that the ‘collector’ dug them out of a grave; “exhumations were at the time a widespread method for acquiring human remains for anthropological study”. Even Fritz and Paul Sarasin, the founding fathers of the Basel collection, procured bones from graves in Sri Lanka and Sulawesi, in some cases without the knowledge of the indigenous inhabitants. What was exceptional was the point in time when these bodies were exhumed, for digging up fresh corpses that had not yet decayed was “very rare”. A hundred years later, an ethical unease has surfaced. Human remains in museum collections have become a problematic matter, and demands for their restitution have resulted in controversy about the legacy of early anthropology. In 2011 this climaxed in a foreign-policy crisis between Germany and Namibia, when the presence of bones in German collections raised direct questions about the genocide once perpetrated against the Herero tribe in the former German colony. Pierre-Louis Blanchard explains that these concerns have been compounded by shifting sensibilities with regard to our relationship to death and the dead. Back then, anthropological textbooks offered practical guidelines for exhuming bodies. Even handling human flesh was “not problematic” at the time. The Basel Society for the Natural Sciences also had no compunction about making public the circumstances in which they acquired their two Fueguians, as they happily published the details in their annual report. And no one back then questioned whether those circumstances were either legal or legitimate. At the same time, the collectors didn’t just see themselves as beholden to science alone, explains Blanchard, but also in a position of responsibility towards the indigenous peoples themselves. The collectors believed them to be threatened by both modernity and colonisation, and they wanted to secure these peoples a place in human history by collecting cultural and biological evidence of their existence. That is precisely why the bones of Santa Inéz were so “valuable” to the Basel Society; they were “the remains of a tribe that is dwindling without hope [of survival]”, as the Society wrote. Only parts of these two collections truly raise ethical concerns, Blanchard insists. And where these exist, there is no guarantee that historical knowledge can help us find an answer to the questions we have today. Blanchard hopes that his research will at least make a contribution to the “fundamental knowledge” that is often lacking in the debate – namely about the origins of the bones and just how they entered these collections in the first place. “Many objects are badly documented”, he says, “and many museums have until now only engaged with the problems in a defensive manner”. The Natural History Museum of Basel is supporting Blanchard’s work. The head of its anthropological collection Gerhard Hotz explains that it is part of a long-term programme in the field of provenance research. Daniel Di Falco is a historian and a journalist at the Bund newspaper in Bern.

Hitchcock was right: the same photo looks happier to the audience when they’ve first seen a clip from a comedy. After seeing the horror clip, the same photo came across as more fearful. The study also showed that the impact can last at least one-and-a-half minutes.  

Young professionals who start their working life in temporary jobs earn on average eight percent less than their peers who enter permanent positions straight after finishing their training. “However, it very much depends on the sector”, says the researcher Laura Helbling. In low-wage environments such as the hospitality industry or the basic service sector, wages can even be 14 percent less. But when people do a more demanding apprenticeship – such as in the commercial sector – the wage difference is almost negligible. Helbling offers one possible explanation for this: employers in the catering industry or agriculture might tend to outsource (seasonal) risks and employ more people in a temporary capacity. This can result in gaps in someone’s CV – which is a handicap for them when they go job-hunting or enter into wage negotiations. In sectors with more stringent requirements, however, temporary jobs can certainly serve to open up doors, says Helbling. “Here, employers may see temporary employment or internships as a trial period in advance of a permanent contract”.  

This walnut-shaped painting is our brain seen from above. The colours indicate the direction of information flows: longitudinal in green, transversal in red, and vertical in blue. The corpus callosum, which connects the two hemispheres, is the clearly visible red shape in the centre. The technology behind tractography is diffusion MRI. This imaging technique is different from conventional MRI as it reveals the movement of water molecules, not their locations. As water molecules move first and foremost along the axons, they can be used to trace paths. “This image is only a first step”, says Girard. “My team and I are characterising axons in even greater detail, in terms of their size or number, which helps us look for links to diseases”. A local degeneration of neuronal tissue, for example, can affect signal transmission and could therefore show up when using tractography. Daniel Saraga

The ‘flippening’ is complete: just a decade ago, video games were considered straw men. They supposedly caused teenagers to isolate themselves in a world cut off from reality and to become violent. But now that simplistic and hysterical view has been abandoned in favour of one that sees an accepted relationship with a new culture. Experts are even happy to point out the economics of it all: the video-game sector is bigger than the film industry, and in Swiss universities there are courses on game design. The turnaround runs deeper still. Some job candidates are now emphasising on their CVs their collaborative experience playing online games – the well-known MMORPGs such as World of Warcraft. This might typically take the following form: videoconferencing via skype with teammates in Korea, multitasking between skirmishes and strategic plans, filtering avalanches of information and occasionally pulling all-nighters to achieve targets and outpace the competition. These just happen to be skills required and desired in today’s professional world. The growing importance of digital literacy and its codes and practices cannot be ignored. Video game enthusiasts enter the labour market with a head start: they have already learned to evolve in both the real and virtual worlds. Science is now interested in the benefits of playing video games. But it would be illusory to think that today’s gamers will necessarily be tomorrow’s model employees. This is a somewhat naïve hope, and it harks of the discomfort experienced in response to the general upheaval brought about by the digitization of society. In the face of the unknown, we often rush to the first remedy that rears its head, attributing it with quasi-magical powers. Schools as well as parents will have a crucial role to play. Faced with our children’s passion for the virtual world, we must put to one side apprehension, misunderstanding and indifference and focus on talking and understanding. That is, if we are to speed up the preparation of a new generation – as well as an old one – as we move forward into a real world which certainly looks increasingly like a game, but one in which bonus points, free lives and other ‘restart’ buttons are sorely lacking. Daniel Saraga, chief editor

In less than 10 years, perovskites have become an established part of solar cell research. Scientists in the United States, Korea and Switzerland are all studying this family of crystalline materials. And the technology is rapidly improving: the stability of photovoltaic collectors has increased from a few hours to more than 40 days, and yields have increased fivefold from four percent to more than 22 percent. Solar panels are made up of many cells that do not always operate at the same time. This can be problematic for modules based on both perovskites and traditional silicon. “Any cells in the shade act as barriers to the current generated by those cells exposed to the sun”, explains Bertoluzzi. “If the voltage difference exceeds a certain threshold, the circuit is overloaded and can become damaged”. Silicon can withstand voltage differences of more than 10 volts without sustaining damage. Perovskite prototypes only tolerate differences of one to four volts, but they are capable of reversing some of the harmful effects. If the scenario continues or repeats itself, however, the damage accumulates and leads to reduced performance, followed by cell death. Lionel Pousaz

Romain Felli first wanted to be a notary “to earn a lot of money”, then a geographer to preserve nature, and finally a civil servant in the European institutions. He tried his luck at skiing too, although his “elegant but not fast” moves took him no higher than second place in the special slalom of French-speaking Switzerland. Finally, he realised that nothing fascinated him more than research. The pieces of the puzzle are now interwoven: Felli studies climate change policy. He’s currently an assistant lecturer at the University of Lausanne and a lecturer at the Institute of Environmental Sciences of the University of Geneva. He’s an elegant thirty-year-old known for his bow ties, and he spends his working hours analysing what international institutions are doing to protect the environment. His work is at odds with the standard discourse on global warming. “In fact, current political governance is in no way able to limit the rise in temperatures”, he says. “The dominant model does not dispute the orientation towards environmentally destructive growth, but rather intends to draw opportunities from it. This can be seen in adaptation programmes that seek to expand market mechanisms, for example through private micro-insurance programmes for small farmers”. Felli is the son of a former director of the Alpine ski school in Leysin, Vaud, and he first became interested in climate change when he saw that the resort was threatened. “I realised it was going to happen, neither far away nor in the distant future, but in an environment I was familiar with”. For the past ten years or so, Felli has been working on the discourse on the subject, such as the way in which ‘climate refugees’ have become ‘migrants’. He then turned his attention to the now omnipresent concept of ‘resilience’, which promotes adapting to global warming rather than combatting it. “His work is totally innovative”, says Géraldine Pflieger, the director of the Institute of Environmental Sciences at the University of Geneva. “Just reading it changes your world view”. She considers Felli to be “an atypical researcher who combines both a critical approach and methodological rigour, while being a brilliant theorist”. Felli is currently analysing the World Bank’s discourse on resilience and deciphering the sociology of the experts involved. Three quarters of them went through the same English or American universities”, he says. “Yet many studies in this area have shown the importance of local knowledge”. Felli refuses to be a catastrophist, but looks harshly upon the call for adaptation, behind which “lies a major political failure, that is, not having succeeded in changing the economic structures driving the overexploitation of resources”. This trend abides by the neo-liberal logic of ‘better adapted = better off’. “Measures to reduce greenhouse gases benefit everyone, while adaptation measures benefit only those implementing them”. Felli avoids being an easy target for reproach and criticism by putting his own skin in the game. Two Tuesday evenings of every month he switches from theory to practice, as councillor of a local authority in Lausanne. What’s more is that the bright-eyed Felli has broken away from his liberal family tradition, having been a Socialist Party member since 2007. Felli sits on the financial sub-committee for industrial services, which is mandated to lead the energy transition in Lausanne. Despite his climate change expertise, he has refrained from acting as a specialist. What has been brought to his attention through his research, however, are certain points, such as “possible measures against the formation of heat islands during heat waves”. As the father of a five-year-old boy, he has proposed the installation of paddling pools in public parks and the planting of urban orchards. The president of the Lausanne Socialist Party, Benoît Gaillard, sees Felli as “a true social democrat, just as interested in changing things in the here and now, as in changing ideals in the longer term”. It’s not just his academic work that influences his political activities; the opposite is also true: “My election to the local council has made me very aware of the difficulties faced by coalitions and political and economic constraints that come with institutional structures”. Felli is barely concerned that the two roles are “not watertight”. On the contrary, he sees them as “mutually beneficial”, provided that the nature of each institution is respected and “the respective roles assumed are well understood”. Felli does not fear for the supposed neutrality of research. “My projects focus on elements that I consider politically important, but that does not influence the direction of my research”. In his view, neutrality is less important than explaining points of view and methods, bearing in mind his aim of research reproducibility. “By following my approach, a person of another political orientation should achieve the same results, even if he or she might not have asked the same question in the beginning”. If there is one question that is rarely directed at Felli, it’s about leisure time. Even so, when his commitments do afford him time off, he shares his life with a social scientist, and skis with his son on the trails of his native Leysin. For as long as the snow is still there.

“We want to capture the reader” How is Higgs doing so far? Extremely well, considering that we didn’t spend anything on marketing. After 13 weeks, we’ve reached 6,000 unique visitors per month and 1,700 subscribers on Facebook. Why don’t you sell your content to other media? Because almost no Swiss newspaper is ready to pay for science stories. Readers don’t want to pay for news, and now publishers want articles for free. Is that sustainable? No. And it’s neither desirable nor good. But free content is the only way. It’s also important in the fight against fake news, which spreads seven times faster than facts. If you have a paywall, you can’t compete. You get your income from a foundation. But who should really be supporting you? Society, industry, universities… All of them should have an interest in spreading scientifically sound information. We are looking for support from businesses, the wealthy, towns and cities, foundations… I think that the media in general will go in this direction. It’s not such a bad model: a foundation creates a layer between the donors and the content. That way we’re independent of particular interests, publishers and advertisers. … but also of your readers. That’s correct. But we still want to ‘seduce’ them. We have to. For instance, we offer them a short story or a spectacular science picture in order to lead them to a longer story. It’s like a flower attracting a honeybee. We want to capture the reader. On the one hand, your stories appear on several media. On the other, you publish articles by external journalists and paid content. What is Higgs’s real identity going to be? Our platform is not completely open. We will still choose what appears on Higgs, and we follow our own editorial and ethical guidelines. Interview by Daniel Saraga



It’s unlikely that anyone reading a novel stops to think about how the genre originated with Renaissance book printers. But it’s true. It started out as a trade practice, dating back to the appearance of the first printing presses in France around 1470. The goal was to compete with books written in Latin imported from Germany and Italy. But “the publishers then identified a niche: the vernacular”, explains Gaëlle Burg of the Institute for French and French Studies at the University of Basel, and “they began to call urgently for works in French”. Burg’s field of study is the advent of the chivalric novel as a literary category between the Middle Ages and the Renaissance. The publishers drew on medieval chivalrous texts and reformatted them for their readership: setting them in prose, reworking the language and introducing new iconography. It involved changes to both substance – shifting from medieval symbolism and motifs of courtly love to stories revolving around warlike exploits, and appearance – replacing the Roman lettering with Gothic and dividing the text into chapters. Interestingly, the concept of a title page also originates here. “These book printers created a certain number of broad characteristics that would lead to the delimitation of a general category – the chivalric novel – based on distinct medieval literary forms”, says Burg. Her work involved analysing the changes in a corpus of five works, stretching from the first handwritten editions to those printed in the French publishing hubs of the 16th century. In total, some one hundred works became part of a re-emergent literature. Books describing knighthood reached their peak around 1540, but despite their subsequent decline, they were reborn as part of the foundations of the genre of the romantic novel.



“Every morning, I set out from my modest suburb of Ouagadougou, leaving behind the frequent water and electricity cuts. It took almost an hour by motorbike through the often-chaotic traffic. When arriving at the hospital, I was always struck by the smell of urine and death. You needed a solid constitution. I was in daily contact with people suffering and who could only be given little relief. Cancer kills more people in Africa than AIDS, tuberculosis and malaria combined, but in 2015 Burkina Faso had only four oncologists for its 18 million inhabitants. My thesis in ethnology focussed on cervical cancer. In particular, I’ve sought to understand how official guidelines for the management of the disease, issued by national or international institutions, are implemented on the ground. I concentrated mainly on the university hospital in Ouagadougou. I was given a post on the nursing staff of the gynaecological service, and wore a white coat. As I had no medical training, I took care of odd jobs, which allowed me to justify my presence. In total, I attended over 400 consultations, observed care and conducted numerous interviews with patients and staff. I found the medical teams to be generally very receptive to official instructions and new techniques, but they face great difficulties when it comes to training and resources, which in turn can lead to a ‘DIY’ approach. For example, samples of pre-cancerous lesions collected during screening should be sent to the laboratory in a specific single-use medical container. Since patients must provide them, but often can’t afford them, hospital staff reuse bottles of injection medicines. They bottle the sample and wrap it inside a latex glove to keep it as sterile as possible. Patients, for their part, often fail to fully understand cervical cancer, which is a little-known disease in the country. In 80 percent of cases, it is detected at an advanced stage, by which time there is little that can be done to treat it. Doctors rarely explain to them the severity of their illness, instead telling whoever accompanies them, and leaving them to decide whether or not to pass on the information. Officially, they fear patients will give up the fight if told they are doomed. But in reality, there is often no treatment available. The African medical community was the subject of several studies between 1990 and 2000, which accused medical personnel of mistreating their patients. I’ve now had the opportunity to note that denigrating behaviour is indeed a reality, both verbal and physical. It is, however, above all a form of self-protection. The medical teams suffer the violence of being unable to treat patients, given the lack of means and possibilities of early detection. Against these feelings of frustration and weariness, they forge themselves hard shells. Sometimes when talking with patients, I even found myself adopting the authoritarian tone of the medical teams. I feel a little ashamed when I think about it, but at the same time it was a way of fitting into the environment, of making myself understood and of being accepted, both as a person and as a scientist. I also had to accept that I could not always be master of my own affairs. On the contrary, I was the one who put myself in this big puzzle. Originally, I thought my research would promote me to the role of a representative for those patients receiving little or no care. In the end, I became more of a caregiver. Once my thesis is finished, I would like to share my results with the doctors I have worked with, official institutions and various associations. In this way, I hope to raise awareness and encourage reflection on some practices that could be improved – despite the constraints on the ground”. Interview by Martine Brocard

Twenty healthy, male coffee-lovers took part in the study. Their average daily consumption of caffeine was 470 milligrams – an amount roughly corresponding to five cups of coffee. Every test subject was given three different pillboxes for eleven days each. One tin contained only caffeine pills, another contained a placebo, while the contents of the third tin meant the men consumed caffeine for nine days, then placebos for the last two. After they’d finished each pillbox, they went to the sleep laboratory. Whether the test subjects consumed the active pills or the placebos made no difference to the research results. In other words, if the stimulant was constantly available, then the test subjects developed a tolerance for it. “It astonished us that human beings can adapt themselves so much to a constant consumption of caffeine”, says Carolin Reichert, the study leader. But the effect of caffeine was noticeable elsewhere. If the test subjects withdrew from it for two days, then took a nap of an hour, they felt sleepier overall and less attentive than after having consumed only caffeine or placebos in the preceding days. So withdrawal does have a short-term effect.

An old, squidgy cucumber; maize salad with grubs; and a cook working with her bare hands. These images aren’t very appetising, but they encapsulate the topics that Christina Hartmann, a nutritionist at ETH Zurich, is using to measure degrees of nausea among consumers. Her questionnaire is phrased in objective, neutral terms, but the imagination of her test subjects provides the rest. Images of other people’s saliva and blood rise up in your mind’s eye, and of bugs crawling through our food. You can almost smell the putrefaction and taste the slime. If these mental images make you cringe or feel sick, you’re reacting quite normally. “The ability to feel nausea is inborn”, says Hartmann. Disgust is one of the basic human emotions. It’s a strong, universal feeling that protects us from infection: “As a rule, we’re disgusted by things that we believe could make us sick – such as putrid, contaminated food”. Yet this nausea isn’t universal, because it’s influenced by society and culture. We learn throughout our childhood and youth to react with disgust to specific triggers, and these can change. “Frequent contact with foodstuffs that we used to find disgusting can mitigate our reactions”. Hartmann and her team of researchers are using a series of studies to investigate how feelings of nausea influence our eating behaviour. This is because what we either spurn or accept on our plate has far-reaching consequences – also for the environment. Hartmann has developed two instruments for measuring disgust – one with photos, one without. Over a thousand people in Switzerland filled out her questionnaires. And a hundred people also allowed Hartmann to observe them in an experiment. They were presented, for example, with dried-out mealworms garnished with chocolate – a product that you can actually find on the market. Mealworms have been allowed as a foodstuff in Switzerland since 2017, as have crickets and locusts. Their results confirmed existing findings, according to which women are quicker to feel revulsion than men. “Because women can get pregnant, it’s advantageous for them to be more sensitive when it comes to feeling nauseous reactions”, thinks Hartmann. This sense of disgust offers them greater protection from possible sources of infection. As we grow older, these feelings of nausea diminish, but then they increase again in old age. Is it because the elderly are especially prone to illness? This isn’t clear yet, according to Hartmann. But she and her team have instead found a clear correlation between a heightened sense of disgust and either a rejection of new foodstuffs or highly selective eating behaviour in general. Disgust-sensitive people also tend to feel revulsion at gelatinous, soft textures. “Even when the foodstuffs themselves are not dangerous – such as overripe fruits and vegetables”. It’s notable that situations involving a lack of hygiene don’t induce strong feelings of disgust. For example, the image that came last on the scale of disgust was one of bare hands wearing rings, kneading minced meat. In this case, the health risk was probably being underestimated, says Hartmann. Her studies have shown that a sense of disgust can be highly useful to us, but can also stand in our way. Hartmann has concluded from her findings that triggers of disgust should be avoided in order for us to promote environmentally friendly behaviour. If overripe fruit and vegetables could be processed so that we didn’t see their brown patches or their wizened exterior, we could reduce food waste. And we need to prevent feelings of disgust if we are going to make palatable new foodstuffs that could serve as climate-friendly meat substitutes – such as insects. This could start with what we call them. “‘Insects and worms’ doesn’t sound very tempting. But even when it comes to meat, we talk of steaks and cutlets, not of the species of animal they come from”. What’s more, new foodstuffs would be better accepted if they were connoted as positive or trendy and eaten communally. The best example of this is sushi bars. In our part of the world, we tend to regard raw fish as something disgusting, but as ‘sushi’ it’s become hip. Hartmann is now going to investigate disgust-sensitivity in other countries, from France to Sweden, China, South America and Australia. Apparently, fried grubs are regarded as particular delicacies at Asian street markets.

Today, healthy pensioners are travelling the world, dancing to keep themselves agile, looking after their grandchildren, and doing volunteer work. Whereas getting older used to be equated with a loss of our physical and mental abilities, ‘active ageing’ is the new paradigm. With demographic change and increasing life expectancy, our notions about old age are also shifting. It’s a sign of civilisational progress, but one that threatens to make certain groups of elderly people feel forgotten and increasingly excluded. This is shown in a study carried out by the Zurich ethnologist Francesca Rickli among elderly people with limited mobility. The 35 people involved were all from German-speaking Switzerland, over 64 years of age, and were either unable to walk unaided, or could only manage a few metres on their own. Some of them had lived with this disability even before retirement, while in others it was age-related. Rickli visited these men and women during their everyday routines over a period of several months. Most of them struggled with their inability – either recent or long-term – to grow old ‘successfully’. “This is because disability, infirmity and dependence on others aren’t part and parcel of this picture of active ageing”, says Rickli. In the case of those with old-age-related mobility problems, this resulted in them rejecting the use of zimmer frames or wheelchairs, even though these would provide them with greater mobility and more opportunities for a social life. It’s also notable that some of the participants in her study said they felt under pressure on account of the public debate about assisted suicide. Elderly people who’ve already been living with disabilities for a long time ought to have better access to support, says Rickli. To this end, it would also be necessary to make adjustments to the Swiss social security system.

Using these measurements, the researchers have developed a new classification system with seven different ‘flow regimes’ – which is more detailed than hitherto schemes. For example, the researchers can show how different regimes sometimes overlap in large avalanches, and can also demonstrate what external factors have an impact – such as temperature and slope.

Scientists disclose all their study plans and experimental designs; they write daily blogs about their progress in the lab, revealing every detail; and then they publish in open-access journals that are assessed through an open peer-review process. And their results are stored in databases that are on open access to everyone. This is the utopia of open science. Are we about to attain such a state of transparent research? Well, things are unlikely to develop quite so straightforwardly. Sometimes it's because there's just not enough money. Sometimes people aren't in a position to set up the required databases. And sometimes scientists hesitate to reveal their data because they fear that competitors could steal their ideas and publish them first. The successes achieved by Big Science in laying open research data are deceptive – whether at the nuclear research centre CERN or in genetics research. In many fields outside the big projects, there are still major obstacles to progress. It's easy to insist that data should be made freely available. But individual researchers who have neither the means nor the expertise can be driven to despair over it. And because individuals and small research groups find it difficult to place their data on open access, it means other scientists find it difficult to use that data. "Many researchers lack the time and the knowledge they need to be able to document their data adequately and make it available", says Benedikt Fecher. He is currently doing his doctorate at the German Institute for Economic Research and the Alexander von Humboldt Institute for Internet and Society in Berlin, and he has been investigating researchers' attitudes to open science. In the USA and Europe, the research funding organisations have proclaimed their support for data disclosure. But this isn't enough to enforce the standards of open science. Researchers also need organisational, financial and personnel support. This is just what is offered by the Swiss Centre of Expertise in the Social Sciences (FORS), for example. It helps with processing, documenting and storing research data in the social sciences, and provides the necessary infrastructure for it. Researchers can attend workshops to gain further skills and get access to online tools for data management, for instance. Open data is already established in the natural sciences, but the social sciences are still shy about the concept. This is partly because they usually work with personal data that is subject to data-protection laws. But this isn't the only reason. According to Alexandra Stam, the head of the Data Promotion group at FORS, one of the problems is that social scientists are in general not used to documenting their data in a standardised fashion. "Many researchers don't realise that their data can have an existence after their own work is completed". This means that much potentially valuable data and many important details are lost unnecessarily. This predicament is in part a result of how people are trained today. Data management isn't taught formally as part of degree courses, says Stam. And often, researchers simply fail to document their data during their project, but instead only start the documentation process when it's nearing completion. In some countries, such as the USA and the UK, a data management plan often has to be provided when an application for research funding is submitted. In Switzerland, this is not yet the case. Stam hopes that it will happen soon. Furthermore, it's essential that data should be stored in permanent databases after it's been documented and placed on open access. Otherwise, the issue of data maintenance can be left up in the air after the end of a project. We still can't be overly optimistic about the prospects for open data – despite institutional assistance such as that offered by FORS. Even when researchers aren't left to cope on their own, many still hesitate to reveal their data. In his survey, Fecher has discerned a discrepancy between a generally positive attitude to open science on the part of researchers, and their personal hesitance to reveal their own data. Often, the fear of intellectual property theft is what holds researchers back. This risk might be heavily overstated, but it can't be denied that there have indeed been such cases. The genetics researcher Titus Brown at the University of California in Davis reports that competitors once used his data for their own articles after he had placed it on open access – articles he could have written himself. Nevertheless, he remains an advocate of open science. Brown is convinced that it's of use to research. Naturally there are also other reasons for this hesitation. People might be in favour of transparency, but it can still be held back by certain established rights. In empirical medical research, for example, it is still the custom today – however antiquated it might seem – for the author of data to be listed as the co-author of any new studies based on it, says Fecher. Many observers complain that there is a general lack of incentives to disclose data. Today, researchers are measured by the quality and quantity of their publications. But there is no similar academic recognition for datasets. "Researchers would welcome it", says Fecher. Stam also believes that such an incentive would be significant. "It's important that people recognise the usefulness of good data management for their own research – above and beyond the act of sharing data". Nevertheless, in recent years, many so-called data journals have emerged that place their main focus on publishing new datasets. The best known of these is probably 'Scientific Data' from the Nature publishing group. But archaeology, the geosciences, chemistry and other branches of science have also seen the emergence of subject-specific data journals. These specialised media will fill the gap until the day when research data is given formal recognition. When it comes to revealing the research process itself, things are a little different. Such as in 'open lab notebooks'. The ecology researcher Carl Boettiger of the University of California, Berkeley, began putting his research notes online when he was still a doctoral student. As he admits today, he was simply lucky: he went about it quite naively, and none of his bosses took umbrage at his notebook. But this isn't usually the case. Some young researchers irritate their colleagues by being a bit too candid about what they put on open online access. In some cases, they can even damage their careers. Boettiger uses his notebook primarily as an aide-memoire and to exchange information with colleagues, whom he can refer directly to specific content. Now and then, his co-authors of articles ask him to hold back sensitive information, he says. But otherwise, he always writes up everything straight away. None of his ideas have as yet been stolen from his open notebook. Along with the assorted vague worries that exist about open science, there is, however, a real problem with open lab notebooks: they can eat up too much time. According to Boettiger, you have to familiarise yourself with special programs, depending on your degree of IT knowledge. Because he is overall keen to simplify open science in all its facets, Boettiger founded the project 'rOpenSci' a few years ago. It's a platform that offers software for processing and disclosing scientific data, and which is also useful for keeping lab notebooks. Naturally, open science isn't confined to data and communication. In open-source projects, hardware and software are also transparent. Circuit diagrams and construction plans are placed on open access – just like the source code of open-source software, explains Lorenz Meier, a doctoral student at the Institute for Visual Computing at ETH Zurich. Meier has worked on several projects together with outside companies. He was usually able to insist on working with open hardware and software. In the case of open-source software, that also meant companies were often prepared to pass on the improvements made during the course of a project. Together with his colleagues, for example, Meier developed the autopilot software 'PX4' that allows you to control drones and miniature airplanes. The software and the instructions for the hardware are offered as free downloads. Nothing else would make any sense, says Meier. "For drones, the open-source solutions are even better than military software". No longer is any company in a position to prevent the new development of better software. Meier thinks that his collaborations with companies work well – though not always right from the outset. In his experience, companies tend to block open access when problems occur – for example, if they feel that their business model is under threat. In order to dispel such resistance, you have to explain where a company can actually make money from a project. And it's rarely the construction plans or the software that bring in income. Instead, it comes from marketing the company's expertise and services. Oliver Gassmann works at the Institute of Technology Management at the University of St. Gallen. He confirms that models such as Linux, where the source code is openly accessible and enjoys no protection, have proven themselves in the marketplace. Companies have recognised their advantages to the extent that they sometimes even donate patents to the open-source movement. "That means new standards prevail much quicker than they would with protected solutions", says Gassmann. In such cases, the company's task is to seek added value elsewhere. Basically, Gassmann finds that the cooperation between research institutes and private companies is a positive thing. The companies get access to fundamental knowledge, and the researchers get additional funding. Open science could cause conflict, however, if the researchers were to publish so early that they reveal the current state of the technology while a patent application is still being processed. But this is a fundamental problem that also occurs in classical collaborations between universities and business partners, says Gassmann. With open science, the problem is simply exacerbated. This call for transparency can be pushed too far, however, if open information is misused in order to damage the reputation of scientists. Climate researchers – especially those in the English-speaking world – can testify to the frustrating impact of data disclosure such as is allowed by the 1967 US Freedom of Information Act. Often, such information has subsequently been used to disparage mainstream climate research. Michael Mann of Pennsylvania State University is probably the most prominent victim of such activities. So it's not so easy to decide just how far researchers should go in disclosing their work. The pressure to be overly transparent can also lead to unwanted results. Self-censorship, for example, can lead to conformist behaviour. And that in turn would be counterproductive to open science's hopes for success. When the rights of third parties are involved, the private sphere can become a minefield for open science – such as when patient data from clinical or genetic studies is made accessible to third-party medics. The consequences can be really exasperating. Doctors with patients suffering from very rare diseases need to know of concrete, comparable cases to help them find the best possible therapy – but data protection laws have until now often stood in their way. Nevertheless, solutions do exist, even for such difficult cases. In 2013, for example, the 'Global Alliance for Genetic Health' was founded – a worldwide association with more than 380 institutional members. It develops sophisticated procedures so that patient data can be shared safely and effectively on a volunteer basis. It has made a carefully differentiated permit model for the release of data by patients, and has developed algorithms to aid data access. Ultimately, such an exchange of patient data should support research into cancer and into rare and infectious diseases. There is still a lot to be done if we are going to realise the cultural shift towards open science, despite all the obstacles.

Optimism would seem to be a beneficial character trait for someone whose job is to develop answers to some of the most difficult ethical questions facing society today. As a professor of health policy and founding head of the Health Ethics and Policy Lab at the University of Zurich, Vayena studies the regulatory challenges that accompany advances in health and medical technology. She studies the privacy, fairness, and freedom of choice issues that today’s regulatory frameworks are simply not equipped to address. Genomics and gene sequencing, for example, allow us to know more about patients’ futures than ever before. “But what information should we share with them, or with others? Should this information remain private or be used for the greater good?” Vayena asks. Vayena hasn’t always been in academia. She first came to Switzerland in 2000 to work for the World Health Organization (WHO) in Geneva. “I started out studying history and the history of ideas, but I became more interested in the controversies I encountered in ethics and medicine – especially those relating to assisted reproduction and genetics”. At the WHO, Vayena researched reproductive health in developing countries, focusing on infertility. While not usually associated with developing nations, many of which suffer from overpopulation, infertility impacts health and wellbeing in these regions just as it does in developed countries, Vayena explains. She studied how new reproductive technologies could alleviate suffering in these regions, and whether such technologies have a place when health resources are limited. As part of this work, Vayena travelled to support local groups in implementing ethical research programmes and practices. She says her experiences left her in awe of the researchers she met. “When I was in Myanmar, I was so impressed by how candidly they spoke about their challenges, their lack of funding, the ethical norms they valued, and human rights”, says Vayena. “I was inspired by their resilience and determination to improve their research and their lives, and to defy obstacles. They would build their own cars to get around – I rode in one of them”. Following the birth of her first daughter, Vayena decided in 2008 to return to academia via a habilitation programme in bioethics and health policy at the University of Zurich. Another area of interest for Vayena is citizen science. Although the movement isn’t new, smartphones and the Internet have allowed participants to share more data more quickly and more widely than ever before. For Vayena, Switzerland is an ideal place to study citizen science questions, such as: how can we protect participants and their data, and engage everyone in decisions about science? “It’s really interesting for me to be doing my research in Switzerland, because of its tradition of direct democracy”, she says. “I’m interested in learning how we can create new norms to help manage problems of ethics, health and data. And how do we create norms? Ideally, through reflection, democratic participation and deliberation”. Vayena can now participate in such deliberation, having obtained Swiss citizenship last year. As luck would have it, her first trip to the ballot box included a vote on the regulation of pre-implantation genetic diagnosis – a controversial procedure that involves the genetic testing of human embryos in vitro, before they are implanted in a woman’s uterus. Vayena voted in favour of revising Swiss law to allow the procedure, which was the choice accepted on 5 June 2016. A democratic model also prevails in Vayena’s lab: “I like to create an informal setting without too much hierarchy; we work hard and laugh a lot”, she says. “In my lab we don’t use pipettes. I like to think of it more as experimenting with ideas”. Next year, Vayena and her team will begin work on an SNSF-funded project combining big data, ethics and health. Vayena is also at the forefront of the new Swiss Personalized Health Network (SPHN), a CHF 70-million National Support Initiative coordinated by the Swiss Academy of Medical Sciences and designed to accelerate personalised health through harmonised frameworks for medical data in Switzerland – and potentially beyond it. And if she still has time after that? Vayena says that long-term, she’d like to study the influence of artificial intelligence on medical research and health care. But for now, she’s content to find spare time to spend with her daughters. “I talk to them a lot. They’re growing up trilingual – speaking German, Greek and English – so I answer a lot of questions! And every summer we go back to Greece. They are better on the Swiss ski slopes than me, but at least I can hold my own on water skis”.







“Technological innovation and economic growth began when our ape-like ancestors produced simple stone blades, using one stone to knock flakes off another”. This quotation was taken from the financial magazine World Finance and is a reflection of the current view of the mechanism that has led to humanity’s accumulation of wealth. It is a trait of our species. It results from an innate and universal drive that has developed throughout our evolutionary history, and which is still present in contemporary society. Any attempt to control the growth of production to reduce the overall environmental impact is destined to fail; it will clash with a fundamental aspect of our mind-set. However, empirical studies have produced a much more complex image of the psychological side to our economic behaviour. For example, behind our desire always to have more lies our aversion to loss, and coming hand in hand with our propensity to maximise personal interest is a spontaneous and continual desire for equality. The result is that the different impulses of our brain converge into a complex interaction of biology and culture. Both in economics and elsewhere, human nature seems to show plasticity. Both Adam Smith and the schools of classical and neoclassical economics that followed saw ‘the progress of opulence’ in societies as based on two deeply rooted individual drives: the desire to improve one’s lot and the need to be acknowledged by others. Each drive aims to increase the wealth of the individual continually, through perfectly rational means. Smith argued that this stretched back to the dawn of time and that human beings were naturally equipped with a propensity to maximise their personal interest. As of the 1970s, behavioural economics started attacking the foundations of this vision. On the one hand, classical economics saw rationality as perfect, but it now seems that it is not. When faced with a choice, we use neither all of the information available to us, nor all of the resources of rational logic; we most often make intuitive judgement calls, produced automatically by the fast-reacting circuits of our brains and not our analytical faculties. These “fast and frugal” heuristics, as they are called by Gerd Gigerenzer and Daniel Goldstein, often allow us to get things just right, but they also lead to what psychologists call ‘cognitive bias’. This bias opens us up to influence and leaves us vulnerable to manipulation by economic actors, who can push us to make decisions that go against our own interests, according to Klaus Mathis, a law professor at the University of Lucerne, in 2015. In the 1990s the MacArthur Economics Network drew together approaches from experimental economics, psychology and anthropology. This network of researchers, including the pioneering neuro-economist Ernst Fehr of the University of Zurich, observed that the vision of human nature at the heart of economic theory was blind to a number of elements. “People care both about other people, and about how social transactions occur—not just the outcomes”, they wrote in an article in 2004. Laboratory and field experiments led by these teams, both in the West and further afield, showed no sign of the Homo oeconomicus that they had expected. What they found was Homo reciprocans. In this individual, “the logic of ‘reciprocal fairness’ takes precedence over selfish self-maximizing behaviors”. Intercultural comparisons show that the psychological impulses behind our economic behaviour vary greatly among groups of humans. There may be a universal human nature, but it is expressed in a number of different ways when it comes to the mutual construction of culture. There is a contemporary vision of economic anthropology and psychology that aligns itself closely with that of Adam Smith, as put forward by Bruno S. Frey of the University of Basel, a specialist in the economics of wellbeing. “Our research on wellbeing shows that having an advantage in terms of material resources is very important to those who have very little. What we see is that, if someone has a low income and their income later increases, there is a spectacular growth in their life satisfaction. This is because they are leaving behind poverty which is a very unhappy situation”. Those who are already better off will still try to increase their incomes, but they do it for very different reasons. “If you are a senior manager, you will compare yourself with your colleagues in similar positions. But, even if you earn more in Switzerland than you would in France, Germany or Italy, you will still tend to compare yourself with peers in the US financial sector, who are paid even more”. This is a universal law, says Frey. “There seems to be an innate tendency to compare oneself with those who are in a better situation. This envious tendency is not necessarily a likeable feature of human nature, but the systematic comparison with people who are more successful is what pushes humanity forward”. A third impulse makes up the system, maintaining it in perpetual movement even for a person at the top of the prosperity ladder. This is the familiarisation effect. This impulse leads us to perceive an objectively constant state as increasingly less satisfying, the longer it lasts. In other words, our minds perceive what is an unchanging quantity of resources to be a decreasing quantity. This is because our expectations fail to stop adjusting upwards. “This familiarisation factor plays a more important role, when it comes to income, than in other areas of life. It neutralises a large part of the increased effect on individual material well-being”, says Frey. According to Jörg Rieskamp, a psychologist and specialist in economic heuristics and decision-making, also at the University of Basel, there is one other factor that explains our desire. “Evolution has clearly given our species hedonic preferences. We tend to seek pleasure and to avoid unpleasant situations. But that does not mean that we are driven to grow in such a way as to make us want more than we have. From a biological, evolutionary point of view we just cannot identify such a drive. What we can see is, on the one hand, an element pushing us to achieve the necessary resources for survival, and on the other, a drive to avoid loss, in other words, a strong tendency to avoid losing resources”. So, what then is the relationship between loss aversion and growth impulse? “In principle, once we have sufficient resources, we are happy with preserving the status quo. But in reality, it is difficult to keep things safe. There are always fluctuations, uncertainty and risk. Our tendency to avoid all potential negative change drives us to seek security by always aiming to have a little more resources in the immediate future. We are therefore trying to accumulate more material goods, because we see that as the safest strategy for avoiding having less, even if deep down we would be happy with the status quo”. It is conceivable that these psychological faculties make up only one of a range of possible states of mind. This is the argument put forward by Christian Arnsperger, the director of the University of Lausanne’s Institute of Geography and Sustainability. He sees the psyche of H. oeconomicus as corresponding less to the immutable human nature inherited from the hunter-gatherers of the Pleistocene and more to a “cultural and political project”. In Adam Smith’s time, this was a humanist approach, “enabling the emergence of a society free of the shadow of hunger and early death”. Is H. oeconomicus therefore an exclusive product of the European 18th century? “I’m not really in favour of purely historical explanations: I think that there is a human foundation that stretches throughout history”, says Arnsperger. “But within this human foundation, there is an ongoing internal debate. The human in favour of growth is only one of the possible variants of the human being”. We are very far from being truly determined by a rigid neurobiological programme, and we do indeed show some anthropological plasticity, in other words, an “innate capacity to overcome our innate faculties”, leading to a large range of different ways of being a human being. Interestingly, the biological sciences are also showing a similar image, where even the genome and the very architecture of the brain can lead the way to a variety of different behavioural and physical results. How has this quest for increased wealth led to a behavioural second nature? On the one hand, it is a consequence of economic mechanisms themselves. “The creation of money, for example, came hand-in-hand with the creation of debt, and henceforth individuals and societies have the obligation of growth”, says Arnsperger. On the other hand, “growth is being increasingly presented as a collective project. No individual acts spontaneously with the goal of macroeconomic growth in mind. However, what we see in the political discourse is an increasing frequency of the suggestion that contributing to growth must be a personal motivation. It is of course true that there is a minority holding capital who do have a direct interest in economies growing incessantly as a whole”. So, as Arnsperger argues, we are faced with an unprecedented task. “Faced with the progressive destruction of all of the key elements of our biosphere, creating a culture of sustainability for human life on Earth does not just mean stopping all growth, but electing a selective and temporary growth model, made up of conscious decisions with regard to where growth is desirable and for how long”. He also calls for a real “anthropological transition”, which will be made possible thanks to the very plasticity of nature. “Of course, today we need to lead this project in a different way than through the top-down employment of constructivism used by totalitarian movements”.



What is your main goal as AILA’s president? To focus on linguistic research that truly matters for society at large. For example? Our world is multilingual. Mass migration and globalisation present serious challenges to integration, but also offer huge opportunities for fostering diversity. Hiring has become more and more international. Using international English is not enough, though. To communicate efficiently, you have to understand not only the words, but also what people mean when they use them. This is when intercultural communication happens. How do you plan to bridge the gap between academic research and society? We want to collaborate systematically with practitioners right from the start, when research projects are conceived, and not only when the results are communicated. For example, we are collaborating with UNESCO to develop language programmes that include intercultural aspects. Is AILA mainly concerned with multilingualism? Applied linguists have a broad understanding of what a language is. Even if everybody in a company speaks the same language, they still use different varieties and different technical terms. This internal multilingualism presents issues similar to those we have between languages. Or take the concept of translanguaging, which questions the idea of fixed borders between languages. They interpenetrate each other and our entire life. As a Swiss person, you are used to a multilingual environment. Does it make it harder to understand monolingual cultures? Like many Swiss people, I’ve grown up between cultures – and I think it actually helps because we are at ease in different contexts. In any case, most communication in the world is intercultural and multilingual. Wherever you go, you see people not understanding each other. We researchers have developed tools that can change that.

A solid mass comprised almost solely of air – it sounds almost too good to be true. But this fabulous material really exists. Aerogels are light, porous solids that are produced from dried-out gel and are perfectly suited for use as heat insulators. But that’s not all they’re good for. This research is still in a very early stage, however, and Nyström insists that there is no way as yet of guessing what the costs might be. But Matthias Koebel from Empa is convinced that no one will be concerned about high costs if the material in question is conceived for a specific purpose, if it’s the best on offer, and if only small amounts are needed. These unusual product ideas are in any case probably unsuited to mass production. At present, mass production is anyway only possible for silica-based aerogels. These are the class of aerogels that have been investigated the most and that are the most widespread. They are also the only aerogels that are commercially available at the moment. Their processing technology is already at an advanced stage of technological maturity, way beyond the laboratory stage, says Koebel. But if this silica aerogel is to have any chance of being used to insulate houses, making it will have to become quicker and cheaper. To this end, Koebel and his team are now working on more efficient production processes. When you produce silica aerogel, says Koebel, first you have to dissolve a precursor material like silicon dioxide in a liquid such as alcohol. After its solid particles have linked up to form a gel, the wet material then has to be dried. And there are different ways of doing this. Up to now, the drying process has usually involved exchanging the one solvent with another. In one variant, for example, you can replace the alcohol with carbon dioxide – typically at a pressure of roughly a hundred atmospheres and at a temperature of over 50 degrees Celsius. After the carbon dioxide has drained off, the aerogel remains behind as silicon dioxide in the form of a netlike, ramified structure. The equipment needed for this is relatively expensive, and the production cycles require a lot of time and maintenance. What’s more, the procedure consumes a lot of energy. These are issues that will undergo a decisive improvement in Koebel’s new process. One very important factor in production is adding chemical substances to the solvent to make the aerogel water-resistant. “Otherwise, the aerogel could later become saturated with water”, explains Koebel. That would make it useless for heat insulation. It could also crumble, and that in turn could make components fail. The search for improvements is ongoing. Now, the researchers at Empa and in a spinoff called Nexaero are developing a “semi-continuous” production process. This is a common-or-garden approach to batch production which proceeds step by step in a range of stirrer tanks. But it would be unsuitable for Koebel’s aerogel production because it is too slow. In a semi-continuous process, however, only a few interruptions occur between adding the raw materials and getting the finished product at the end. When the drying is over, the granules should then emerge “as if from a baking tunnel for croissants”, as Koebel jokingly remarks. That would be a major step towards mass production. Koebel believes that small-scale production will be possible as early as 2020. If everything goes according to plan, large-scale capacity will become available just two years after that.

In an email today, the International Journal of Research on Neuroscience has invited me to submit an article in order to make the results of my “groundbreaking” research accessible to a broad readership. Open access, of course. In the eyes of the journal’s editors, I’m an “esteemed researcher” and a “leader in the field”, even though I’ve never actually done any research in the neurosciences.

Affolter believes that the decisive importance given to ‘credibility’ in asylum proceedings stems primarily from the difficulty that arises from any attempt to lodge an appeal against a supposed lack of it. “By questioning their credibility, you shift the burden of a rejection onto the asylum seekers themselves. It essentially makes them personally responsible for any decision made against them”, says Affolter. The main goal of this project was to gain an understanding of the decision-making processes. So the researchers haven’t formulated any concrete recommendations for action. “But we are ready and willing to discuss our findings with the authorities”, says Julia Eckert. Astrid Tomczak

Her straightforward manner surely also helped – not just when it comes to dealing with skeletons. And her enthusiasm will also have played a role. “I wanted to delve into the Stone Age since I was a little girl”, says Lösch. There was a kids’ book that set her off, and she can still remember the title: ‘How prehistoric people lived’. And she always wanted to know: “How did they find their food? Who had the idea of domesticating animals? Did someone just call out one day: ‘Hey, there’s a cow, let’s catch it’?” Sometimes she dreams of a time machine. But as long as these don’t exist, she’ll use bones instead. They can be almost as good. The fact that her working group is situated in the Institute of Forensic Medicine is something of a red herring. To be sure, Sandra Lösch and her team are consulted when skeletonised or mummified corpses have to be identified for criminal cases. “There’s maybe one such case every two months”, she says. But her research focus is really in the field of bio-archaeology and paleopathology. She wants to find out what millennia-old, (pre-)historical skeletons can tell us. To this end, she is aided by both high-tech analytical techniques and – as is so often the case in her discipline – by sheer good luck. Luckily, the boy’s family promptly informed archaeologists of their discovery. It took just five months to excavate the skeletons. The researchers worked day and night, wearing gloves and face masks, and to be extra-careful they also took DNA samples of their own saliva for comparison purposes, so that they could exclude any contamination that might nevertheless occur. Archaeologists and anthropologists used to be primarily concerned with morphology. In other words, they used the form of bones to determine the age, gender and body size of skeletons, and were also perhaps able to make a rough estimate of their origins. Today, researchers can also apply the whole arsenal of modern biochemical analysis. Genetic analysis enables them to clarify family relationships thousands of years later, and also to investigate pathogens. Stable isotopes offer information about diets and migrations, and can do so in chronological order: tooth enamel is only formed during childhood and youth, and the isotopes stored there can provide information about where the person in question lived during their youth. Bones store information on the previous ten to twenty years, hair on the last few months. In future, researchers will even be able to reconstruct characteristics such as hair colour and eye colour by using ancient DNA. “It’s really cool”, says Lösch. It’s even helpful in criminology. Recently, her team helped to name a corpse that had no identification papers on it. Their isotope analysis showed that it was a man from the former Yugoslavia who must have entered Switzerland between three and seven years earlier, and who also spent his final months here. The analyses of Oberbipp are still ongoing, and the results are eagerly awaited. Other studies by the Bernese working group can already give an intimation of what is possible. Using finds from an Iron-Age burial ground at Münsingen-Rain (ca. 400 to 200 BC), they were able to show that men ate more meat than women, especially in cases where they were buried with weapons. Conversely, they were surprised to learn that the diet of Roman gladiators in today’s Turkey mostly comprised barley and wheat, which is indicative of low social status. Isotope analysis also proves that many early societies were patrilocal, with their womenfolk coming from outside. In short: “We answer research questions in the humanities by using methods from the natural sciences”, explains Lösch. Lösch hopes that they will also soon be able to make a contribution to medical knowledge with a new DNA laboratory at their Institute in Bern. She wants to focus more on investigating old illnesses. When and where did the pathogens of the plague and tuberculosis first occur, and how did they travel? When did they become virulent? How did they evolve over the millennia? Until now, the only information we’ve had has been found in unreliable chronicles. “We want statistics, not speculation”, insists Lösch. Christian Weber works as a science editor at the Süddeutsche Zeitung.

Experts were never really that popular. People don’t like to be told what’s best for them, and anyone who insists on accuracy is soon labelled a know-it-all. Experts early on had to learn to live with ridicule: they might know a lot about their own subject, so it went, but they didn’t have a clue about ‘real life’. The American satirist Ambrose Bierce mocked “specialists who know everything about something and nothing about anything else”. The crisis in expertise doesn’t just affect science. Doctors tell of patients who don’t ask for advice, but simply demand treatments they’ve found on Google. Architects and craftsmen tell of clients who want to dictate to them how to do their work. And teachers often have to cope with parents who aren’t prepared to accept that the answers their child gave in a test are actually wrong. The reasons for this phenomenon are as diverse as the problem is widespread. Nichols writes of a negligence that comes with prosperity: “Our highly technological world functions so smoothly that people mistakenly start to believe that everything is really simple. You click on a button, and your e-mail flies halfway round the world. No one thinks about all the experts that make it possible, from the engineers to the software designers and the diplomats”. Another reason is the trend towards treating students like customers today, asking after their wellbeing instead of challenging them. This can lead to an excess of self-confidence that is coupled with less knowledge. Two other reasons for this crisis of expertise are to be found within our science system itself. On the one hand, we are experiencing the revenge of postmodern relativism. Starting with Nietzsche – who claimed that there were no facts, just interpretations – left-wing theoreticians in particular have fundamentally questioned whether there is any such thing as objective truth. The philosopher Michael Hampe from ETH Zurich claims that this is why it’s difficult to counter the arguments of those who wish to relegate the notion of man-made climate change to a mere thought-construct. On the other hand, experts have constantly been venturing beyond their own field of competence. “Scientists can state the degree of probability that measles will break out in a kindergarten if 20 percent of the children aren’t vaccinated”, says Dietram Scheufele, professor of life sciences communication at the University of Wisconsin (USA). “But it’s not their job to decide whether or not to introduce compulsory vaccinations”. This is a political issue that can only be answered through the political process, he insists. Scientists should certainly offer their opinion, but they shouldn’t claim to be acting with any authority (as they often do), as “this can only mean they lose their credibility”. They should accept the fact that moral and religious notions play a role, says Scheufele. “Friedrich Dürrenmatt put it really well: ‘if something affects everyone, then everyone has to solve it’”. None of these undesirable trends would have culminated in our current crisis without one decisive factor: the Internet. It was naïve to think that the boundless availability of information, free of charge, must surely lead to the triumph of knowledge. In truth, the opposite has happened. Sound knowledge and informed opinions today exist on an equal footing with conspiracy theories and mere gossip. What’s even worse: fake news often spreads quicker and further than facts. Social media are intensifying these negative developments. “We’re all friends on Facebook”, says Tom Nichols. “That has led to the absurd notion that we all know as much as everyone else and everyone’s opinion is equally valid”. The Internet has also contributed to this loss of respect, because people have far fewer inhibitions online than when speaking to someone face-to-face. What’s more, social media serve to promote an effect that psychologists call ‘confirmation bias’. In reality, people rarely form their opinions based on facts. Instead, opinions tend to be dominant, and people then seek the facts that confirm them. The Internet makes it far easier to find such ‘facts’ – supported by algorithms that supply us with hits that affirm what we want to believe. “This is the paradox of our new world of information: it has never been so easy to get all the information you want”, says Dietram Scheufele. “But it has never been so easy to avoid all the information that you don’t want”. The current crisis in expertise isn’t actually a crisis of science. In Europe, scientists are still regarded as trustworthy, and in the USA, 90 percent of the population – both Republicans and Democrats – have a positive opinion of science. The problem is that people seek out the science that happens to suit them. And this might just turn out to be the study about alleged links between vaccinations and autism that has long been revealed to be fake. So it is inevitable that people don’t become less ideologically minded as their knowledge increases. Instead, they become even more beholden to those ideologies. This has been shown to be the case with man-made climate change. Among Democrats, the more people know about it, the more they believe it; but the opposite is the case among Republicans. The American psychologist Ashley Landrum recently reported on a fascinating experiment she conducted. She had test subjects read an article about the dangers of the Zika virus. But she had two different versions of the article: the one linked Zika to climate change, the other to migration. Republican readers showed concern when they’d read the migration article, whereas Zika in the context of climate change left them cold. The exact opposite was the case among Democrats. In Europe, the situation does not yet seem to be as dramatic or polarised as in the USA. But a glance at the wider political situation doesn’t exactly foster optimism. To give just one of many examples, we need only consider the triumph of the Movimento Cinque Stelle in Italy, which insistently supports vaccine sceptics. The concurrent crisis in journalism doesn’t make things any easier.  “It’s already five to twelve”, says Stephan Russ-Mohl, professor of journalism and media management at the Faculty of Communication Sciences, University of Lugano. “In the fight against fake news, we’ve got our backs against the wall”. Despite all the initiatives that already exist, we can barely reach people”. Science urgently needs something along the lines of a communication strategy. It’s not enough to be right in principle. Because as the above examples prove, people are rarely willing to abandon their convictions through arguments alone. “If facts challenge the ideology of your conversation partner, mentioning them can be counter-productive”, says Gleb Tsipursky, a science historian at Ohio State University with an interest in psychology. “People speak of this as being the ‘backfire effect’”. This is why he recommends first exploring the emotional state of your conversation partner. Why is he so angry? What’s troubling him? In a second step, you have to demonstrate sympathy for his problems. Only when you’ve done this groundwork should you bring your arguments – but you should do this, wherever possible, so that you don’t come across as diametrically opposed to the fundamental convictions of your opposite number. By following these steps, Tsipursky claims to have been able to change the minds of several science sceptics. Getting to grips with people’s values could also work in other fields. A study at Emory University in Atlanta, for example, has shown that vaccine campaigns don’t have much impact if they strike a moralising tone and highlight the danger to vaccine-ineligible children. Vaccine-sceptical parents don’t generally react to the value of ‘fairness’. You’d have a better chance of success if you pointed out that vaccines strengthen the body’s natural resistance and give you greater control over your health. Another approach from communication psychology is so-called framing. This means the art of giving a topic a specific slant by carefully choosing your vocabulary. This can help you to shift the audience’s emotions in the direction you want. Dietram Scheufele offers a negative example that’s been successful: the expression ‘Frankenfood’ for genetically modified foodstuffs, which immediately awakens notions of science being out of control.  “This concept was quite intentionally coined by an organisation opposed to genetic engineering. It has such a powerful impact that it’s difficult to combat”. This is why it’s all the more important for scientists to consider early on how they should talk about their topics. For example, there is a new book entitled ‘A Crack in Creation’ about the genetic engineering method CRISPR, written by Jennifer Doudna, a researcher from Berkeley. “It sounds good”, says Scheufele. “But it will tread on the toes of the almost 60 percent of Americans for whom religion is very important”. It reads as if this new technology contradicts the values of a large portion of the population. “If such a notion gets established, it’s almost impossible to rectify”. The situation is pretty messed up. Science is in the process of losing the race – even before it’s really noticed that the race is on. “First, the scientists have to realise that they actually have a problem”, says Gleb Tsipursky. “Then they have to stop seeing themselves as lone fighters and start to club together”. Tsipursky has set up a movement called ‘Pro Truth Pledge’. It gets experts – along with journalists and interested laypersons – to commit publicly to spreading only information that’s been verified; they also have to correct their own mistakes and the mistakes of others, and must always differentiate between facts and opinions. This might sound obvious to a scientist. But it’s probably wise in today’s age to cease assuming that anything is obvious at all. When it’s suggested that science sceptics are hardly going to be won over by such a project, Tsipursky answers that there are still enough people situated between the two opposing poles who might respond to such an approach. Hardened sceptics are probably hopeless cases anyway. But what if scientists communicated directly with the public on a more regular basis – such as via social media, blogs or newspaper articles? “That would be desirable, but there are no incentives for it”, says Russ-Mohl. Scientists have enough on their plate, he says, because they need to publish in specialist journals to maintain their standing. “For as long as PR isn’t explicitly rewarded by the organisations that fund science research, it’s unlikely anything’s going to change”. Furthermore, many scientists have adapted quite comfortably to living in complete disregard of the public. Of course it’s difficult to discuss things with laypeople, especially when they’re recalcitrant. “It often seems to me like I’m arguing with kids”, says Tom Nichols, who gives many public lectures, writes popular articles and is a passionate tweeter. “For example, if you correct the false assertion of someone you’re listening to, you’re immediately accused of being elitist and arrogant”. Nevertheless, this is something that experts mustn’t shy away from: “Whether they like it or not, experts have to get involved”. Maybe mathematicians and surgeons might be excused, but all those who deal with politically controversial topics ought to take part – the so-called ‘public intellectuals’. “It’s our duty to discuss things with the public and not just among ourselves”. Nichols is less optimistic. If you ask him for a general assessment of how things stand, his answers can be pretty frightening. It is tragic to think, he says, that this rampant narcissism might only disappear if it culminates in a catastrophe – such as a war or economic collapse. Because in crisis situations, people suddenly feel a need for real expertise again. “In the emergency room”, says Nichols, “you don’t see many people arguing with the doctor”.

With land, sea, and air conquered, humans have since yearned to stake their claims in outer-space. But there’s still space to be claimed underground. In the past, we drilled for gold and oil. Now we’re after geothermal energy and groundwater, not to mention new transport routes and deep foundations for towering buildings. From a resource perspective, the ground under our feet is ripe for exploitation, but that same perspective also takes in new issues: who owns what and what uses should take priority? So far, Switzerland has scarce legislation, but that’s beginning to change. The Swiss land-planning law is currently pending review and there are moves to expand its scope to include the subsoil and bedrock, which would be welcome. If there is to be coordination among the burgeoning numbers of projects of national importance, inter-cantonal barriers will have to be torn down without delay. The role played by science is very important too, as there are still gaps to be filled in our knowledge of the Swiss bedrock. One step in this direction has been taken by Swisstopo. It has developed a tool to chart the geological layers and faults of the Swiss Plateau in three dimensions, making it a potentially valuable planning aid. In the end, it will be up to politicians and civil society to debate whether we want to prioritise geothermal energy over transport or to preserve groundwater over the environment generally. We also need to start by asking about how it can all be managed sustainably. This may seem paradoxical – who’d believe you could ‘use up’ the bedrock? – but forward thinking really is important, because an underground structure can’t be demolished. We’ve almost entirely overexploited the environment. Now it’s time to adopt a different approach to our use of resources and manage the underground sensibly and wisely. Daniel Saraga, Editor in chief

We have less snow in the winter, longer dry periods in the summer, and water is getting scarcer. This scenario doesn’t bode well for farmers. In July 2018, for example, the canton of Thurgau banned the drawing of water from streams, rivers and ponds. The researchers chose maize for their case study, which is a widespread crop in Africa. They incorporated different data in their model, for example data on agricultural practices – such as when the crop is planted, when it’s harvested, and whether or not fertiliser is used. Then they added geographical data, such as slope and elevation, soil information, and daily climate data such as solar radiation and precipitation. The sources of their information are the Food and Agriculture Organization of the United Nations (FAO) and the World Meteorological Organization (WMO). This enabled them to divide up the whole of sub-Saharan Africa into small regions of roughly 50 square kilometres each, in which they could determine what factors were the biggest threat to the harvest, and where. For example, it rains rather too little in the Sahel and in the south of the continent, whereas in Central Africa it is generally the high temperatures that are the problem, because more water evaporates through the leaves of plants. Yang admits that their work is complicated and highly theoretical, but insists that it is very useful: “We want to develop a consistent way to measure the degree of crop vulnerability. Although there are many discussions on drought vulnerability, there is little study on how to quantify it”. But can anyone really profit from the results of this model? Chinwe Ifejika Speranza, a professor of geography at the University of Bern, offers a qualified answer: “‘Yes’ at the national planning level, but ‘no’ at the local level. More detailed and context-specific data is needed for such applications at farm level”. In developing countries, the main factors are usually the social and economic conditions of the local farmers. “For example, farmers may receive early warning information but still won’t change their planting dates. Maybe they haven’t the money to buy the right seeds, or have no trust in the early warning system”. If farmers are going to integrate this new knowledge in their daily lives, they’ll need contact with local, practically oriented researchers and agricultural advisers as well as with the theoreticians behind the simulations. This is why Pierluigi Calanca from Agroscope (the Swiss centre of excellence for agricultural research) is interested in the work of Hong Yang. As they link drought exposure with crop sensitivity, “her ideas are suitable for discussing the vulnerability of production with local stakeholders. They enable you to separate the influence of the climate from the impact of crop sensitivity”. But this can also function in Switzerland. Calanca has been involved in several pilot projects at FOEN. He sees agricultural information centres – whether public or private – as the ideal places for researchers, farmers and advisers to exchange ideas on cultivation strategies. “Ultimately, it’s personal contacts that are needed”.



In the Swiss Programme for Research on Global Issues for Development (the r4d programme), the Swiss Agency for Development and Cooperation (SDC) and the SNSF together support transnational research partnerships with countries in Africa, Asia and Latin America. The programme replaces traditional North-South research and is intended to provide funds for global sustainable development. Between 2012 and 2022, almost CHF 98 million is being provided. Researchers have to apply for monies from the rd4 programme in a competitive process. Up to now, 225 research partners in 41 projects across 42 countries have participated. The Swiss Tropical and Public Health Institute in Basel (Swiss TPH) was founded in 1944. It is recognised across the world as a leading institution in the fields of tropical diseases and public health. In competitive tenders, the TPH regularly competes successfully against consulting companies. At present, the TPH employs over 700 people from more than 60 countries. Just under half of its 2015 expenditure of CHF 76.7 million was spent on research. Almost all Swiss universities are involved in development research. The best-known example is the Graduate Institute of International and Development Studies (IHEID) of Geneva, which researches in areas such as peace-building, the environment, trade, migration and health (also under the auspices of the United Nations). Another example is the International Graduate School North- South (IGS) at the Center for Development and Environment at the University of Bern, which emerged out of the former National Centre of Competence in Research (NCCR) North-South. Its aim is to establish an international research network. Currently, over 100 people from Asia, Africa, Latin America and Europe are studying at the IGS. The two Federal Institutes of Technology, ETH Zurich and EPFL, are heavily involved in development research. The UNESCO Chair in Technologies for Development has been located at the Cooperation and Development Center (CODEV) of EPFL since 2007. Besides engaging in technological innovations for countries in the Global South, such as in the fields of risk reduction and urban planning, EPFL also runs innovative massive open online courses (MOOCs). At ETH Zurich, development research is carried out in the most diverse areas, from the Mobile Health Systems Laboratory to NADEL, the Center for Development and Cooperation. In Switzerland, the Commission for Research Partnerships with Developing Countries (KFPE) is a point of contact for researchers. Its goal is to make a contribution to solving global problems through fair, sustainable research. The KFPE is financed by the SDC, SNSF and SCNAT. Several networks are active in development research. For example, there is SFIAR, the Swiss Forum for International Agricultural Research, which links interest groups in agricultural research for development. SNIS, the Swiss Network for International Studies, has been promoting interdisciplinary research since 2008. And the Development and Cooperation Network of swissuniversities, SUDAC, is being built up in answer to the universities' increasing activities in the field of development research. Its goal is to improve the framework conditions for research and teaching in cooperation with partners from the Global South. There are further important funding organisations such as foundations, some of which have been set up by companies, and the NGOs. It is difficult to estimate how much of their expenditure flows into development research.

In Europe, 2017 is a ‘super election’ year. There are going to be elections in the EU’s two big players, France and Germany, and in several other countries. But this time everything is different. Since Donald Trump’s success in the US presidential election, a spectre is haunting Western democracies: digital populism. Controversial discussions have now been taking place about whether there is a connection between the success of the populists and their social media campaigns. Researchers are hesitant about drawing conclusions. At the Institute of Communication and Media Studies (icmb) at the University of Bern, Thomas Häussler warns against blaming Facebook and other social media for the successes of the populists. “Of course populists make clever use of social media – here in Switzerland, that primarily means the Swiss People’s Party (SVP)”, says Häussler, who is researching into political communication and online mobilisation. “But for them it’s just one more channel of communication”. The classical media still have more of an influence on the political opinion-forming process, he says. In Switzerland, that’s mostly the newspapers. Elsewhere, it’s the TV. If we were to pull the plug on Facebook tomorrow, the political landscape would not change fundamentally, he says. The political polarisation that already exists would not disappear overnight. Fundamentally, however, online platforms and populism are indeed an ideal combination: “Populists look for a direct line to the people”, explains Sven Engesser of the Institute of Mass Communication and Media Research at the University of Zurich. At the National Center of Competence in Research (NCCR) ‘Democracy’, he is researching into populism and the mass media. “Facebook and Twitter enable them to feel the supposed pulse of the people, and to convey their messages to them without the detour of using the classical media”. The role of social media in the rise of populist movements has until now been subjected to remarkably little scholarly research, says Engesser. Research into digital populism is made more difficult because there is no generally recognised definition of ‘populism’. This is itself in part a result of the heterogeneity of the parties and movements generally described as being ‘populist’. Engesser and other researchers at the University of Zurich have been engaging with the content that populists from Switzerland, Austria, Italy and Great Britain have been spreading on the Internet. What they all have in common is that they see themselves as the ‘true’ representatives of an idealised people that is in constant conflict with supposedly remote elites. The digital content of the populists largely corresponds to their offline content. Whereas left-wing populists tend to attack the economic elites – thus large corporations and banks – the right-wing populists fire off tweets, make posts and publish online articles against political elites and migrants. Criticism of the traditional mass media mostly comes from the right wing. In this rejection of mass media, Thomas Häussler sees an important characteristic of populism in the Internet. It is particularly pronounced in the debate about the so-called ‘lying press’ in Germany. “In historical terms, the public prestige of journalists was never very high. But in recent years it’s sunk even further”. The media now receives widespread, basic criticism of a kind that was unheard of for many years. And the populists are turning this loss of trust to their advantage. Häussler says: “They accuse the traditional media of being part of an elite that is conspiring against the people and intentionally trying to manipulate them”. This accusation is diametrically opposed to the values propagated in journalism’s codes of practice, such as independence and a responsibility towards the public. It is not surprising that many populist parties – in Switzerland, that’s first and foremost the SVP – are demanding the downsizing or even the abolition of public service broadcasters, because they are supposedly the standard-bearers of the elite. In its online expression, however, this anti-elitist stance leads precisely to a dissolution of journalistic standards. Suddenly, dubious sources such as the Swiss conspiracy theorists’ portal ‘Alles Schall und Rauch’ (‘All hollow words’) is afforded the same journalistic significance as a Neue Zürcher Zeitung. Gut feeling and ‘healthy common sense’ count more than expert knowledge and verifiable facts. It has even become easy to spread fake news by means of fictitious online articles that mimic the style and layout of the traditional mass media. Engesser and Häussler suspect that a conscious political strategy lies behind this. People who feel insecure tend to seek support from charismatic leaders and simple ideologies. And this is exactly what the populists offer. This erosion of journalistic standards can have a long-term negative impact on political processes. Under these circumstances, the media cannot fulfil their role as the fourth estate, with their function of critique and oversight. If everything is relative, it becomes ever more difficult to form a fact-based opinion and to debate political topics. “You then get stuck in the meta-discussion as to whether the basic information presented by the media and experts is actually true – indeed, whether anything at all that the media report is true”, says Häussler. “In extreme circumstances, this way of thinking undermines democracy”. This relativisation of facts is promoted even further by so-called echo chambers or ‘filter bubbles’. These two concepts have become common-place and are used to describe the tendency for people to surround themselves on the Internet with others who think similarly, and who engage in mutual confirmation of their attitudes. This phenomenon is not new, when one considers that newspapers faithful to specific parties dominated the Swiss scene until the 1960s. Thomas Häussler agrees, but he points out: “If you wanted to know that there were other opinions apart from the one in your party newspaper, you just had to take a step back at the kiosk for you to see the newspapers of the other parties”. Taking a step back – adopting a neutral, bird’s eye-view, as it were – is no longer possible in the Internet, says Häussler, because with every new click, its users are constantly changing their communicative network. Algorithms use their activity to ensure that users see content that corresponds mostly to their own presumed worldview. And this trend is further intensified by the micro-marketing companies that have specialised in tailored Internet advertising. Up to now there has been no empirical proof that filter bubbles in the Internet have helped the populists to electoral victory. Both Häussler and Engesser assume that there is a so-called spill-over effect, meaning that, by reporting on tweets, blogs and Facebook entries, the traditional media act like continuous-flow water heaters. They merely serve to amplify the impact of those tweets and blogs, far beyond the actual bounds of social media. To survive in the battle for coverage (and thus for advertising revenue), the classical media are increasingly orienting themselves to social media. “Drama, emotions, clear messages – everything that populists offer in tweets and in Facebook posts can get more people to read an online newspaper article, for instance”, says Engesser. These statements often cannot withstand fact-checking. But once they’ve been disseminated, it’s difficult to disprove them. Although the populists and the supposedly lying mass media are at loggerheads, paradoxically they profit from one another, Engesser adds. The tirades of the populists provide the clicks, while the mass media spread their messages. This problem has become especially virulent in countries where politics is highly polarised, and where media supportive of the state (and thus, in the eyes of the populists, allied to the ‘elites’) are unable to assume a moderating function. A paramount example is the USA, where the public service broadcasters are very weak. During the presidential election, the US mass media simply fell short with their cultivation of indignation, says Thomas Häussler. “By taking up every hair-raising tweet by Donald Trump and disseminating it in their quest for clicks and advertising, they ultimately promoted his policies too”. S. Engesser et al.: Populism and social media: how politicians spread a fragmented ideology. Information, Communication and Society (2016)

It took thirteen days for Terri Schiavo to die after the doctors took out her feeding tube. For fifteen years, this 41-year-old woman from Florida had lain in a vegetative state after cardiac arrest and brain damage. Her death in late March 2005 was preceded by a bitter dispute. Her husband wanted to let her die, but her parents fought for her to be kept alive. Both sides claimed they were acting in her best interests. The Schiavo case went through the US courts, was debated by politicians, and attained considerable worldwide attention. It is regarded today as a tragic example of the complexity that such situations can take on – especially when the person actually affected cannot express an opinion. However much we profit from the successes of modern medicine, many people refuse the option of being kept alive, because they don’t want “to be hooked up to tubes or machines”. No one can know in advance how it feels to be in a coma or to have dementia. But people wouldn’t like to be kept alive at any price. It is common in Switzerland for end-of-life medical decisions to be made that might possibly (or even probably) accelerate the inevitable. And such decisions are becoming increasingly common, as has been shown in a study conducted by the universities of Zurich and Geneva. In cases registered in German-speaking Switzerland in 2013 where death was not unexpected, 80 percent of the deceased had taken advance decisions about the end of their lives. In the great majority of cases, treatment was either discontinued, was not begun at all, or more drugs were administered to alleviate pain and other symptoms. In a small number of cases, the people concerned died by means of assisted suicide. This representative data comes from a survey of doctors. But it’s we ourselves who decide about the last things. Patient autonomy has become a core legal and medical/ethical principle in recent decades. It has equivalence with a doctor’s duty of care. Our previously paternalistic relationship with medical professionals – along the lines of ‘doctor knows best’ – has purportedly given way to an interaction between equals. After the doctor has given his or her findings, the patient agrees to a particular treatment – or not. Informed consent is what the experts call it. The Swiss Act on the Protection of Adults, which entered into force in 2013, strengthens the law on the right to self-determination. For the first-ever time, the patient decree, or ‘living will’, was established on a national basis. This allows a person to determine what medical measures they wish to accept or reject when they are no longer able to express themselves. It is binding for the doctor. Even if no such patient decree exists, the doctor may not simply take a decision on his own. He has to consult the next of kin too. But not even their views are binding – it’s the presumed wishes of the patient that are paramount. Studies carried out by the universities of Lucerne and Zurich show, however, that problems are now arising in daily healthcare practice. Regina Aebi-Müller, a professor of private and comparative law at the University of Lucerne, speaks plainly about this: “The patient decree, which attained legal certainty in the Act on the Protection of Adults, is practically useless in its present form”. The researchers of Lucerne and Zurich carried out interviews with doctors and qualified nursing staff to ascertain how decisions about ceasing treatment or refusing it are actually made. It transpires that only a few people have made a patient decree. And when an acute situation actually arises, the decree is often neither available nor up to date. In such situations, it remains unclear whether the patient who is dying in an intensive care unit actually wants to be reanimated, or whether the nursing home resident suffering from advanced dementia should be transferred back to hospital and given antibiotics to treat pneumonia. Doctors are also confronted with patient decisions that are contradictory or impossible to respect. This does not surprise Aebi-Müller, who is studying the legal aspects of patient autonomy within the framework of National Research Programme 67 ‘End of life’: “There are several templates for patient decrees. You can download them from the Internet, and tick the boxes in private”. Patient decrees have to be interpreted, but lawyers are better equipped than medical experts to interpret texts. Aebi-Müller gives an example of where this can end up: a patient suffering from terminal cancer had decreed that she wanted ‘no tubes’. The woman in question later lost consciousness, was unable to empty her bladder, and was visibly suffering. But the nursing supervisor refused to give her a catheter on account of her patient decree. The senior consultant, however, doubted whether the patient would have meant to include this kind of ‘tube’. After the nursing staff’s next change of shift, he inserted the catheter himself. The woman died peacefully that same night. If the next of kin have to make such decisions, they are often overwhelmed, or unable to agree. They don’t know the will of the patient because no one took the initiative to discuss it in the family. This can be a difficult burden for partners, daughters and sons. “One in three people is traumatised by having to make a proxy decision, and doesn’t know if it was what their loved one would have wanted”, says Tanja Krones, Head Physician of the Clinical Ethics Committee of the University Hospital of Zurich. Despite patient autonomy, doctors still have the power to make decisions. A trend has become discernible over the past ten years in which “patients tend to be drawn more into making decisions at the end of their lives”, says Milo Puhan, a professor of epidemiology and public health at the University of Zurich. Few doctors act on their own without discussing anything with their patient and their next of kin, or without any recourse to an earlier expression of the patient’s wishes. The study carried out in Zurich and Geneva showed that in just eight percent of cases where a patient was incapable of making a decision, their doctors took decisions for them. In a further twelve percent of cases, the doctor discussed the matter with professional colleagues or with nursing staff. In a further eight percent, the patients were actually able to make decisions themselves, but their doctors still failed to discuss end-of-life issues with them or their next of kin. Puhan sees one possible explanation in it being difficult to predict the course of a disease. “Diagnosing the phase of dying is medically challenging, and requires a lot of experience”. An Australian study has shown that most conversations about medical decisions at the end of life only take place in the last three days before death. According to how a disease develops, the right moment can be missed altogether. So, research is revealing possible areas of conflict. Aebi-Müller’s conclusion is this: “Medical situations at the end of life cannot be regulated in the manner that the legislators imagine”. She is convinced that any form of “absolute” patient autonomy will not function. More realistic, in her opinion, would be “relational” autonomy. At the end of our lives, when we are particularly vulnerable and suffering from pain, respiratory distress and fear, we are dependent on relationships. Aebi-Müller argues that medical staff should be given greater responsibility to make decisions, though without lapsing into old patterns of doctor-dominance. “There is no decision more personal than that relating to medical measures at the end of a life”. A relationship between doctor and patient that is based on partnership, in which decisions are made together, can help support people in these situations. The Zurich University Hospital is investigating how such support might be given. ‘Advance care planning’ is the name of he concept, meaning structured conversations with patients and their next of kin. Treatment teams trained in communication – doctors, nursing staff, pastoral care workers and social workers – find out in good time about a patient’s wishes for treatment at the end of their life, and also about their personal views. If they become unable to make decisions themselves, what will actually be important to them? What are they afraid of? The Zurich University Hospital offers expert counselling, not just the patient decrees that can be downloaded from the Internet. “People are given evidence-based, decision-making aids”, explains Krones. This means they know the concrete figures: out of 100 people who suffer cardiac arrest in hospital, even with immediate assistance, on average only 17 of them survive. And of these survivors, five to seven of them are later highly dependent on care. Advance planning offers a better guarantee that a patient’s wishes will be known and feasible, says Krones. This is also a relief to their next of kin. Such planning may also result in drawing up a patient decree, but it doesn’t have to. Krones recommends a modular system that ranges from an emergency plan signed by the doctor to instructions for what to do in a case of a chronic incapacity to make decisions. The latter could come about because of dementia, or after a stroke. “What’s important is to keep checking with the patient. Because people change”. Perhaps someone has been diagnosed with dementia and wants to refuse life-extending measures as soon as she can no longer recognise her relatives. But what happens if her loved ones realise that this patient seems happy despite her limitations, laughing and taking pleasure in small things? “We have to address These questions”, says Krones. ‘Advance care planning’ is not yet widespread in Switzerland. Krones’s research confirms findings made abroad, namely that advance planning both helps to meet people’s wishes better, and alleviates the trauma suffered by their next of kin. It also means that fewer people are taken to hospital or are subjected to invasive treatments such as operations. This concept does not aim to lower costs, but it appears to be a side-effect. All the same, the patients don’t die any sooner. This is how we are endeavouring to come to terms with death in a professional manner. Nevertheless, it will always remain something of a mystery. In the words of Ralf Jox, a palliative healthcare professional: “Advance care planning will change nothing about the fundamental insecurity that is characteristic of our existence”. But it could help to increase trust.

Almost half of the carbon dioxide that humans release into the environment is taken up by the world’s oceans and the terrestrial biosphere. In this manner, greenhouse gases are partially extracted from the atmosphere, which alleviates the process of global warming. But will the land and the seas be able to continue storing carbon dioxide in the future? Researchers aren’t sure. Changes in ocean circulation, woodland clearances and stress reactions in forests could reduce their capacity to act as carbon sinks. During their research voyage, Grosjean’s project partners will be drilling on several sub-Antarctic islands to collect sediments from lakes. These will subsequently be analysed in the lab by Grosjean and others. Algae that used to live in these lakes are today found fossilised in this sediment, and they can provide us with information on wind intensity during the Holocene period. Reconstructing these winds means drawing complex conclusions from the data. The salt content of the island lakes is influenced by the wind intensity, for example. Strong winds drive more spray into the air and more salt into the lakes than do lighter winds. This has an impact on the algae, as Grosjean explains: “Algae vary in their sensitivity to salt”. So the species composition of the algae in the sediments can allow the researchers to determine the former salt content of the lake, and thus also the strength of the winds at the time.

It’s a sobering fact for nature conservationists: Of the roughly 45,000 known species of flora and fauna in Switzerland, about a third are threatened, while hundreds have already died out in recent years or are under pressure. Despite all our efforts up to now, biodiversity is vanishing almost unimpeded. In view of this development, Christoph Küffer is campaigning for a rethink in the field of conservation. He’s an urban ecologist who teaches at the University of Applied Sciences Rapperswil and at ETH Zurich. “The countryside areas that are worthy of conservation are too fragmented here for them to be able to retain their biodiversity”, he says. Furthermore, human beings are changing all habitats irreversibly on account of CO2 and nitrogen emissions. The idea of conservation is no longer sufficient in the Anthropocene era, says Küffer. His proposal is ‘nature design’. “In order to maintain biodiversity, we have no choice other than to invent and design a new nature for the future”. Küffer’s idea would be a radical departure from existing practices such as have been implemented in the Swiss National Park in the canton of Graubünden. On its 17,000 hectares, animals and plants are left as undisturbed as possible, and human interventions are taboo. Instead of leaving authentic wildernesses to themselves, Küffer believes that humans should actively maintain and create diverse nature areas. He is even willing to contemplate intervening in conservation areas themselves. For example, he could well contemplate creating low-nutrient meadows on the outskirts of the Neeracherried in Riedt near Zurich – one of the last remaining large fens in Switzerland. The goal would be to create an unnaturally high degree of biodiversity. Even the many small nature reserves in the Swiss midlands could be organised more intensively – in other words, with a greater biodiversity. Nature design would also mean that roof gardens, green façades and parks in urban areas could offer new habitats for species under threat. For Küffer as a maverick thinker, the famous High Line in New York is an exemplary case where his ideas are already being realised – it is a specially designed natural landscape on an abandoned railway line in the midst of the metropolis. “Nature conservation as design means that any and every place has the potential of becoming a nature paradise”. According to Küffer, the biodiversity of the future would be a mixture of wild species, cultivated plants and ornamental plants, right in the middle of our human environment. For Küffer, ‘designing’ biodiversity also means shifting nature conservation away from specialists and from the notion of ‘managing’ it. Instead, it should be the responsibility of gardeners, farmers and even nature enthusiasts – the selfsame people who have always been involved in ‘creating’ nature anyway. This would make nature conservation more varied and less planned. As a consequence, nature design would probably mean that some endangered species would die out, since their dwindling habitats would only be replaced in part. But this is also the case with current conservation policies, insists Küffer. He is convinced that his approach will ultimately be more efficient. Through designed landscapes, many moderately threatened species could be protected, whereas human influence means that even a lot of money could not ensure the long-term survival of highly rare species. Küffer’s ideas are disputed in specialist circles. Markus Fischer is a plant ecologist at the University of Bern and President of the Swiss Biodiversity Forum. He shares Küffer’s view that a conservation policy cannot be viable today if it is based on traditional values that were valid 100 years ago. But he believes that the problems lie elsewhere: in a lack of money and in a lack of political will to implement nature conservation goals: “For effective protection and to promote biodiversity, it would have to be prioritised on roughly 30 percent of our surface area”. This could be carried out partly in conservation areas (which thus far encompass only 10 percent of Switzerland), and partly in agricultural areas that are biodiversity-friendly, says Fischer. Raffael Ayé, the head of the species support programme at BirdLife Switzerland, points out that traditional conservation too is pursuing pioneering concepts. “Since the 1980s we have been using integrated methods to try and protect and utilise areas at one and the same time”, says Ayé. We must never lose sight of nature conservation and preservation goals. “We have to keep investing in the protection of our most valuable areas such as dry grasslands and the National Park”. Just like Fischer, Ayé too is advocating for more support from politicians – in other words, for more money, for a greater degree of appreciation and for better care for endangered habitats. Küffer is aware that many of his colleagues see his suggestions as a provocation. But he does not want to play off different ideas against each other. The current formulae for nature conservation – protected areas and supporting individual species – undoubtedly have their own justification, he says. But he is convinced that “if we are going to maintain biodiversity in a time of climate change, intensive farming and funding scarcity, we are going to need to rethink things and develop new approaches”.

To be able to carry out any experiment you like without leaving your desk, and without having to pick up a single test tube or look down a microscope. That is the vision of the company Emerald Cloud Laboratory, which allows biologists and chemists to design experiments, adjust and monitor instrument settings, and then analyse data with a few clicks of a mouse. Extending the concept of cloud computing beyond simple data storage and processing to the operation of real experiments over the Internet, the idea is that scientists should free themselves from dreary bench work, and use the extra time on their hands to Devise better experiments. Emerald provides this service from a warehouse on the outskirts of San Francisco. There, on rows of parallel benches, a series of liquid-handling robots, automated incubators, centrifuges and other assorted machines manipulate samples according to a precise set of instructions sent by each user through a special web-based interface. With the equipment operating more-or-less autonomously around the clock, results can arrive back on a researcher’s computer within 24 hours of them having requested an experiment. here are still very few companies that provide such a service. The first to do so was a firm called Transcriptic that was set up in 2012, and which is based in a warehouse a few miles down the road from Emerald. But already there are scientists who are enthusiastic converts. Among them is Justin Siegel, a synthetic biologist at the University of California, USA, who says that his research students can test more, and bolder, hypotheses than they could if doing the experiments themselves, and that even fresher undergraduates and school students can get involved. “They can work on designing experiments and not worry about having ‘good hands’ to implement them”, he says. In fact, Emerald risks becoming a victim of its own success. Having started offering its cloud service last October, it currently has a list of several hundred labs waiting for time on its robots. But the company co-founder Brian Frezza is confident the backlog can be whittled down and that within about a year Emerald will offer all of the hundred or so standard experiments used in the life sciences. Currently they can run about 40. “At that point we want to be profitable”, he says. Researchers already have a lot of experience with robots. For years, pharmaceutical companies have been using them to carry out repetitive, time-consuming tasks in early-stage drug development, while biotechnology firms rely on them for manipulating DNA – a growing demand that has been met by instrument manufacturers such as Tecan, based near Zurich. “Most of what humans can do in the lab can now be done by machines”, says Ross King, a biologist and computer scientist at the University of Manchester in the UK. Perhaps the archetype of automated science is DNA sequencing, the process of determining the order of genetic base pairs. This used to require very labour-intensive work that only a few labs could perform. Nowadays it is carried out automatically by machines that read genetic material millions of times over. Those machines are located at centralised facilities, making it unusual now for labs to do their own sequencing, according to Siegel. What Emerald does is “fundamentally different”, says Frezza. Rather than carrying out “one experiment perhaps a million times, like a car factory”, he explains, “we do a million different experiments at once”. But because robots are not very efficient at carrying out a series of steps one after another – as opposed to many versions of the same process simultaneously – on average, their devices are actually slower and more expensive than people would be. As such, his company is not trying to compete price-wise with existing contract research organisations, which use a mixture of robotic and human labour. However, the great virtue of robots, says Frezza, is reproducibility, or, as he puts it, the fact that they “always pipette in exactly the same way”. Taking advantage of this ability, he says, has meant developing an instruction set that scientists can use to specify without ambiguity exactly what steps a robot needs to execute when performing an experiment. He thinks that after several years of working on the problem he and his colleagues have now developed a robust set of commands, but adds that they still need to make the interface more user-friendly. “What tends to get people’s backs up is the idea that they are writing code”, he says. Richard Whitby of Southampton University in the UK agrees that reproducibility is very important. He says that humans’ versatility is a great asset when it comes to carrying out the complex reactions in his field, organic chemistry, but that scientific papers often don’t spell out that complexity in full – neglecting to specify, for example, how quickly reagents should be introduced. Without knowing the value of every parameter in a reaction, he notes, it is difficult to quantify the effect of tuning certain variables in order to improve reactions. Whitby is leading a British project called Dial-a-Molecule that ultimately aims to build a machine capable of synthesising any organic compound on demand, just as biologists today can order specific strands of DNA through the post. He is under no illusion as to how difficult this will be, pointing out that such a machine would need to carry out tens of thousands of reactions as opposed to the four used by DNA synthesisers. “We have given ourselves a 30 or 40-year timescale”, he says. Even more ambitious is the vision of King and his colleagues at Manchester, who aim to “automate the full cycle of scientific research”. Like the cloud-based companies, they use robots made commercially, but then hook those robots up to artificial-intelligence systems. After being educated about a particular subject using logic and probability theory, the idea is that a robot will by itself formulate hypotheses to explain observations, then devise and run experiments to test those hypotheses, before generating new hypotheses and repeating the cycle many times in an attempt to learn something new about the world. King reckons the approach is bearing fruit, and that machines can make science both more efficient and more precise. He embarked on the research while at Aberystwyth University in the UK, assembling a robot called Adam that in 2008 successfully identified several previously unknown genes that encode enzymes in yeast. He has since developed the one-million-dollar Eve, which has gone on to discover the anti-malarial mechanism of an everyday compound known as triclosan – potentially easing the substance’s approval as a pharmaceutical. Beyond biochemistry, robots are also being used increasingly in materials science. Last year, engineers at the US Air Force Research Laboratory in Ohio reported results from a robot with artificial intelligence that had carried out research on carbon nanotubes – cylindrical molecules of carbon that are strong, light, and very good conductors of heat and electricity. The machine carried out more than 600 experiments on its own, varying conditions to try and speed up the growth of nanotubes. Doing so it confirmed theoretical predictions of the maximum growth rate. Some researchers are even trying to automate advances in physics, although they aren’t using robots as such. Hod Lipson at Columbia University in the US and his colleagues have developed an algorithm that generates equations at random and then uses an evolutionary process to select the equations that best match experimental data. In 2009 they reported using their approach to model the behaviour of chaotic double pendula, yielding what they describe as physically meaningful conservation laws. Two years later they followed that up by deriving equations describing energy production from sugar breakdown using data on yeast metabolism. Not everyone is convinced. The American physicists Philip Anderson and Elihu Abrahams wrote a letter to the Journal Science in 2009 accusing both King’s and Lipson’s groups of being “seriously mistaken about the nature of the scientific enterprise”. They argued that even if machines contribute to what the philosopher Thomas Kuhn called “normal science”, they could never transform science by discovering new physical laws – maintaining that in Lipson’s research on pendula motion the “relevant physical law and variables are known in advance”. King acknowledges the limitations of machines, pointing out that even if a robot successfully carries out experiments, it doesn’t know why it’s doing so. He adds that he and his colleagues wanted to include Adam and Eve as authors on their papers, but were told they couldn’t because the robots wouldn’t be able to give their informed consent. Nevertheless, he believes that intelligent robots are set to become more commonplace in science, thanks to the ever-increasing power of computers, improved algorithms and more advanced robotics. “They are getting better, while humans remain the same”, he says. “I don’t see any reason why these trends aren’t going to continue”.



A psychology professor from Germany is teaching a Bachelor course at the University of Geneva – in English. The art history programme at the University of Zurich is offered in German according to the website – but an English course turns out to be part of it. Along with globalised research, the academic elite arriving in Switzerland is teaching students in English. Mostly it’s not even their mother tongue. In response to a query from Horizons, the Universities of Basel, Bern, Geneva and Zurich have confirmed that the trend is increasing. However, there are no statistics as to the proportion of courses taught in English at Bachelor and Master level. English as a medium of instruction can be a barrier, says Josef Stocker of the Association of Swiss Student Bodies (VSS): “For fresher students, language is an additional hurdle”. But it’s not insurmountable, he says, and in many subjects it makes sense to have English as the medium of instruction. He is a student of mathematics himself, and he sees the clear necessity of being able to make yourself understood, also in an international environment. And yet, having courses in English means extra effort for many students, he says. “It would be good to have more transparency at the universities regarding the actual percentage of English-language courses”. Today, he claims, university regulations are sometimes ignored because there are no staff available who can teach in the respective national language. It would also be useful if the universities could actively support students to reach the necessary level of competency in their language of instruction. The regulations, directives and language policies of the Swiss universities are very different, and often also very vague. A directive of ETH Zurich from the year 2010 stipulates that the language of instruction in the Bachelor is essentially German – but English or French may also be officially employed, depending on the respective programme regulations. On its website, EPFL states that French and English are the languages of instruction, though the first Bachelor year will be taught primarily in French. From the second year onwards, up to 50 percent of the courses may be in English, it says. The Master programme can be mostly in English, mostly in French, or bilingual, dependent on the respective curriculum on offer. At the University of Basel, the Bachelor is taught ‘mostly in German’. And at the University of Zurich, the faculties make their own decisions. There are big differences, depending on the subject. In the natural sciences, the life sciences and social sciences, no one can avoid English. And even in the humanities, this is increasingly the case. Pessimists fear an impoverishment of scholarship through the uniformity of language, whereas optimists see a chance for universal understanding through the use of a scholarly lingua franca. You can’t manage without English, says Gerd Folkers, President of the Swiss Science and Innovation Council (SWIR): “Students have to be able to read sources and articles in the original language”. He supports calls for a transparent approach towards the language of instruction at Swiss universities: “It is crucial to make the rules of the game clear”. He also advises dealing with foreign languages in a deliberate manner instead of simply taking arbitrary decisions: “It’s about getting the right balance and about finding the appropriate language for the appropriate content”. With this, he broaches a fundamental distinction in the field of scholarship. Much scholarly content is described relatively independently of any linguistic constructions – in a so-called ‘theoretical language’. This becomes clear in highly formalised sciences such as mathematics. This content is then taught, discussed or reported in a specific language – be it German, French or English. Folkers teaches chemistry at ETH Zurich, and illustrates things as follows: “If I lecture in the English language in German-speaking Switzerland about the biochemical impact of new antibiotics, then I use our theoretical language. But if I speak about its possible application in pig feed and its problematical consequences for human beings, then German might be the better choice of language because the brain can order complex interdisciplinary facts better in one’s mother tongue”. This is why Gerd Folkers argues in favour of a more conscious approach to multilingualism. English might have emerged as the language of basic consensus; “But is a university really the right place for us to agree on the lowest common denominator?”, he asks. He believes it would be more courageous to improve English skills in language courses, in group sessions and tutorials on the one hand, but on the other hand to engage in a multilingualism in order to promote a scientific discourse in the students’ respective first language. After all, if a biologist is taught primarily in English in his main subject, how is he or she supposed to explain a nature conservation project at a local community meeting in German or French? nstead of using a specific language at a specific time, concepts should be introduced in parallel languages at the same time wherever possible – for example, in English and in a local language. Franceschini’s reasoning is simple. She is convinced that “solely monolingual teaching is no longer sustainable”. Thanks to international mobility, the linguistic profiles of academics are getting more varied. And she doesn’t just mean English, which is often the second language of university lecturers: if a professor has roots in Italian Switzerland, but grew up in Germany and studied in England, then he – or she – can quite possibly debate matters better in English than in German or Italian. Language is the means of communicating new knowledge. “The question is: how can you get students to acquire this knowledge?”, asks Franceschini. One way is to link it to knowledge they already possess, she says. This might succeed in either English or in one of the national languages – independently of the competence of the person teaching them. “More attention should be paid to this than to the language concept of a university”. At Franceschini’s university in Bolzano, the official language policy takes the trilingual nature of its region into consideration. Here, German, Italian and Ladin are spoken. Professors are given financial incentives to learn German or talian “at least as an everyday language”, so that they can converse with the students. “Language policies like this would also be preferable at Swiss universities”, says Franceschini. But the reality is different, despite the country’s four national languages. Only a few universities have a language policy that regulates their approach both to the national languages and to English. One of these is the University of Geneva. But when we asked the organisation swissuniversities and assorted Swiss institutions of tertiary education whether professors from abroad should learn one of the national languages, their answer was typically Swiss and federalist: Every university should decide that for itself.

We’re in a laboratory of the Department of Mechanical and Process Engineering at ETH Zurich face to face with cables, containers and gas flasks, all rather small and not at all impressive. Before our visit, Professor Philipp Rudolf von Rohr had promised us that we’d be seeing a “real research facility”. But standing in front of us, atop a chest of drawers, is just a block of metal with a small window in it. We’re told it’s actually a viewing cell in a catalytic reactor. When used together with a Raman spectrometer, the reactor enables the researchers to observe material properties down to the molecular level. The interactions between the light of the laser beam and the material inside the reactor produce the signals that interest experts. Now, at least, it’s obvious that the size of the test setup is inversely proportional to the importance of the project, which is the joint effort of Philipp Rudolf von Rohr and over a dozen researchers from eight countries. “Our goal is to turn CO2 into something sensible”, says Rudolf von Rohr. This isn’t about getting carbon dioxide from the air around us – though it does have to do with our climate. They want to make it possible to turn CO2 into a liquid resource. Using hydrogen, they want to turn this harmful greenhouse gas into a commodity from which they can in turn produce useful things such as fuels. The problem with storing CO2 as a gas is that it requires a gigantic effort. But if it can be turned into a liquid, it can be stored and transported with ease. On paper, the problem looks simple enough for schoolkids to solve. And the research team has already mastered two of the three necessary steps involved. First, two catalysts are used to transform the gases carbon dioxide (CO2) and hydrogen (H2) into formic acid and methanol, which then unite to form methyl formate. Then another catalyst is used to break down this intermediary product into formic acid and methanol again, this time as liquids. The tricky one is the first catalyst used to produce formic acid, or, to be more precise, its interaction with the second catalyst that produces the methanol. Rudolf von Rohr and his team are experimenting with pressure, temperature, retention time, volume, yield, and much, much more. Last but not least, the researchers are faced with the problem of being able to identify reliably everything that emerges, whether by design or not. What’s more, their desired product, formic acid, is also proving to be wayward. There is no simple method for determining what volumes emerge after a reaction. “Measuring it is not at all simple”, says Rudolf von Rohr, who clearly knows innumerable ways of avoiding the concept of ‘highly complicated’. Rudolf von Rohr’s team comprises chemical and process engineers, but they don’t work on their own. “Problems like this can only be solved when different disciplines work together”, he says. There are four groups of researchers busy with it: specialists in catalysts, then analysts who can determine “what actually comes out at the other end”, as Rudolf von Rohr says. Then there are the chemists who are trying to understand what exactly happens with the catalyst. And, finally, there is Rudolf von Rohr’s own group, which is building, running and optimising the apparatus. It wouldn’t work without an interdisciplinary approach, he says. “This research project is worthy of support, not least because it points us in the direction of a CO2-neutral energy cycle”, explains the physicist Reto Holzner. He’s the head of development at Silent-Power, a company that markets electricity generators that run on ethanol. In the light of climate change, developments towards this goal of a CO2-neutral energy cycle are among the most important of all, he says. He sees possible difficulties in the multiple catalysts, while the high pressure involved could become a problem in later, bigger plants. But their findings are ultimately of great importance for Switzerland as a business location, says Holzner. “Otherwise, others will overtake us”.

Back in the days when Asea Brown Boveri (ABB) was still called Brown, Boveri & Cie., the company was already sending its employees from north to south, east to west, and vice versa in both cases. By 1988 at the latest, after its merger and change of name, ABB began to attach increasing priority to ‘best practices’ on the ground and ‘peer education’ in different cultural environments. Many large, globally active companies in the financial and pharmaceutical sectors did the same in order to break down prejudices against local cultures and at the same time to build trust in organisations that had been newly created through international mergers. In the past 30 years, the mobility of employees has become increasingly important across all industries and sectors. It has often happened that the new experiences gained by such ‘wandering’ employees have enabled them to undergo an attractive change in their career path, whether in academia or in different social spheres. At a younger age, it can be especially appealing to experience change within a new organisation – and it’s also easier to cope with it if you haven’t yet started a family. Later, the hurdles to change become higher. This is also why early internships can be beneficial – and not just for students. At present, however, I am observing a contrary tendency. Despite swift, free, borderless communication and a global market, the underlying conditions have worsened for the upcoming generation of students and those young people who are in training. For example, since 2014 Switzerland has only been able to participate indirectly in the European educational programme Erasmus Plus. But student exchange programmes and similar measures are in fact highly relevant for young Swiss citizens whose environment is in any case already multicultural. We have to meet these challenges together with our neighbours, and find common solutions. It is important that we can progress to full association quickly, by 2021 at the latest. This would open up the doors not just to our European neighbours and the USA, but also to the East and to Asia.

The girth and the thickness of skin folds, on the other hand, offer a direct way of measuring body fat. Children with more fat had worse motor skills. “Other studies have shown that these young children notice such limitations – they are chosen less often to be in groups and take less pleasure in moving”, explains the study leader Jardena Puder from the Lausanne University Hospital (CHUV). As other studies have also confirmed, less movement leads to more fat at a later date. This data has been acquired from 84 day-care centres in the cantons of Aargau, Bern, Fribourg, Vaud and Zurich. The effects of age, gender, the socio-economic status of the parents, the linguistic region and even movement measured during everyday activities were discounted. For example, the children in French-speaking Switzerland move 10 percent less each day than children in the German-speaking regions.

With their model, the physicists have developed a new category of worm hole and describe – in theoretical terms – how information stored on a particle (e.g., using its electrical charge) could travel instantaneously to another part of space-time. “Wormholes are today still only theories”, says van Breukelen. “But, in principal, it would be possible to create an artificial black hole, by using a particle accelerator, for example, although it would have to be a billion kilometres long, the same distance the Earth travels around the sun in a year. So it’s an idea that’s theoretically possible, but also many millennia ahead of its time”. This work remains abstract in nature. There’s still a long way to go before computers can simulate the behaviour of particles travelling through a worm hole. “That will require quantum computers, which may not see the light of day for another 15 years. Even then, we’re still talking simulations, but it beats waiting 2,000 years”, says van Breukelen.  

It makes no difference whether the projects are funded by the SNSF or not. “It’s a fundamental problem”, says Briel, who is researching at the Basel University Hospital. His team has analysed why so many RCTs end ahead of schedule. The main problem, they find, lies in the early stages, namely in the recruitment of suitable participants. “Often, the researchers’ estimates are too optimistic”, says Briel. In other words, the doctors are confident there will be enough patients taking part without properly ensuring that the numbers are right. In reality, not every patient will fulfil the inclusion criteria of a study, nor will everyone will be willing to participate either. Especially where a lot of effort is involved. “Another problem is that many studies are too regional in how they’re organised”, says Professor Peter Meier-Abt, the Vice President of the SAMS. Many hospitals in Switzerland are too small to be able to rely on a satisfactory pool of patients. The health system is organised on a federal basis, and most experts see this as a core issue in the optimal organisation of a clinical study. “We really need an overall pool of patients”, says Meier-Abt. But coordinating such a pool across all of Switzerland is difficult. Briel also believes that “you don’t have to limit things regionally to a single Swiss hospital”. Studies that are run in several places can function very well if they are properly prepared and coordinated. The experts are also of one mind with regard to another object of criticism: that doctors in Switzerland are much too involved in everyday clinical work. “We need more time to be allocated specifically for research”, says Meier-Abt. Doctors who are already putting in overtime can’t carry out research on their free evenings or at weekends. Magnin also says: “Treating people is what actually brings in money for the hospitals; but as time goes by, it gets more and more difficult for their clinical personnel to invest time in research too”. “We have to be careful that we don’t miss the boat, internationally speaking”, says Meier-Abt. Denmark, Sweden and the Netherlands are far more advanced than Switzerland when it comes to research infrastructure. And in the Anglo-Saxon world, scholarly work carries far more weight. Preparing something well is the best path to success, says Matthias Briel, who is himself the author of a clinical study: “It’s best to carry out a controlled pilot study with the same study protocol”, says Briel. Doctors aren’t always enthusiastic when they hear this, but various international investigations have confirmed it as a recipe for success. What is also decisive, says Briel, is describing the recruiting process in detail in the study protocol. “The researcher should also run through the ‘what-if’ scenarios at the preliminary stage”, he says. “That way, you can minimise the damage, should your search for participating patients be proceeding sluggishly”. Briel sees social media platforms as a means of expanding the potential group of participants. Initial trials have shown that social media can help to stimulate interest in a study. Overall, the general public has to be sensitised to the fact that clinical research is for the good of everyone, but that it’s only possible if a lot of people are prepared to participate in studies. The ethics commissions could also do their part in making the recruitment process as successful as possible. “When assessing studies, they ought to make the researchers already aware of possible shortcomings in recruiting participants”, says Briel. In the past, he adds, doctors have repeatedly complained that the administrative burden caused by such studies is a major hurdle. Meanwhile, the procedure has been somewhat simplified. The experts are also united in their belief that more should be invested in training young researchers: “Planning and carrying out clinical studies correctly is a discipline all of its own – one you have to learn”, says Magnin. Clinical Trial Units exist today at six Swiss hospitals and act as service providers to the researchers. But their support is costly. Last year, the Federal Office of Public Health launched a roadmap for promoting young clinical researchers. One part of this package entails the creation of a Swiss Clinical Research Education Centre. “Here in Switzerland, we need a clear commitment to clinical research”, says Magnin. Briel is also insistent that “all the key stakeholders must participate in these efforts, and assume their responsibilities in this vital field”. The question remains as to what should happen with the data that is left unused after unfinished studies. “It should be made generally available to later studies, either for meta-analyses or as lessons learned”, says Briel. The National Institute for Health Research (NIHR) in Britain, for example, solved the problem by insisting that all studies it supports be published. If that condition isn’t fulfilled, they don’t get any money.

“We were able to travel for miles into the mountain through access tunnels, and saw small cracks and crevices in the tunnel walls from which water was dripping. We had a relatively clear task before us: we had to map the structure of an alcove roughly ten cubic metres in size at Nagra’s Grimsel rock laboratory. On our journey there, we only had a vague idea of what exactly awaited us. I had no way of knowing that a small alcove deep inside the Aarmassif would lead me to new explanations for the origins of the whole massif. Today, we can link our knowledge acquired in the depths of the mountain with that of the natural hazards that occur close to the surface, and even with new findings about geothermal energy. “I needed twelve years of intensive collaborative work with my team in order to be able more or less to ‘read’ the mountains in the upper Haslital. These seemingly compact, giant rock formations were formed some 300 million years ago in the middle of the Earth’s crust. It was only about 20 million years ago that the Alps began to form, and the Aarmassif rose up because of increasing pressure and heat. The structures of today’s massif were preconditioned tectonically back then, deep in the Earth, and were permeated with a dense network of malleable fault zones. Much of what we see today in the craggy rock faces was formed far below ground. But the behaviour of this malleability changed during its journey to the cool surface of the Earth. Granite that had formerly been hot and soft now became hard, and the puzzles it poses become more complicated. What remains is really only a giant ‘rubbish heap’ of blocks and plates. “All these factors have their biggest impact where the mountain is at its weakest: at fracture points and in crevasses. That is why we have been hunting for them with different methods. In the Grimsel Massif, we have found more than 30,000 lineaments. These fissures can be seen on the surface, but their sheer number means you can barely comprehend them. So we have looked for their traces on aerial photos, checked them on the spot, and calculated high-resolution models of them using computers. These don’t just show the surface, but predict fractures that penetrate into the interior of the Earth. This information enables us to understand now why the mountains are up to four thousand metres high on the northern edge of the Aarmassif. Glaciers and water have played their part over the past millennia, ensuring that these mountain bastions rise up even more ruggedly into the skies today. The melting away of the glaciers has exposed the rough rock of the extremely steep valley flanks. At the same time, water and large temperature differences wore down the rock even more. These are ideal conditions for gravity to play its part, and can accelerate the onset of rock falls and landslides. A third natural hazard is mudslides, which thunder into the valley after strong rainfalls, and are also caused by the disappearance of the permafrost. “It’s very important to me that our research is able to provide a precise basis for the work of geological engineers. This helps them to better protect the population and the infrastructure in the mountains. It is fascinating how our fundamental research can find concrete applications. Modelling the crevices and the fissures also allows us to carry out far more precise calculations on subterranean water flows. It’s not by chance that the fissured region of the Grimsel is where we find Europe’s highest-lying hot spring. Now we have to set about how to use this energy in the future. But for this, we first had to learn to read this mountain properly”. Recorded by This Rutishauser  

Video game players have solved a 15-year-old puzzle by describing the structure of an HIV envelope protein, and it got them their names on the author list of the specialist journal Nature. But all they’d actually done was to try and score as many points as possible in the computer game ‘Foldit’. It was the first scientific computer game to go online, and it’s all about discovering the correct three-dimensional form of proteins. The background is this. Proteins control almost all processes of life – whether in microbes or in humans. But they can only do this if their long chains of amino acids – sometimes several hundred of them – fold into a specific three-dimensional shape. This shape also determines the point of attack for medicines. Scientists can figure out the sequence of these amino acids relatively easily. But predicting the three-dimensional form of a protein has up to now been almost impossible. The interactions between the amino acids are just too complex. That’s why researchers sometimes work for years to explain the folding of certain proteins. If you look at the complicated procedures that you need to master in order to play Foldit, you quickly realise that you have to learn a lot to be a success at it. “The game showed that even people outside academia can acquire enough knowledge to participate in specialist discussions”, says Strasser. The Foldit graphics are reminiscent of diagrams in chemistry books and don’t look much like fun: all the excitement seems to lie in a small red star that jumps backwards and forwards in a jumble of branches and spirals. If you use your mouse to move the amino acids, more stars can appear. This means that the side branches of the amino acids are too close together and are getting in each other’s way. The protein couldn’t be folded that way in real life. The Foldit interface looks rather ‘nineties’ in design, and the people that play it have also got older. Many are today over 50. Of the registered users, only a few hundred are still active. New players usually belong to a circle of experts. “Foldit isn’t as exciting as shooting zombies”, says Strasser. “It’s very difficult to build up a community of players around a relatively boring game”. It’s for this reason that the start-up ‘Massively Multiplayer Online Science’ (MMOS) in the canton of Valais is forging an interesting new path. This Swiss IT company has made two additions to the multi-player Internet role-playing game ‘Eve Online’, which is a space flight simulator without any scientific aspirations. First, players can now investigate microscopic pictures of coloured cells to look for any obvious changes in them. Secondly, they can assess satellite data in order to discover new planets. Both these additions run under the name ‘Project Discovery’, and the players can generate rewards with them that they can then use in the normal role-playing game. Eve Online has 500,000 registered users, of whom some 40,000 are online at any one time. Scientific research questions are thus being shared with a giant, already existing community. This is a very promising idea, because the difficult step is always to entice enough players into a game and to keep them playing long enough to be able to solve a scientific project through gaming. Meanwhile, there are several hundred scientific games today, whose fields range from astronomy to climate research and entomology. Many have appealing graphics, and some of them are animated. One of the scientific computer games with the most players is Eyewire. It has 250,000 registered users, with 1,000 active players in December 2017. It was developed at the Massachusetts Institute of Technology, and its success probably lies not least in its having been designed as far as possible to be an actual video game. It’s meant to be fun, and features both fictional characters and modern graphics. The goal of Eyewire is to map the course of nerve cells in the retina of the mouse. To this end, the players are assigned ‘dice’ with cross-sectional images of the retina that have been made with electron microscopes. The players use these two-dimensional photographs to reconstruct three-dimensional images of the tangled nerve cells. One of the most successful Eyewire players is Susanne Reber-Leutenegger (@susi) from Sissach near Basel, who’s 68 years old. She recently reached 30 million points. Only one other player has achieved a higher score, @Nseraf. “The game is very satisfying”, she says. “I’ve found a new purpose in life by becoming part of a scientific project again”. She’s also made new friends. Having contact with younger people in the Eyewire community helps her to keep feeling youthful. Susanne is above retirement age, but still has a part-time job as an accountant, which she calls her ‘second’ career. Her ‘first’ career had begun when she completed a doctorate in biology on the microscopic structure of unicellular organisms in the sea. Back in the 1970s, when she was studying biology, she worked on a 3D-reconstruction of an amphibian brain. “Back then we didn’t have any help from computers – you did everything by hand. Eyewire is a kind of third career for me that’s linked up with my first”. Reber-Leutenegger is an exception, however. Most players are men. The best-researched game is Foldit, and there some 90 percent of the players are male. Eighty percent are also active professionally as scientists, engineers or IT specialists. “There are only a few players whose careers have nothing to do with science or computers”, says Bruno Strasser. “So we should be cautious about claiming that citizen science is bringing about a democratisation of science. Not everyone can do research, and not everyone wants to”. It would also be an exaggeration to regard people playing scientific computer games as if they were really ‘scientists’: “They help us with knowledge production, but are more like technicians with special abilities”, says Strasser. “Science is much more – especially when it’s a matter of developing new research fields”.

‘Metre’ means both a measurement and an ordered rhythm in poetry. It came about, ironically, at an immeasurably disordered time – in the wake of the French Revolution, when many different, local units of measurement were replaced by a global decimal system. Napoleon and colonialism ensured that it spread across Europe and throughout the world. In November 2018, another revolution will come about. The kilogram is going to be redefined, and the Swiss Federal Office of Metrology (METAS) is participating in the process. Its ‘Kibble balance’ (also known as a ‘watt balance’) will enable the kilogram to be measured more constantly over time. The philosopher Oliver Schlaudt is investigating how natural scientists, economists and all other scientists quantify the world. He studied physics, and lectures both at the University of Heidelberg and at the Institute for Political Studies ‘Sciencespo’ in Nancy. Is there any point in measuring emotional phenomena such as love? Your question itself testifies to a deeply rooted unease about measurements! So you say it’s possible. But where does this sense of unease come from? On the one hand, there’s the matter of objectivisation. It’s unpleasant to be confronted with facts. It’s like going to the doctor: once you’ve got your diagnosis, you have to live with it. The real problem with measurements is that it means comparing one thing with another. But this actually happens all the time in everyday life. Someone might prefer autumn to summer, or we might find one author more subtle than another. The only difference to how it’s done in science is the degree of precision that scientists use to quantify things. Is there anything that we should never measure on principle? There we have it again, this unease about measuring! We want to draw boundaries. Even when we’re just talking about things, we start to compare. We need everyday concepts, but these can’t do justice to the individual. If I call you a journalist, I’m comparing you with others. Or if I speak of the French Revolution, I’m making it just one revolution among many. And we’re back to our problem again. Does this unease also surface in our attitude to efficiency indicators such as university rankings? This is more of a technical problem, because the measurement criteria are unknown. Excellence and innovative strength are very vague concepts. These criteria are difficult to define, so you inevitably measure the wrong things and create misplaced incentives. The Swiss economist Mathias Binswanger has demonstrated this very neatly. So measuring just means comparing things with each other? Yes, for practical purposes. The first measurements occurred in ancient Mesopotamia. Even before they had numbers, practical matters had to be regulated in legal terms across their large, centrally organised empire. So they had to start measuring things. Mathematics later developed out of this. In what ways do researchers go beyond our everyday comparisons? In matters of precision. That is fundamental. But it’s not simply about taking something to the tenth decimal point. It’s about opening up a gateway to whole new worlds. The microcosm and quantum physics only become visible thanks to very precise measurements. That’s really a qualitative step. So are the observing sciences less objective? Well, their observations aren’t just carried out by anyone, anyhow. Ethnologists don’t just march up to a foreign culture with their photo camera. They are instructed precisely in advance, they compare their observations and thereby engage in a conscious process of objectivisation. What’s special about measuring as opposed to observing is not the act of objectivisation, but the precision that allows the whole panoply of mathematics to be applied to it. Is there measurement envy on the part of the humanities towards the exact sciences? I think so. The natural sciences have become our dominant culture. They define what good science is supposed to be. Measuring is one aspect of that. But as I said: even the humanities engage in comparisons. But they specify less precisely how this happens. They’re more concerned with the authority of the trained intellect.

Fair-trade products are a standard feature of the Swiss retail business today. But the actual meaning of ‘fair trade’ has changed dramatically since the term was coined in the 1960s. The 1973 oil crisis was followed by a global food crisis in 1974, and this prompted a change in the approach of the fair-trade activists. Their goal was no longer to get developing countries unobstructed access to global markets; instead, their focus shifted to local production and protecting small farmers in the developing world. This development continues to have an impact, up to the present day. “For example, there are chocolate factories in Ghana that can’t export their products to Europe on account of trade barriers”, explains Franc. Focussing on a small basket of tropical commodities that are typically sold in Europe under the ‘Fair Trade’ banner leads us to ignore the competitors in other developing countries. These findings prove to Franc that there simply isn’t a patent remedy that could solve all the injustices of the global economy. “As an initial step towards fair global trade, we perhaps need to show some humility in the face of its complexity”.

All lasers exploit the same phenomenon: when an atom at an excited energy level receives a photon, it emits a second photon of the same frequency and phase. This creates a chain reaction that produces a photon flux: this is the laser beam. In their amplifier, Keller and her team in Zurich have used a nanostructured semiconductor for the self-generation of quantum dots. It traps the excited electrons, and thereby amplifies photon emission. “With a density of one trillion quantum dots per square millimetre, this material lends itself to the design of high-performance, compact and energy-efficient femtolasers”, says Keller. Ultrafast lasers have recently begun to appear in consumer devices. In the latest iPhone, they are used for facial recognition: the phone emits a laser beam cloud and analyses the photons reflected by the user’s face and then creates a 3D model. The low power is, however, a limitation, restricting it to use with nearby objects. This is because the number of photons being reflected to the sensor decreases with distance. “Our technology would allow a larger physical environment to be measured in 3D with micrometric accuracy”, she says.

My day begins with an hour of cleaning. I enter the chimpanzee cage, remove the droppings and food scraps, and wipe the windows. For the zoo keepers, it’s a welcome exchange of good practices; for my fellow passengers on my train home, it’s an unwelcome exchange of odours, given how dirty my clothes can become. With the cleaning over, my work as a scientist begins. My aim is to understand how social learning in chimpanzees influences the development of their vocal repertoire. To bear this out, I focus my research on ‘food calls’, the sounds made by apes when they eat or discover food. I am currently studying whether social signals play a cognitive role in the speed of retention of new information. This has involved installing two touch screens in the chimpanzee cage. The screens display pairs of objects that are unfamiliar to the animals: a Rubik’s Cube next to a square pouffe, a hairbrush next to a kitchen whisk. They must then select the image that had been arbitrarily designated as the correct one. As a reward, they receive a piece of fruit. In the experiment, the computer makes one of two sounds just before the images are presented: a food call or a quick blow of a hammer. Then I look at how many tests are necessary for them to retain the right image. The preliminary results suggest that the food call helps them memorise information faster. But this remains to be confirmed. During these sessions, I stay behind the screen and give the rewards at the right time. They can see me, but I am never in direct contact with them and I never work unless a zoo keeper is present. The aim is to guarantee the best level of safety for all and also to avoid subjecting the animals to stress. I’ve previously studied the dingo in Australian wildlife reserves. In the zoo, I am guaranteed to be able to work with the animals for three hours at a time, instead of having to hike for hours through the forest without even being sure of finding my research subjects ... The downside is that zoo populations are smaller and haven’t grown up in a natural environment. There are also certain rules. For example, the animals cannot be separated. My work depends a lot on the mood of my subjects, because their participation is voluntary after all. The zoo keepers and I agreed I should keep to a maximum length of two 15-minute sessions per day. A red background on the screen indicates to the chimpanzee that he/she has reached this limit. This is very important, in terms of diet and of the proper functioning of the group. The apes’ eating behaviour must not be disturbed by the rewards, nor must conflicts arise over access to the screen. Currently, I have at my disposal three adult individuals who have acquired a sufficient level with which to work. Two others are progressing, while there are four females who are not showing any interest in the screens, although I am hopeful that one day they will participate. I was aware of the neophobic nature of chimpanzees, but I was surprised that it took weeks to encourage them to touch the screens – despite the pieces of carrot placed on it. Working with chimpanzees pushes you to constantly rethink your tasks. You have to try to be smarter than them, which is not always easy! If there is a way of getting the reward with less effort, they will always find it. For example, one female’s task was to press a square that moved along a random trajectory. She soon worked out that by pressing the same spot repeatedly, the square would eventually pass under her finger ... In such cases, I am the one who has to adapt by changing the computer program. This research has its fair share of amusing moments too. One day, a female covered my clothes with a handful of excrement that she threw through the grate. Right after, a visitor started asking me some very serious questions about my work, but the smell was so bad that I could hardly keep a straight face! I am currently conducting a second study to determine if the food calls influence an individual’s behaviour with an unknown food. The ultimate goal is the same: by studying apes’ communication skills, we can better understand the evolution of human language. Interview by Martine Brocard.

We may laugh, but behind the joke there is a more serious issue. A tidal wave of doubt has swept away the certainties that science seemed to carry. Conflicting results and political attacks have shaken confidence. Having been dragged from a situation where expertise would guide our individual and collective choices, the citizen is now left deafened by the cacophony of opinions. Yet this state of affairs can also be seen in a better light: as a reconciliation with the doubt that is actually at the heart of science, a clarification of the disagreements through which all knowledge is constructed, an uncovering of conflicts of interest often present in expert reports. All of this can lead us – perhaps – towards a more mature and less naïve relationship between science and society. It would be a relationship where scientists bear a little less responsibility for transmitting the Truth and instead become more involved in the democratic game. And here’s how it might happen. “To understand the situation, we have to go back to the source of what is known as evidence-based policy”, says the Swiss political scientist Caroline Schlaufer, who currently holds a position at the Higher School of Economics in Moscow. The term appeared in Great Britain in the 1990s, under Tony Blair’s government. It describes the intention of the authorities to base their actions on empirically proven facts, rather than on ideology or belief. The expression became fashionable and the social sciences finally decided to look into it and see whether scientific data really are being used in policy, and if so, how. The question of public confidence in experts is also subject to empirical checks. This is indeed the idea behind the Swiss Science Barometer – conducted by the Universities of Zurich and Fribourg – which measures people’s attitudes towards scientific knowledge. The results are rather comforting: “Confidence in science is high”, says Julia Metag, a co-director of the project. “In Switzerland, it is even a little higher than in the other countries where it is measured. The majority of the population agrees that political decisions should be based on scientific results”. She adds a few provisos, however: “Trust in scientists employed by industry is lower than trust in those working in universities. And it is in areas that polarise public opinion that there is more mistrust, such as anything even remotely related to animal experimentation”. The Barometer’s data stretch back to 2016, the beginning of the era of Donald Trump, post-truth and fake news. Has the situation worsened since then? “In the United States, the 2018 Science and Engineering Indicators survey, which measures the same variables as our Barometer, shows that scientists remain one of the most trusted groups in society as a whole”, says Metag. In countries such as the United States and Germany, where longitudinal data are available, this confidence remains stable over decades. “We don’t see any sign of the collapse that’s so readily evoked by the media”. So where does this crisis of perception come from? “In my opinion, there are two new phenomena”, says Schlaufer. “One is ‘expert bashing’, an activity common in certain political movements. The other is the response to these attacks over the past two years whereby scientists have felt a need to raise their voices in the political arena. They have become more and more present in the media to defend their work”. According to Schlaufer, this recent phenomenon does not necessarily reflect a growing politicisation of expertise, but rather, the current exacerbation gives greater visibility to an older fact: expertise had been long politicised before the ‘crisis’ now being deplored. In this sense, scholarly controversy is a reflection of opposing world views and societal projects. “Research can be neutral in itself, but what takes place upstream generally isn’t – by this I mean the definition of the problem we want to study”, says Schlaufer. According to Sheila Jasanoff, a founding figure in the sociology of science and a professor at Harvard University, it represents the calling into question of what she recently termed the “founding myth of expert authority: the separation of facts and values”. At the same time, a reconfiguration of the relationship between science and society is taking place. “Great efforts have been made over the last three decades in many countries to develop forms of debate between scientists and the public”, notes Chilvers. In preparation for the climate conferences in Copenhagen in 2009 and Paris in 2015, for example, there was a series of citizen deliberation sessions. “By the way, this has shown that citizens are quite capable of making very sensible judgments on highly technical issues”. This participatory approach has its grey areas, says Chilvers. “The public is often defined as the problem. Consequently, the process sometimes aims to cause behavioural change among the population in a way that has been defined as desirable in advance by the public authorities”. It is the policy of soft persuasion, known for a decade as ‘nudging’, through which individuals are led to adopt practices that appear to them to be the result of a personal choice rather than a constraint. Underlying the ‘crisis of expertise’ is, therefore, another phenomenon: a broad movement of accepting uncertainty. It is modifying the mutual expectations of experts and the public and proposes renewed roles for both. “Scientists should not just communicate their findings”, says Metag. They should talk about the processes used to construct their results, express their opinions, and engage in discussion with the public”. And if possible, they should resist the temptation to withdraw from the debate out of spite, when they see that their studies are being misused. The media, for their part, should “give a better view of how science works, with its limits and margins of error”. They should also continue to play their role as safeguards, adds Schlaufer. “Sometimes political authorities commission studies and then hide the results when they fail to meet expectations. In general, the study then ends up in the hands of the press and becomes public anyway”. In conclusion, “it is naïve to think that scientific evidence or research results can be the decisive factor in a democratic process: it never happens”, according to Schlaufer. Individual and collective decisions need facts, and to produce facts means turning increasingly to experts. But our choices should also always take on board values, interests, opinions and day-to-day experience. This web of elements is rooted outside of the purity of empirical evidence and reasoning.

An Arctic fox wouldn’t last long in a desert, nor would a desert fox do well in the Arctic. Indeed, most animals in the colder regions of the Earth grow bigger in its warmer climes than related species – although their ears are smaller. The cause of these evolutionary adjustments lies in temperature balance: a large volume with a small surface area means less warmth is lost. Smaller bodily extremities also prevent heat loss. “The reason for this could be a physiological reaction to local temperatures” says Patrick Rohner, the primary author of the study. Insects grow slower when it gets colder, but at the same time, their development time is extended so much that this is more than balanced out. Whether or not this larger size provides flies with an evolutionary advantage in the cold is still unclear, says Rohner. But in colder regions, the flies’ wings were also longer – which is the converse of the rule with warm-blooded creatures. Rohner explains that shorter wings have no effect on the temperature balance of the creature. “Flies are so small that they immediately take on the outside temperature”. However, longer wings have a clear advantage: calculations have shown that they help flies to generate thrust with less energy. This means they can take to the air, even at lower temperatures – perhaps to try and find a warmer spot, for example.



How do you see Switzerland’s relationship with its subsoil? The Swiss obsession with tunnels obviously has economic aspects. There is know-how to export and a market value to prove. As with the underground nuclear fallout shelters during the Cold War, it was partly the result of the cement industry lobbying parliamentarians for their mandatory construction. During the Second World War, the Swiss population was convinced they would end up in the National Redoubt. Mistakenly … There is a double imagery connected to the world underground. On the one hand, since the time of the Sumerians it has been the home of the dead, a place where only gods and heroes survive: Gilgamesh, Amon Ra, Orpheus... On the other hand, there is a positive image of the underground world as a place where we preserve ourselves, as a place of gestation from where a renewed society can emerge when the conditions above ground are once again favourable. In everyday terms, this image comes to life in Switzerland’s traditional carnotzet, a furnished wine cellar for hosting social events, where individuals can work on themselves, at the same time cut off from the outside world and surrounded by a group of friends. It’s a place where Swiss people build their inner characters. Yet the excessive recourse to this behaviour leads to a particular form of claustrophobia observed on board submarines and anywhere people are confined together for long periods: irritability, obsessive disorders, paranoia. This is the trap of the never-ending carnotzet ... Following on from the Alpine tunnels, the National Redoubt and the plethora of fallout shelters, Switzerland is continuing to privilege its subsoil with renewed vigour today in the form of data storage. Switzerland is currently positioning itself on the data-security market. For example, the Ticino-based company Dataverna bought up part of the service tunnels bored during the construction of the Gotthard Base Tunnel, and has since installed its computer servers there. The term ‘data mining’ has been used for some time to describe the exploration and exploitation of data. It’s as if this metaphor is becoming reality. From one point of view, it would indeed seem that the physical world is falling neatly into the boundaries of the metaphor. But seen from another angle it portrays a material attachment to objects, imbued with an ancient imagination and past customs, that endures and even determines our way of thinking. This is the case with everyday objects: for example, the layout of a computer keyboard results from the physical constraints of the typewriter, whose hammers would entangle when certain letters were set too close. Through the material properties of objects, therefore, old social practices are continually imprinted in our minds and behaviours. The impact of this imprinting is typically observed with tunnels. I worked for the PostCarWorld project at EPFL, exploring the hypothesis of a car-free world. We recognised that the new tunnel for cars in the Gotthard – voted for in 2016 – will in some way condemn us, if the tunnel is to be profitable. We voted for the tunnel because we drive cars, and we will continue to drive long distances because the tunnel has become a reality. The logic specific to our ancestors that led to bore holes under the Alps in the first place is now to be found everywhere in our practices because it makes up part of our physical environment. This brings us to one last important aspect of the imagination of the underground. The world may change, but matter endures, and anything imprinted in it, buried in the ground, may later therefore reappear. Like the 7,000 tons of ammunition buried during the Second World War in the Mitholz depot in the Bernese Oberland, which caused a deadly explosion in 1947 and could explode again...  You have explored all kinds of depths in your literary work. This is the story of a Swiss cartographer who is sent on a mission to define Europe’s eastern border. The cartographer arrives in the castle of a boyar, somewhere near Ukraine, where he aims to study a collection of old maps so as to establish the exact line of the border. But the maps all contradict each other, not lining up with one another, and then of course the castle is also slowly sinking into the ground … There are two themes that interest me here. One is linked to a branch of geographic information systems called geodesy, which is used regularly to recalculate the coordinates of a series of points on Earth. The landmarks move relatively quickly: continental drift is as high as 10-15 centimetres per year, which is some two kilometres since the foundation of Jericho. I am fascinated by the fact that even land isn’t permanent, given the movement of tectonic plates. Borders move not only historically but – it appears – also geologically, following this movement of the Earth’s very surface, further implying a fundamental instability of any reference territory. The other theme is related to the movement of the castle sinking. At some point, the protagonist goes digging in the cellars and discovers that the foundations of the building are macerating in clay. He is then confronted not only with the Earth’s capacity to swallow up the reality that we build upon it, but also with the fact that every form of human project is sooner or later absorbed back into shapeless mud. You also connect the imagery of the underground and big data.

Hammer drills are doing their best against the surprisingly tough limestone rock, while flak cannons fire off into the dark. Here in the Hagerbach Test Tunnel near Flums in the canton of St. Gallen, researchers are able to carry out their more extreme tests. Deep in the mountain, it’s not so bad if smoke alarms and fire extinguishing systems have their quirks – so fire detectors can also be tried out here too. If they fail, you can resort to hand-held extinguishers instead. This tunnel was actually created almost fifty years ago as an experimental site for tunnel engineers so that they could work under the most realistic conditions possible. They tested their machines and their explosives so successfully that they ended up with an extensive tunnel system many miles long. Now there’s enough space down here for all kinds of research projects – the kind that appreciate the discretion the place offers, and for which the geological ‘cushion’ provided is much appreciated. When construction machinery unexpectedly uncovers old artefacts of scientific value, the machines give way to archaeologists who rummage through the earth in their stead – with the appropriate degree of caution, of course. These messengers from the past can be hundreds of years or millennia old, and sometimes they are also revealed by soil erosion. That’s when emergency excavations become necessary, which always keep archaeologists working at full capacity. But the archaeologists of today prefer to leave their findings where they turned up in the first place, because that’s where they are best protected, and where the most contextual information can be found. The earth is the best archive; only where the archaeological substance is directly threatened do archaeologists begin excavations. Archaeology is really a kind of controlled act of destruction, says Armand Baeriswyl of the Institute of Archaeological Sciences in Bern. Incidentally, archaeology in Switzerland is the responsibility of the individual cantons. The Swiss Civil Code states: “Ownerless natural bodies or antiquities of scientific value are the property of the canton in whose territory they were found”. You could almost say that the sewage system is the subconscious of our urban existence. When researchers descend into the sewers, they engage with tangible aspects of our history – such as chemical residues. The research conducted by Christoph Ort of the Swiss Federal Institute of Aquatic Science and Technology (EAWAG) in Dübendorf has achieved a certain fame because he has succeeded in calculating drug consumption in different cities just by sampling the tiniest concentrations in waste water. A team run by Frank Blumensaat at the same institute is currently constructing an urban hydrological field laboratory in Fehraltdorf in the canton of Zurich. They want to investigate a town’s complete water circulation system, so they’re installing modern sensors for rainfall, flow rates and water levels in order to create detailed models of outflow processes in an urban environment. Vibrations, sounds, temperature differences – for nanotech experiments, everything has to be reduced to the minimum. IBM has been lucky in Rüschlikon, because the layer of soil and clay below its research centre there is only eight metres thick, under which there lies conglomerate rock. They have built a nanotechnology centre here on a concrete base that’s fixed directly to the rock, independent of the rest of the building. Their six noise-free labs are unique in the world today. But it would be more accurate to say that these labs (or at least their working surfaces) ‘hover’ above the rock. The foundations themselves pick up the nanometre-small vibrations of the cars on the motorway about a hundred metres away, but the labs – all 50 tonnes of them – float on a cushion of air to avoid all extraneous vibrations. This means that all kinds of nanotech experiments can be carried out here under conditions that are quieter and more constant than anywhere else in the world. The labs are also completely shielded off from all electromagnetic rays and from acoustic noise. The temperature does not even fluctuate during an experiment by more than 0.01 degrees Celsius. This mountain never lets you alone. Mont Terri divides the Ajoie district from the rest of the Jura, so it was only a question of time before people started tunnelling through it. First the railways came, then the motorway. But because people have meanwhile found out that its Opalinus Clay is one of the most stable, impermeable geological stratifications, an experimental tunnel has been created alongside the motorway tunnel, where research can be conducted into the storage and management of atomic waste. This project brings together fifteen international partners and is being coordinated by Swisstopo. No actual atomic waste is being brought to Mont Terri, nor will any storage facility ever be built here. The tests they carry out are of a different kind. Recently, for example, one young researcher from EPFL was able to show that the dangerous hydrogen gas released by the corrosion of the steel containers can be removed by micro-organisms that are being cultivated nearby. They’re dark, cold and wet – caves are inhospitable places to live. At least for human beings. Some animals feel positively at home in this ecological niche, but because it’s small and badly lit, the study of these animals – called biospeleology (or ‘cave biology’) itself exists somewhat on the margins of science. There’s only a few specialist scientists who devote themselves to environments underground – and cave researchers usually have other things in mind than trying to find out what’s actually alive down there. Biospeleology is thus an ideal field for citizen science. Sometimes, amateur scientists come up with specimens that can then be classified by specialists. Recently, three new species of pseudo-scorpions were discovered in Hölloch in the canton of Schwyz, in the Jura, and in the Schrattenfluh caves in the canton of Lucerne.
